{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/isa-ulisboa/greends-pml/blob/main/ML_overview_with_examples.ipynb",
      "authorship_tag": "ABX9TyPK2dDw8zkYg2zSO4F5vvf8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "287b831a2015472ca1ad96be2344a838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5037df45e75347b999912f5ff8148050",
              "IPY_MODEL_242053e6c5fe49e9b821e592142baa86",
              "IPY_MODEL_0294731999604d828d2f6db099524643",
              "IPY_MODEL_b56866f8cd04425090c8847432d99030"
            ],
            "layout": "IPY_MODEL_0ad66d52b29b4132880bc2c3878bb0cc"
          }
        },
        "5037df45e75347b999912f5ff8148050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": true,
            "description": "a",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7eb98727910e4732a7a0961c9024160c",
            "max": 3.3000000000000003,
            "min": -1.1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".2f",
            "step": 0.1,
            "style": "IPY_MODEL_6fb1bc9c4e4940fea7bd973249e4c294",
            "value": 2.5
          }
        },
        "242053e6c5fe49e9b821e592142baa86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": true,
            "description": "b",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_468087a33c8d482bb2cd7bdbe0ab01c5",
            "max": 3.3000000000000003,
            "min": -1.1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".2f",
            "step": 0.1,
            "style": "IPY_MODEL_af0c9f2494794d8faf9647863eb50e61",
            "value": 1.1
          }
        },
        "0294731999604d828d2f6db099524643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": true,
            "description": "c",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_cdd35afc8efb4be9ae8fd575d1009bc5",
            "max": 3.3000000000000003,
            "min": -1.1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".2f",
            "step": 0.1,
            "style": "IPY_MODEL_454e8a074fa54e4c93a2e75e611c5e13",
            "value": 1.1
          }
        },
        "b56866f8cd04425090c8847432d99030": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_003db380868741ce917469e6dd6b746d",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<Figure size 432x288 with 1 Axes>",
                  "image/png": "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\n"
                },
                "metadata": {
                  "needs_background": "light"
                }
              }
            ]
          }
        },
        "0ad66d52b29b4132880bc2c3878bb0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb98727910e4732a7a0961c9024160c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb1bc9c4e4940fea7bd973249e4c294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "468087a33c8d482bb2cd7bdbe0ab01c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af0c9f2494794d8faf9647863eb50e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "cdd35afc8efb4be9ae8fd575d1009bc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "454e8a074fa54e4c93a2e75e611c5e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "003db380868741ce917469e6dd6b746d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isa-ulisboa/greends-pml/blob/main/ML_overview_with_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical Machine Learning**\n",
        "\n",
        "Masters in Green Data Science, ISA/ULisboa, 2022-2023\n",
        "\n",
        "Instructor: Manuel Campagnolo mlc@isa.ulisboa.pt"
      ],
      "metadata": {
        "id": "f0qoqpJ4-iom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview of Machine Learning (ML) \n",
        "\n",
        "In this course we are dealing with data sets of *labeled examples*. Examples can be scalar numbers, rows of tabular data, images, etc. For tabular data, we refer the to columns as *explanatory variables* (sometimes also called *independent* or *descriptive* variables).\n",
        "\n",
        "Labels can be categorical, ordinal or continuous. Labels can be refered to as the *response variable* (or *dependent* variable). They are also called *targets*. Typically, we the problems are called:\n",
        "1. *Regression problems*, when the labels are continuous. \n",
        "2. *Classification problems*, when the labels are categorical.\n",
        "\n",
        "The distinction is not always clear. Some problems can be considered either as regression or classification problems. \n",
        "\n",
        "Given a ML problem, i.e. a set of labeled examples, the goal is to build a function $f$ that maps examples to labels or, in other words, that predicts the label from the example.\n",
        "\n",
        "The outputs of $f$ are called *predictions* or *predicted values*, and the actual labels of the examples are called *actual values* or *target values*.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RP73ZCHW-5IP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python packages"
      ],
      "metadata": {
        "id": "OV7OxFdf78XU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this ML course, the main Python packages are:\n",
        "\n",
        "1. **Fastai**, a high-level package build from `pytorch`. A description of `fastai` is available in the paper *Howard, J.; Gugger, S. Fastai: A Layered API for Deep Learning. Information 2020, 11, 108. https://doi.org/10.3390/info11020108* and on the site https://docs.fast.ai/\n",
        "\n",
        "2. **Pytorch**: PyTorch is an optimized tensor library for deep learning using GPUs and CPUs;  https://pytorch.org/docs/stable/index.html\n",
        "\n",
        "3. **Scikit-learn**: Another high-level package build on `NumPy`, `SciPy`, and `matplotlib` which covers most ML techniques except deep learning;  https://scikit-learn.org/stable/index.html."
      ],
      "metadata": {
        "id": "Ly1ySlnR8AMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models and parameters"
      ],
      "metadata": {
        "id": "RW_X7OPCXc3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "More formally, if $E$ is the set of examples and $L$ is a set that includes the labels, then what we call the *model* is a family of functions $f_{\\rm \\bf w}$ that depends on a set of parameters ${\\rm \\bf w}$: $$f_{\\rm \\bf w}: E â†’ L.$$\n",
        "\n",
        "It can be more convenient to express the function as depending on the parameters ${\\rm \\bf w}$ as well as the example ${\\rm \\bf x}$. The model's predicted label $\\hat{y}$ for the example ${\\rm \\bf x}$ is:\n",
        "\n",
        "$$\\hat{y}=f_{\\rm \\bf w}({\\rm \\bf x})= f({\\rm \\bf x}; {\\rm \\bf w}).$$\n",
        "\n",
        "ML practicioners use an enormous variety of models, depending on the problem at hand and on the available computational resources to train the model. Models include convolucional neural networks (CNN) for image classification (resnet and other kind of CNNs), neural networks (NN) for classification of tabular data, linear regression models, decision and regression trees, random forest and other ensemble models, among many other models.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1rjcetay_O8EPd9mUHh4k1XFQIi84FfX2\" width=\"800\" >\n",
        "\n"
      ],
      "metadata": {
        "id": "IKZwTca7XfkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of a simple model (simple linear regression)"
      ],
      "metadata": {
        "id": "xNbDdfhgXHQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose that our examples are scalar numbers $x_1,\\dots, x_n$ and the labels are continuous labels $y_1, \\dots, y_n$. We call $x$ the explanatory variable and $y$ the response variable. \n",
        "\n",
        "Let's consider the simple linear regression model:\n",
        "$f_{\\rm a,b}(x)= a \\, x + b$. The model parameters are ${\\rm \\bf w}=(a,b)$ and the predicted values are given by$\\\\[1em]$ \n",
        "$$\\hat{y}=f(x; {\\rm a,b})=a\\, x + b.$$\n",
        "\n",
        "The target  or actual label values are the $y_1, \\dots, y_n$, and the predicted label values are the $\\hat{y}_1,\\dots,\\hat{y}_n$.\n",
        "\n"
      ],
      "metadata": {
        "id": "ak8k0ZkGXL5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of a simple model (quadratic regression)"
      ],
      "metadata": {
        "id": "KCwiAiilXOkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In notebook [Lesson3_edited_04-how-does-a-neural-net-really-work.ipynb](Lesson3_edited_04-how-does-a-neural-net-really-work.ipynb), a similar simple example was discussed. The only difference was that the model $f_{\\rm a,b,c}$ was quadratic instead of linear: \n",
        "\n",
        "$$f_{\\rm a,b,c}(x)= f(x;a,b,c)= a \\, x^2 + b \\, x + c.$$\n",
        "\n",
        "In the illustration below, the observed (actual) values are plotted in blue, and the values preditted by the model for a fixed set of parameters $a=3, b=2, c=1$ are plotted in red."
      ],
      "metadata": {
        "id": "B06MlDsTXWxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example from Lesson3_edited_04-how-does-a-neural-net-really-work.ipynb\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(42)\n",
        "def noise(x, scale): return np.random.normal(scale=scale, size=x.shape)\n",
        "def add_noise(x, mult, add): return x * (1+noise(x,mult)) + noise(x,add)\n",
        "# create synthetic examples (x) and labels (y), and calculate predictions\n",
        "x = torch.linspace(-2, 2, steps=20)[:,None]\n",
        "def f(x): return 3*x**2 + 2*x + 1\n",
        "y = add_noise(f(x), 0.15, 1.5)\n",
        "ypred=f(x)\n",
        "# plot \n",
        "plt.scatter(x,y);\n",
        "plt.scatter(x,ypred,color='red');\n",
        "plt.title(\"Example of a simple quadratic model with 3 parameters\")\n",
        "plt.xlabel(\"Explanatory variable\")\n",
        "plt.ylabel(\"Response (actual in blue, predicted in red)\")\n",
        "plt.plot(x, f(x), 'red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WcGDmG34Jshd",
        "outputId": "f19cdb50-58a4-4b62-ef9f-ad255aa7e431"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss function"
      ],
      "metadata": {
        "id": "TsCcLtocYK6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In ML, it is usual to call *loss* to the **dissimilarity** between actual and predicted label values for a *set* of labeled examples.\n",
        "\n",
        "Let ${\\rm \\bf x}_1, \\dots , {\\rm \\bf x}_n$ be a set of examples with labels $y_1, \\dots , y_n$. Let $f_{\\rm \\bf w}$ be our model. Therefore, the predicted labels are \n",
        "\n",
        "$$\\hat{y}_1=f_{\\rm \\bf w}({\\rm \\bf x}_1), \\dots, \\hat{y}_n=f_{\\rm \\bf w}({\\rm \\bf x}_n).$$\n",
        "\n",
        "The loss over that set of examples is some dissimilarity measure between the actual labels $y_1, \\dots , y_n$ and the predicted labels $\\hat{y}_1, \\dots , \\hat{y}_n$.\n",
        "\n"
      ],
      "metadata": {
        "id": "Bp8K-cntPVfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example (simple linear regression)\n"
      ],
      "metadata": {
        "id": "cM7AZbYpYeRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "For the linear regression example, the response variable is continuous. We wish to measure the dissimilarity between the set of actual label values $y_1, \\dots , y_n$  and the set of values predicted by the model \n",
        "$f_{\\rm a,b}(x)= a \\, x + b$: \n",
        "\n",
        "$$\\hat{y}_1=a\\, x_1+ b, \\dots, \\hat{y}_n=a\\, x_n+ b.$$\n",
        "\n",
        "Since the response is continuous, it makes sense to use a function like:\n",
        "\n",
        "1. Mean absolute error (MAE), given by $\\frac{1}{n}\\sum_{i=1}^n |y_i-\\hat{y}_i|$; or\n",
        "\n",
        "2. Mean square error (MSE), given by $\\frac{1}{n}\\sum_{i=1}^n \\left(y_i-\\hat{y}_i\\right)^2$."
      ],
      "metadata": {
        "id": "L2buuqntYha_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example (quadratic regression)"
      ],
      "metadata": {
        "id": "2WgfmI8oavMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In notebook [Lesson3_edited_04-how-does-a-neural-net-really-work.ipynb](Lesson3_edited_04-how-does-a-neural-net-really-work.ipynb), loss was given by MAE, i.e. $\\frac{1}{n}\\sum_{i=1}^n |y_i-\\hat{y}_i|$."
      ],
      "metadata": {
        "id": "FE79yyV8a1hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(preds, acts): return (torch.abs(preds-acts)).mean()"
      ],
      "metadata": {
        "id": "P2hSIz50ckp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The notebook includes code to interactively change the parameter values and compute the MAE loss function for the data set for an arbitrary choice of weights $(a,b,c)$.\n",
        "\n",
        "Function `partial` in the code below converts the 4-argument function $f(x,a,b,c)$ into a one argument function $f(x;a,b,c)=f_{\\rm a,b,c}(x)$. Therefore, `mk_quad` corresponds to the one argument function $f_{\\rm a,b,c}(x)$. Hence it can be passed to `plot_function` which expects a one argument function.\n",
        "\n"
      ],
      "metadata": {
        "id": "Mz8gGbFccln_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.basics import * # necessary for partial\n",
        "def quad(a, b, c, x): return a*x**2 + b*x + c\n",
        "def mk_quad(a,b,c): return partial(quad, a,b,c)\n",
        "def plot_function(f, title=None, min=-2.1, max=2.1, color='r', ylim=None):\n",
        "    x = torch.linspace(min,max, 100)[:,None]\n",
        "    if ylim: plt.ylim(ylim)\n",
        "    plt.plot(x, f(x), color)\n",
        "    if title is not None: plt.title(title)\n",
        "# interactive plot\n",
        "from ipywidgets import interact\n",
        "@interact(a=1.1, b=1.1, c=1.1) # this is called a decorator\n",
        "def plot_quad(a, b, c):\n",
        "    f = mk_quad(a,b,c)\n",
        "    plt.scatter(x,y)\n",
        "    loss = mae(f(x), y)\n",
        "    plot_function(f, ylim=(-3,12), title=f\"MAE: {loss:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377,
          "referenced_widgets": [
            "287b831a2015472ca1ad96be2344a838",
            "5037df45e75347b999912f5ff8148050",
            "242053e6c5fe49e9b821e592142baa86",
            "0294731999604d828d2f6db099524643",
            "b56866f8cd04425090c8847432d99030",
            "0ad66d52b29b4132880bc2c3878bb0cc",
            "7eb98727910e4732a7a0961c9024160c",
            "6fb1bc9c4e4940fea7bd973249e4c294",
            "468087a33c8d482bb2cd7bdbe0ab01c5",
            "af0c9f2494794d8faf9647863eb50e61",
            "cdd35afc8efb4be9ae8fd575d1009bc5",
            "454e8a074fa54e4c93a2e75e611c5e13",
            "003db380868741ce917469e6dd6b746d"
          ]
        },
        "id": "PoOuvmF9bHM4",
        "outputId": "8a86cddb-3408-4ace-a71e-56c81e087cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(FloatSlider(value=1.1, description='a', max=3.3000000000000003, min=-1.1), FloatSlider(vâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "287b831a2015472ca1ad96be2344a838"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dissimilarity measures to define *loss*"
      ],
      "metadata": {
        "id": "9dLMWMHcYlvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To define loss, we then need to choose an appropriate dissimilarity metric between a set of actual $y_1, \\dots , y_n$ and predicted labels $\\hat{y}_1, \\dots , \\hat{y}_n$. The choice depends on the type of problem, and while MAE or RMSE are adequate for *regression* problems, other dissimilarities are used for *classification* problems.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JaP8Ef2zYo24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples of loss functions for regression problems (MAE, MSE, Huber)\n",
        "\n"
      ],
      "metadata": {
        "id": "TazkXj5DYsdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, two common loss functions for regression problems were listed\n",
        "\n",
        "1. Mean absolute error (MAE), given by $\\frac{1}{n}\\sum_{i=1}^n |y_i-\\hat{y}_i|$; or\n",
        "\n",
        "2. Mean square error (MSE), given by $\\frac{1}{n}\\sum_{i=1}^n \\left(y_i-\\hat{y}_i\\right)^2$\n",
        "\n",
        "In the one hand, MAE is not differentiable everywhere, which is an undesirable property for ML. On the other hand, MSE penalizes too much large differences between actual and predicted values, which means that a single example can constraint strongly the solution. \n",
        "\n",
        "An alternative is called the Huber loss function, which is differentiable everywhere, and behaves like MSE near the origin and like MAE for large $|y_i-\\hat{y}_i|$.\n"
      ],
      "metadata": {
        "id": "WlJNpKjwWRLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of loss functions for classification problems (cross-entropy)"
      ],
      "metadata": {
        "id": "Fsp3Fh9KYwCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification problems have categorical labels. Therefore, the model predictions should return the most likely label for each example. \n",
        "\n",
        "While in regression the model's output is typically an unbounded response variable (for instance, it is $f(x;a,b) = a\\, x + b$ in simple linear regression), for classification problems, it is more convenient to have:\n",
        "1. one output per label;\n",
        "2. each output being a value between 0 and 1 that can be interpreted as the probability of the label.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1iD519g8QbBmOGp9SiOQsIneJnWg53SMQ\" width=\"600\" >\n",
        "\n",
        "Therefore, it is usual to have a model that outputs scores $f_1({\\rm \\bf x};{\\rm \\bf w_1}), \\dots , f_k({\\rm \\bf x};{\\rm \\bf w_k})$ for each of the $k$ possible labels, and an additional model component that converts those *raw* scores into probability-like values for the labels.\n",
        "\n",
        "You saw that kind of probabilistic output when you trained and deployed an image classifier in notebook [Lesson2_edited_book_02_production.ipynb](Lesson2_edited_book_02_production.ipynb). When you did predict the label for a new example with\n",
        "\n",
        "    learn_inf.predict('images/grizzly.jpg'),\n",
        "\n",
        "you got a vector of estimated probabilities like the following:\n",
        "\n",
        "    ('grizzly', tensor(1), tensor([9.0767e-06, 9.9999e-01, 1.5748e-07])).\n",
        "\n",
        "where the values `9.0767e-06, 9.9999e-01, 1.5748e-07` correspond, respectively, to labels *black*, *grizzly* and *teddy*.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NHRyajD_N6hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Softmax \n",
        "\n"
      ],
      "metadata": {
        "id": "iPE1rlP3fzTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The unormalized model outputs $f_1, \\dots, f_k$ are called *scores*, *logits* or *raw* outputs. Each score $z_i=f_i({\\rm \\bf x};{\\rm \\bf w_i})$ is converted into a [0,1] value by the *softmax* function:\n",
        "\n",
        "$$p_i=\\frac{\\exp(z_i)}{\\sum_{j=1}^k \\exp(z_j)} ~~ {\\rm which~implies~that} ~~ 0<p_i \\le 1.$$\n",
        "\n",
        "After that transformation, the classification model's probabilistic output is a vector of values $(p_1,\\dots,p_k)$, with $p_i \\ge 0$ and $\\sum p_i=1$ as required for  probability distributions. The predicted label is the one with highest $p$.\n"
      ],
      "metadata": {
        "id": "9g9P9qwTf18P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing target and predicted probability distributions\n",
        "\n"
      ],
      "metadata": {
        "id": "B-r4_0PVfthi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While in the regression problem the loss is a dissimilarity between the actual labels $y_1,\\dots,y_n$ and the predicted labels $\\hat{y}_1,\\dots,\\hat{y}_n$ for the set with $n$ examples, in classification with *softmax* the loss is then a dissimilarity between the actual labels $y_1,\\dots,y_n$ and the $n$ probability vectors $(p_1,\\dots,p_k)_1, \\dots, (p_1,\\dots,p_k)_n$.\n",
        "\n",
        "To compare vectors of the same dimension, one can express each target label $y_i$ as a probabilitity distribution with 0 uncertainty. Suppose that there are 3 different possible labels and the actual label of the example is the first label: then, the *target distribution* would be $(1,0,0)$ which can be  compared with the model's output probability distribution $(p_1,p_2,p_3)$. This will be illustrated with an example below.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "86MG2Jplf8LX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loss functions in fastai\n",
        "\n"
      ],
      "metadata": {
        "id": "JeIWFIf1gCoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A list of `fastai` loss functions is available in https://docs.fast.ai/losses.html. In general, they are simple adaptations of `pytorch` loss functions listed in https://pytorch.org/docs/stable/nn.html#loss-functions.  The most common *loss* function for classification is called *cross-entropy*. \n",
        "\n",
        "Notebook [Lesson1_00_is_it_a_bird_creating_a_model_from_your_own_data.ipynb](Lesson1_00_is_it_a_bird_creating_a_model_from_your_own_data.ipynb) creates the learner with:\n",
        "\n",
        "    learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
        "\n",
        "`vision_learner` allows to explicitely define the loss function  with the argument `loss_func`. Since it is not explicitely defined in the code above, we can check the default which is stored in property `loss_func`:\n",
        "\n",
        "    learn.loss_func\n",
        "\n",
        "which returns `FlattenedLoss of CrossEntropyLoss()`. This `fastai` loss is described in the Pytorch documentation as the `nn.CrossEntropyLoss` class  [https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). Hence, the loss function that is applied in the example in the notebook is  `torch.nn.CrossEntropyLoss` that computes the cross entropy loss between input logits and target. \n",
        "\n"
      ],
      "metadata": {
        "id": "iPfaq5EUgOR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-entropy\n",
        "\n"
      ],
      "metadata": {
        "id": "qq_PFJW3gGcn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, what is the *loss* you see in the output when you train an image classifier in notebook [Lesson2_edited_book_02_production.ipynb](Lesson2_edited_book_02_production.ipynb)?\n",
        "\n",
        "    epoch \ttrain_loss \tvalid_loss \terror_rate \ttime\n",
        "    0          1.174910        0.043982      0.009091     00:34\n",
        "\n",
        "\n",
        "Suppose that your model (`resnet`) was trained to classify photos of bears into *black*, *grizzly* and *teddy* as in [Lesson2_edited_book_02_production.ipynb](Lesson2_edited_book_02_production.ipynb). The last layer of the model outputs scores $z_1=f_1(x_1,\\dots,x_n), z_2=f_2(x_1,\\dots,x_n), z_3=f_3(x_1,\\dots,x_n)$, where $z_1$ is associated to *black*, $z_2$ is associated to *grizzly* and $z_3$ is associated to *teddy*. \n",
        "\n",
        "The code below creates an example of the outputs for a *batch* of 4 examples. In the matrix below each row is an example and each column is a label. Consider that column 1 is for *black*, column 2 is for *grizzly* and column 3 is for *teddy*."
      ],
      "metadata": {
        "id": "lqWLiFHzgJjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "scores=torch.tensor([[4.5,2.1,0.2],\n",
        "                     [1.3,8.3,0.8],\n",
        "                     [1.2,1.5,4.2],\n",
        "                     [5.1,0.4,2.3]])"
      ],
      "metadata": {
        "id": "pYMCDHdArmrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ikv6xMwCYSAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the tensor above, it looks like the first and fourth examples have a higher likelihood of being photos of *black* bears, while the second example is more likely a *grizzly* bear and the third one seems to be a *teddy* bear photo. Let's apply *softmax* to convert the raw outputs into probability-like values."
      ],
      "metadata": {
        "id": "9N7exOe4L6Y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " softs = scores.softmax(dim=1)\n",
        " torch.set_printoptions(sci_mode=False)\n",
        " softs"
      ],
      "metadata": {
        "id": "_JktsXREIxvg",
        "outputId": "40f4c65a-fadc-4b6a-c9fe-84dca1ab5454",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    0.9056,     0.0822,     0.0123],\n",
              "        [    0.0009,     0.9985,     0.0006],\n",
              "        [    0.0446,     0.0602,     0.8953],\n",
              "        [    0.9347,     0.0085,     0.0568]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clear that the softmax rule did amplify the difference in values for each example. In each row there is one value close to 1 and the remainder values are close to 0. For each example, *cross-entropy* compares the target distribution with the probability distribution returned by *softmax*. \n",
        "\n",
        "Let's suppose that in fact, the first and last examples have actually label *black*, the second is actually *grizzly* and the third is actually *teddy*. Then the target distribution will be 1 for the correct label and 0 for the remaining labels. This is known as  *one-hot encoding* and it's illustrated by the rows of the following tensor (each row is one example):"
      ],
      "metadata": {
        "id": "q-ok5s3pMwFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target=torch.tensor([[1.,0.,0.],\n",
        "                     [0.,1.,0.],\n",
        "                     [0.,0.,1.],\n",
        "                     [1.,0.,0.]])"
      ],
      "metadata": {
        "id": "5MLo9NugNaLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-entropy loss measures the dissimilarity between the probability distribution returned by *softmax* $(p_1,p_2,p_3)$ and the target distribution $(t_1,t_2,t_3)$ for the $i$-th example with the expression, and takes values between 0 (optimal value associated to minimum uncertainty) and 1 (maximum value associated to maximum uncertainty, i.e. all probabilities are equal):\n",
        "\n",
        "$$L_i=-\\left( t_1 \\, \\log(p_1) + t_2 \\, \\log(p_2) + t_3 \\, \\log(p_3) \\right) \\in [0,1].$$\n",
        "\n",
        "In the expression above, we suppose that the probabilities are non zero. \n",
        "For the whole batch of $n$ examples, the cross-entropy loss is given by the average of the $n$ individual loss values:\n",
        "\n",
        "$$L=\\frac{1}{n} \\left( L_1+L_2+ \\dots,L_n\\right).$$\n",
        "\n",
        "This can be computed with `nn.CrossEntropyLoss()` directly from the *scores* and *target* values as shown below:"
      ],
      "metadata": {
        "id": "2ziX1cVzOkaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "# compute loss\n",
        "loss = nn.CrossEntropyLoss()\n",
        "output = loss(scores, target)\n",
        "print('Cross Entropy Loss: ', output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIbwzbeJp7Vg",
        "outputId": "33f64b4d-0208-46bc-973c-12c428bc61c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Entropy Loss:  tensor(0.0697)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ML as an optimization problem\n"
      ],
      "metadata": {
        "id": "BZmxXfDFYx3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now, we can define a ML problem as a optimization problem. Given\n",
        "\n",
        "1.  a set of examples  ${\\rm \\bf x}_1, \\dots , {\\rm \\bf x}_n$  with labels $y_1, \\dots , y_n$\n",
        "2. a model $f_{\\rm \\bf w}$\n",
        "3. a *loss* function $L$\n",
        "\n",
        "the goal is to determine the optimal set of parameters ${\\rm \\bf w}$ that minimize the loss $L$ over that set of examples."
      ],
      "metadata": {
        "id": "8GK-Y7gRLHC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and validation sets"
      ],
      "metadata": {
        "id": "xTke3ilGLKyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prevent *overfitting* the parameters to the set of examples, an independent set of examples for *validation* are set apart. In general, the example data set with $N$ examples is partitioned into a subset with, say $0.2 \\times N$ examples for validation and $0.8 \\times N$ examples for training like we saw in [Lesson2_edited_book_02_production.ipynb](Lesson2_edited_book_02_production.ipynb):\n",
        "\n",
        "    bears = DataBlock(\n",
        "        blocks=(ImageBlock, CategoryBlock), \n",
        "        get_items=get_image_files, \n",
        "        splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "        get_y=parent_label,\n",
        "        item_tfms=Resize(128))\n",
        "\n",
        "where `RandomSplitter(valid_pct=0.2, seed=42)` indicates that 20% of the examples are used for validation.\n",
        "\n",
        "The *training* data set is used to search for the optimal set of weights for the model, typically by iteratively updating the weights from a initial set of weights using *gradient descent* over the loss. The *validation* data set is used to compute the same loss metric over an independent set of examples.\n",
        "\n",
        "By comparing the training and validation losses it is possible to assess issues in model behaviour like *high bias/underfitting*,  *high variance/overfitting*,  and *unrepresentativeness* of either training or validation set."
      ],
      "metadata": {
        "id": "hP5GBX3zLPpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient descent and learning rate"
      ],
      "metadata": {
        "id": "zIX1NzGbLTkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Informally, a gradient measures how much the output of a function changes if you change the inputs a little bit.\n",
        "\n",
        "Given a model $f_{\\rm \\bf w}({\\rm \\bf x})= f({\\rm \\bf x}; {\\rm \\bf w})$ and a batch of examples ${\\rm \\bf x_1}, \\dots, {\\rm \\bf x_n}$, we have seen how we can define a *loss* function \n",
        "\n",
        "$$L({\\rm \\bf x_1, \\dots, x_n; w})= L_{\\rm \\bf x_1, \\dots, \\rm \\bf x_n}(\\rm \\bf w).$$ \n",
        "\n",
        "We can write $L$ just a function of the weights since the ${\\rm \\bf x_i}$ are fixed for given batch of examples. Our goal is to find the set of weights ${\\rm \\bf w}$ that minimize $L({\\rm \\bf w})$. In order to do this iteratively, starting with an arbitrary set of initial weights, we would like to know how $L$ changes with a small change in the weights $\\rm \\bf w$ from the current set weights ${\\rm \\bf w}^{*}$.\n",
        "\n",
        "This  is given by the gradient of $L$ with respect to ${\\rm \\bf w}$ at ${\\rm \\bf w}^{*}$, which is a vector of partial derivatives of $L$ with length equal to $m$=number of model parameters.\n",
        "\n",
        "$$ \\nabla L({\\rm \\bf w}^{*}) = \\frac{\\partial L}{\\partial \\rm \\bf w}({\\rm \\bf w}^{*})= \\left(\\frac{\\partial L}{\\partial \\rm w_1}({\\rm \\bf w}^{*}), \\dots,  \\frac{\\partial L}{\\partial \\rm w_m}({\\rm \\bf w}^{*}) \\right).$$\n",
        "\n",
        "The computation of $\\nabla L({\\rm \\bf w}^{*})$ is usually done by **back-propagation**, which is an automatic differentiation algorithm for calculating gradients for the weights in a neural network graph structure. Back-propagation (aka *backprop*) is an automatic differentiation algorithm that applies the *chain-rule*.\n",
        "\n",
        "The vector $\\nabla L({\\rm \\bf w}^{*})$ points to the direction from ${\\rm \\bf w}^{*}$ along which $L$ grows faster, so gradient descent follows the opposite direction $ - \\nabla L({\\rm \\bf w}^{*})$. \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1-KGjbUaR1l3z879V_eJu7JutnSutqbdC\" width=\"500\" >\n",
        "\n",
        "\n",
        "To simplify, let's suppose that all examples are visited before updating the set of weights. \n",
        "Then, the steps of gradient descent algorithm are the following. In ML, one *epoch* corresponds to the processing of the totally of examples in the data set. So, for instance, if the algorithm runs for 20 epochs, then the model is applied to all examples 20 times.\n",
        "\n",
        "---\n",
        "\n",
        "1. Choose an initial set of weights ${\\rm \\bf w}^{*}$\n",
        "\n",
        "2. For $i = 1, \\dots, E$, where $E$ is the number of epochs, do:\n",
        "\n",
        "   i) Cumpute $\\nabla L({\\rm \\bf w}^{*})$\n",
        "\n",
        "   ii) Update ${\\rm \\bf w}^{*}:={\\rm \\bf w}^{*} - \\eta \\, \\nabla L({\\rm \\bf w}^{*}) $, where $\\eta >0 $ is the learning rate.\n",
        "\n",
        "---\n",
        "\n",
        "The choice of the *learning rate* is critical for a good performance of the algorithm. A very small learning rate will permit a good approximation of the gradient flow by the algorithm (see next figure). But if the step is too small, many epochs will be needed to get a good solution. \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=12c4X3po4-xVGUJKzyKC56lwl4ZEmXqWa\" width=\"400\" >\n",
        "\n",
        "\n",
        "\n",
        "ML practicioners use many different techniques to determine the *learning rate*. In particular, the learning rate can be adaptive and change along epochs, which is a standard approach in ML. An adaptive learning rate is provided by the `fine_tune` method used in   [Lesson1_02_saving_a_basic_fastai_model.ipynb](Lesson1_02_saving_a_basic_fastai_model.ipynb):\n",
        "\n",
        "    learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
        "    learn.fine_tune(3)\n",
        "\n",
        "In alternative, package `fastai` contains a method `lr_find()` that helps to find a adequate lerning rate, as discussed at 1:20' of Lesson 5 of [Practical Deep Learning for Coders 2022](https://course.fast.ai/), where it is used in the following chunk of code:\n",
        "\n",
        "    learn = tabular_learner(dls, metrics=accuracy, layers=[10,10])\n",
        "    learn.lr_find(suggest_funcs=(slide, valley))\n",
        "    learn.fit(16, lr=0.03)\n",
        "\n",
        "The value `0.03` used with `learn.fit` is derived from the visual interpretation of the output of `learn.lr_find(suggest_funcs=(slide, valley))` which is the following.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1bAH7oLrIsuISeZMr749FkI1rkmDp-hw-\" width=\"500\" >\n"
      ],
      "metadata": {
        "id": "yl_HK7NvwxUi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Mini-Batch Gradient Descent applied to simple linear regression\n",
        "\n",
        "The description above of the gradient descent algorithm is for the simplest case, where weights are updated once per epoch. This is called *batch gradient descent*. Things get a bit more involved if one wants to group examples in smaller batches and update the weights after each batch, which is the most common approach in ML. There is another alternative, which is opposite to *batch gradient descent*, called *stochastic gradient descent*, where weights are updated after each single example (this is the particular case of a mini-batch of size 1).\n",
        "\n",
        "In short:\n",
        "1. *stochastic gradient descent*, where weights are updated after each single example;\n",
        "2. *batch gradient descent*, where weights are updated once per epoch;\n",
        "3. *mini-batch gradient descent*, which is somewhere in between the other two.\n",
        "\n",
        "Next, we create from scratch a gradient descent for the very simple linear regression problem, and we compare the result with the optimal coefficients obtained by *least squares*. The code below shows how *training loss* and *validation loss* are computed. It also illustrates how weights update are done after each mini-batch of data (i.e. *mini-Batch Gradient Descent*).\n",
        "\n",
        "The most specific part of the algorithm is the gradient computation. Note that the *gradient machinery* of `pytorch` is turned-on for each weight with `requires_grad = True` as in the following case:\n",
        "\n",
        "    coeffs=torch.tensor([-20.,-10.]).requires_grad_()\n",
        "\n",
        "Then, the derivatives can be computed for any continuous function of the weights in tensor `coeffs`. In particular, the *loss* $L$ is defined as a function (that can be arbitrarily complicated) of the weights, and the *gradient* $\\nabla L({\\rm \\bf w}^{*})$ for the current set of weights ${\\rm \\bf w}^{*}$ is computed with \n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "Finally, the weights are updated with \n",
        "\n",
        "    coeffs.sub_(coeffs.grad * step_size)\n",
        "\n",
        "where method `sub_` is substraction for weight updating ${\\rm \\bf w}^{*}:={\\rm \\bf w}^{*} - \\eta \\, \\nabla L({\\rm \\bf w}^{*})$, and  the learning rate $\\eta$ is called `step_size` in the code.\n"
      ],
      "metadata": {
        "id": "1fG2E4DuYzu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "torch.manual_seed(42)\n",
        "\n",
        "B=20 # batch size\n",
        "step_size = 0.1 # learning rate\n",
        "iter=20 # number epochs\n",
        "\n",
        "############################################ Creating synthetic data\n",
        "# Creating a function f(X) with a slope of -5\n",
        "X = torch.arange(-5, 5, 0.1).view(-1, 1) # rank-2 tensor\n",
        "func = -5 * X + 2\n",
        "# Adding Gaussian noise to the function f(X) and saving it in Y\n",
        "y = func + 0.4 * torch.randn(X.size())\n",
        "\n",
        "##################################### Create train and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "########################################## Baseline: Linear regression LS solution\n",
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression().fit(X, y)\n",
        "print('coefficients:',reg.intercept_,reg.coef_)\n",
        "\n",
        "####################################################### Gradient Descent\n",
        "# initial weights\n",
        "coeffs=torch.tensor([-20.,-10.]).requires_grad_() \n",
        "\n",
        "# defining the function for prediction (linear regression)\n",
        "def calc_preds(x): return coeffs[0] + coeffs[1] * x \n",
        "\n",
        "# Computing MSE loss for one batch of exemples\n",
        "def calc_loss_from_labels(y_pred, y): return torch.mean((y_pred - y) ** 2)\n",
        "\n",
        "# lists to store losses for each epoch\n",
        "training_losses=[]; validation_losses=[]\n",
        "\n",
        "# epochs\n",
        "for i in range(iter):\n",
        "  # calculating loss as in the beginning of an epoch and storing it\n",
        "    y_pred = calc_preds(X_train)\n",
        "    training_losses.append(calc_loss_from_labels(y_pred, y_train).tolist())\n",
        "    y_pred = calc_preds(X_valid)\n",
        "    validation_losses.append(calc_loss_from_labels(y_pred, y_valid).tolist())\n",
        "    # mini-batch gradient descent: weight are updated after each batch\n",
        "    for idx_start in np.arange(0,X_train.shape[0],B):\n",
        "        # create batch\n",
        "        batch_X=X_train[idx_start:(idx_start+B),:]\n",
        "        batch_y=y_train[idx_start:(idx_start+B):]\n",
        "        # making a prediction in forward pass\n",
        "        y_pred = calc_preds(batch_X)\n",
        "        # calculating the loss between predicted and actual values\n",
        "        loss = calc_loss_from_labels(y_pred, batch_y)\n",
        "        # compute gradient\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            # update coeffs\n",
        "            coeffs.sub_(coeffs.grad * step_size)\n",
        "            # zerofy gradients (because they add up)\n",
        "            coeffs.grad.zero_()\n",
        "\n",
        "print('batch size:', B)\n",
        "print('coeffs found by gradient descent:',coeffs.requires_grad_(False))\n",
        "# plot training and validation losses along epochs\n",
        "plt.plot(training_losses, '-g',  validation_losses, '-r')\n",
        "plt.gca().legend(('train','validation'))\n",
        "plt.ylim(0, 5)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss (MSE)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "sS0Uki84xoHN",
        "outputId": "72deaf5d-36ac-4821-bda1-2973574c77c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coefficients: [2.0237875] [[-5.0023813]]\n",
            "batch size: 20\n",
            "coeffs found by gradient descent: tensor([ 2.0390, -5.0677])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some techniques to improve deep learning"
      ],
      "metadata": {
        "id": "CTkkRiF4A9TH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regularization** is a technique used in machine learning to prevent overfitting by adding a penalty term to the loss function. This encourages the model to learn a simpler representation of the data and reduces its capacity to memorize the training data.\n",
        "\n",
        "**Self-regularized activation functions** can help improve the generalization performance of a neural network by introducing an implicit form of regularization. This can be achieved through various mechanisms, such as controlling the distribution of the activations or the gradients. For example, the *Mish activation function* has been shown to have a self-regularizing effect due to its non-monotonic and smooth nature, which can help prevent the vanishing gradient problem and improve the training dynamics of deep neural networks.\n",
        "\n",
        "The *Mish activation function* (https://arxiv.org/abs/1908.08681) is an alternative to *ReLu*. It is a smooth, continuous, self regularized, non-monotonic activation function mathematically defined as\n",
        "\n",
        "$$f(x)= x \\, {\\rm tanh} (\\ln (1+e^x)).$$\n",
        "\n",
        "**Dropout** is a regularization technique used in deep learning to prevent overfitting. It works by randomly â€œdropping outâ€ or deactivating some of the neurons in a neural network during training. This means that during each forward pass, some of the neurons are temporarily removed from the network, along with all their incoming and outgoing connections.\n",
        "\n",
        "The idea behind dropout is to introduce randomness and prevent the model from relying too heavily on any single neuron or feature. By randomly dropping out neurons during training, the model is forced to learn a more robust representation of the data that is less sensitive to small changes in the input.\n",
        "\n",
        "Dropout is typically applied to the hidden layers of a neural network and can be controlled by a hyperparameter called the dropout rate, which specifies the probability that any given neuron will be dropped out during training. A common value for the dropout rate is 0.5, meaning that on average, half of the neurons in a given layer will be dropped out during each forward pass.\n",
        "\n",
        "During testing or inference, dropout is not applied and all neurons are active. However, to account for the fact that only a fraction of the neurons were active during training, the outputs of the neurons are typically scaled down by the dropout rate.\n",
        "\n",
        "**Momentum**  is a technique used in deep learning to accelerate the training of neural networks. It is an optimization algorithm that helps the model converge faster by adding a fraction of the previous weight update to the current weight update.\n",
        "\n",
        "In gradient descent, the weights of a neural network are updated by taking a step in the direction of the negative gradient of the loss function with respect to the weights. This can sometimes result in slow convergence or getting stuck in local minima. Momentum addresses these issues by introducing a â€œmomentumâ€ term that takes into account the previous weight updates.\n",
        "\n",
        "The idea behind momentum is to add a fraction of the previous weight update to the current weight update, effectively â€œsmoothing outâ€ the updates and helping the model converge faster. This can be controlled by a hyperparameter called the momentum coefficient, which specifies how much of the previous weight update should be added to the current weight update. A common value for the momentum coefficient is 0.9.\n",
        "\n",
        "Momentum can be used with various optimization algorithms, such as stochastic gradient descent (SGD) or Adam, to improve their convergence properties.\n",
        "\n",
        "**Adam** (short for Adaptive Moment Estimation) is an optimization algorithm commonly used in deep learning to train neural networks. It is an extension of stochastic gradient descent (SGD) that incorporates ideas from other optimization algorithms such as AdaGrad and RMSProp.\n",
        "\n",
        "Adam works by maintaining an estimate of the first and second moments of the gradients (i.e., the mean and uncentered variance) and using these estimates to adaptively adjust the learning rate for each weight in the network. This allows the algorithm to converge faster and achieve better performance than traditional SGD.\n",
        "\n",
        "One of the key advantages of Adam is that it requires little tuning of its hyperparameters. The algorithm has three main hyperparameters: the learning rate, the first moment decay rate (beta1), and the second moment decay rate (beta2). The default values for these hyperparameters (0.001, 0.9, and 0.999, respectively) usually work well in practice.\n",
        "\n",
        "Adam has been shown to work well on a wide range of deep learning problems and is often used as the default optimizer in many deep learning frameworks.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rYJGaxwxBEMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assessing ML performance"
      ],
      "metadata": {
        "id": "kP-e5P8tGRD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error rate and accuracy"
      ],
      "metadata": {
        "id": "4VcxcaTjMHJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook [Lesson1_00_is_it_a_bird_creating_a_model_from_your_own_data.ipynb](Lesson1_00_is_it_a_bird_creating_a_model_from_your_own_data.ipynb) uses  `error_rate` when creating the `learner`:\n",
        "\n",
        "    learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
        "\n",
        "    learn.fine_tune(3)\n",
        "\n",
        "where `dls` is a `DataLoaders` object with the input data, `resnet18` is a deep CNN model. The argument `metrics=error_rate` indicates that the overall performance of the algorithm is measured proportion of mismatches between the set of actual labels $y_1, \\dots , y_n$ and the set of predicted labels $\\hat{y}_1, \\dots , \\hat{y}_n$. A very similar metric is `accuracy` which is simply `1-error_rate`. \n",
        "\n",
        "When one trains a classifier in `fastai`, the output for the training epochs looks like\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1PJ36nJ-Isu-LThJTFwRj7XwVY5qWeRfJ\" width=\"300\" >\n",
        "\n",
        "One could wonder how the  `error_rate` is computed when the data set is divided into *training* and *validation* sets. In `fastai`, because the training set and validation set are integrated into a single class (`dataloaders`),  by default the metrics displayed during training (as in the output above) use the validation set, so the `error_rate`is computed over the validation set.\n",
        "\n",
        "At this point it should be clear what `epoch`, `train_loss`, `valid_loss` and `error_rate` in the above training output are:\n",
        "1. `epoch`: number of times that the whole set of examples has been used for prediction;\n",
        "2. `train_loss`: the value of the loss function computed with the model weights for that epoch and the training examples;\n",
        "3. `valid_loss`: the value of the loss function computed with the model weights for that epoch and the validation examples;\n",
        "4. `error_rate`: proportion of mismatches between the set of actual labels $y_1, \\dots , y_n$ and the set of predicted labels $\\hat{y}_1, \\dots , \\hat{y}_n$ computed with the model weights for that epoch and the validation examples.\n",
        "\n",
        "There are many metrics other than `error_rate` for measuring the performance of *regression* and *classification* problems. For instance, `scikit-learn` provides the metrics listed in \n",
        "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics. The package `fastai`  includes  all metrics from `scikit-learn` and some additional ones. The documentation is available at https://docs.fast.ai/metrics.html. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "At32ItDHGVkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion matrix"
      ],
      "metadata": {
        "id": "RyKdSl5bQA_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In [Lesson2_edited_book_02_production.ipynb](Lesson2_edited_book_02_production.ipynb), to understand in detail which  mistakes the model is making,  a confusion matrix (also called an *error matrix*) was created with \n",
        "\n",
        "    interp = ClassificationInterpretation.from_learner(learn)\n",
        "\n",
        "    interp.plot_confusion_matrix()\n",
        "\n",
        "which output was: \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1zsTJ7wh6KneWG7_QuXijy5LDlJiu3K-F\" width=\"300\" >\n",
        "\n",
        "\n",
        "The comment in the notebook for this figure is the following: The rows represent all the black, grizzly, and teddy bears in our dataset, respectively. The columns represent the images which the model predicted as black, grizzly, and teddy bears, respectively. Therefore, the diagonal of the matrix shows the images which were classified correctly, and the off-diagonal cells represent those which were classified incorrectly. This is one of the many ways that fastai allows you to view the results of your model. *It is (of course!) calculated using the validation set*. \n"
      ],
      "metadata": {
        "id": "AaA2DfU8P_9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some specific models for ML"
      ],
      "metadata": {
        "id": "emfh_GZQagkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tabular data"
      ],
      "metadata": {
        "id": "buB1nxDccH5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far all ''from scratch'' examples above (simple linear regression, quadratic regression) dealt with *scalar* inputs, i.e. each example was described by a single number. \n",
        "\n",
        "Examples can also be tabular data, where each example is described by a numeric vector. Formally, the $i$-th example is described by a vector  $(x_{i1}, \\dots, x_{ik})$ of length $k$, for examples $i = 1, \\dots, n$ and labels are $y_1, \\dots,  y_n$  as before.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZxwIpE1oavEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perceptron"
      ],
      "metadata": {
        "id": "AnfcN6V9am9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *perceptron* is one of the simplest models for numerical tabular data and 0/1 classification problems.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1HqHfJn7ejJMGeAa5fTTQzW_myubIDsDh\" width=\"600\" >\n",
        "\n",
        "\n",
        "The model is \n",
        "\n",
        "$$f_{\\rm \\bf w}(x_1,\\dots,x_k)= \\sigma (w_1 \\, x_1 + \\dots + w_k \\, x_k)$$\n",
        "\n",
        "where $\\sigma(.)$ is the activation function, and it is defined by \n",
        "\n",
        "$$\\sigma(z) = \\left\\{\\begin{align}\n",
        "1 &, &  z \\ge t \\\\\n",
        "0 &, &  z < t \\\\\n",
        "\\end{align} \\right.$$\n",
        "\n",
        "where $t$ is some *threshold*.\n"
      ],
      "metadata": {
        "id": "9k6m_gN4aqDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below is an adaptation of the code for simple linear regression, where the examples are tabular data instead of just scalar values, and the classes are 0/1 as in the *Titanic* example in notebook [Lesson5_edited_for_colab_linear_model_and_neural_net_from_scratch.ipynb](Lesson5_edited_for_colab_linear_model_and_neural_net_from_scratch.ipynb).\n",
        "\n",
        "Here, we consider that the input data as already been pre-processed, and all explanatory variables $(x_{i1},\\dots,x_{ik})$ are numerical, while the response variable is $y_i \\in \\{0,1\\}$ for $n$ examples $i=1,\\dots,n$.\n",
        "\n",
        "In matrix form, each row represents one example. For $n$ examples $i=1,\\dots,n$, the following matrices represent the examples and the labels.\n",
        "\n",
        "$\n",
        "\t{\\rm \\bf X}= \\begin{bmatrix} \n",
        "\tx_{11} & \\dots & x_{1k} \\\\\n",
        "\tx_{21} & \\dots & x_{2k} \\\\\n",
        "\t\\dots & \\dots & \\dots\\\\\n",
        "\tx_{n1} & \\dots & x_{nk} \\\\\n",
        "\t\\end{bmatrix}~~~~~~\n",
        "$\n",
        "$\n",
        "\t{\\rm \\bf y}= \\begin{bmatrix} \n",
        "\ty_1  \\\\\n",
        "\ty_2  \\\\\n",
        "\t\\dots \\\\\n",
        "\ty_n  \\\\\n",
        "\t\\end{bmatrix}\n",
        "$\n",
        "\n",
        "Since each example corresponds to a row of ${\\rm \\bf X}$, the $i$-th example is  $(x_{i1},\\dots,x_{ik})$\n",
        "and has label $y_i \\in \\{0,1\\}$. \n",
        "\n",
        "To prevent discontinuities, one can choose instead for $\\sigma(.)$  a continuous function. The usual candidate is the *sigmoid* function\n",
        "\n",
        "$$\\sigma(z)= \\frac{1}{1+e^{-z}}$$\n",
        "\n",
        "that ranges between 0 and 1. This function is available in `pytorch` through `torch.sigmoid`. \n",
        "\n"
      ],
      "metadata": {
        "id": "pfmqoyLshvns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy\n",
        "sympy.plot(\"1/(1+exp(-z))\", xlim=(-5,5));\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "LvOfeyF8X72_",
        "outputId": "99c9e99a-94d4-40ea-9af0-773abb0f12a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code allows you to compare results from multiple linear regression and the perceptron for the Titanic data set problem. Try changing some parameters for gradient descent to see what happens."
      ],
      "metadata": {
        "id": "Pqqx3vIggVT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "torch.manual_seed(42)\n",
        "\n",
        "B=10 # batch size\n",
        "lr = 0.1 # learning rate\n",
        "iter=20 # number epochs\n",
        "\n",
        "############################################ Reading Titanic numerical data, i.e., X and y\n",
        "var_names=['Age', 'SibSp', 'Parch', 'LogFare', 'Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
        "path=Path('/content/drive/MyDrive/AAA/Lesson_5/titanic_data') # adapt to your path\n",
        "X,y=torch.load(path/'titanic_tensor_data_set.ts') # these values are not yet normalized\n",
        "y=y[:,None] # to turn it into a column vector\n",
        "\n",
        "##################################### Create train and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "############################################## Ordinary least squares solution with 0.5 threshold\n",
        "# variables to keep to avoid linear dependencies\n",
        "var_keep=['Age', 'SibSp', 'Parch', 'LogFare', 'Sex_male',  'Pclass_1', 'Pclass_2',  'Embarked_C', 'Embarked_Q']\n",
        "keep=np.isin(var_names,var_keep) # boolean list\n",
        "# \n",
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression().fit(X_train[:,keep], y_train)\n",
        "print('coefficients MLR:',reg.intercept_,reg.coef_)\n",
        "y_pred=reg.predict(X_valid[:,keep])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix(y_valid,(y_pred>0.5)))\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "####################################################### Gradient Descent\n",
        "# if you want to standardize X and include an additional additive coefficient to the model:\n",
        "if False: \n",
        "  means = X.mean(dim=1, keepdim=True)\n",
        "  stds = X.std(dim=1, keepdim=True)\n",
        "  X=normalized_data = (X - means) / stds\n",
        "  # add column of 1s to X\n",
        "  ones=torch.ones(X.shape[0]).reshape(X.shape[0],1)\n",
        "  X=torch.cat((ones,X),1)\n",
        "  X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# initial weights\n",
        "def init_coeffs(n_coeff): return (torch.rand(n_coeff,1)-0.5).requires_grad_() # creates a column matrix\n",
        "\n",
        "# defining the function for prediction: the output is a vector of size=nrows(X)\n",
        "def calc_preds(coeffs,X): return  torch.sigmoid(X@coeffs) # using matrix multiplication (aka matmul)\n",
        "\n",
        "# Computing MSE loss for one batch of exemples: the output is a scalar\n",
        "def calc_loss_from_labels(y_pred, y): return torch.mean((y_pred - y) ** 2)\n",
        "\n",
        "# update coeffs\n",
        "def update_coeffs(coeffs, lr):\n",
        "    coeffs.sub_(coeffs.grad * lr)\n",
        "    # zerofy gradients (because they add up)\n",
        "    coeffs.grad.zero_()\n",
        "\n",
        "# compute initial weights as a column matrix\n",
        "n_coeff = X_train.shape[1] # number of columns of X, or X_train, or X_valid\n",
        "coeffs = init_coeffs(n_coeff)\n",
        "\n",
        "# create lists to store losses for each epoch\n",
        "training_losses=[]; validation_losses=[]\n",
        "\n",
        "# epochs\n",
        "for i in range(iter):\n",
        "  # calculating loss as in the beginning of an epoch and storing it\n",
        "    y_pred = calc_preds(coeffs,X_train)\n",
        "    training_losses.append(calc_loss_from_labels(y_pred, y_train).tolist())\n",
        "    y_pred = calc_preds(coeffs,X_valid)\n",
        "    validation_losses.append(calc_loss_from_labels(y_pred, y_valid).tolist())\n",
        "    # mini-batch gradient descent: weight are updated after each batch\n",
        "    for idx_start in np.arange(0,X_train.shape[0],B):\n",
        "        # create batch\n",
        "        batch_X=X_train[idx_start:(idx_start+B),:]\n",
        "        batch_y=y_train[idx_start:(idx_start+B):]\n",
        "        # making a prediction in forward pass\n",
        "        y_pred = calc_preds(coeffs,batch_X)\n",
        "        # calculating the loss between predicted and actual values\n",
        "        loss = calc_loss_from_labels(y_pred, batch_y)\n",
        "        # compute gradient\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            # update coeffs\n",
        "            update_coeffs(coeffs, lr)\n",
        "\n",
        "# predictions and confusion matrix\n",
        "print('coefficients GD:',torch.flatten(coeffs.requires_grad_(False)))\n",
        "y_pred=calc_preds(coeffs,X_valid)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix(y_valid,(y_pred>0.5)))\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "# plot losses along epochs\n",
        "plt.plot(training_losses, '-g',  validation_losses, '-r')\n",
        "plt.gca().legend(('train','validation'))\n",
        "plt.ylim(0, 1)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss (MSE)')\n",
        "#plt.title(\"Train (green) and validation (red) losses\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v1ufDH1Wareo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "outputId": "dc023b3e-6219-44f9-f6a2-c80b1b13b0c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coefficients MLR: [0.5854171] [[-0.0042809  -0.04922816 -0.03017007  0.05970862 -0.5046148   0.22423151\n",
            "   0.1791499   0.07168674  0.04639366]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coefficients GD: tensor([-0.4428, -0.8563,  0.0372,  0.9528, -0.6359,  0.6533, -0.0090,  0.5945,\n",
            "        -0.0683, -0.1924,  0.3725,  0.0073])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEGCAYAAADxD4m3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXA0lEQVR4nO3debRdZXnH8e/vDiFkIhPEmAQTC8WmWIGmIYilEagMdjXYKoKUsgSLtKLWqYJ2FWuX09JqtSg2AgVbBSPYgi0lmCgFW4QECAiJKREZEjKQ3ARCAskdnv6x9yUnIbl373PPyTnnze+z1l45e7h7P+fexcM77Pd9FRGYmaWordEBmJnVixOcmSXLCc7MkuUEZ2bJcoIzs2R1NDqAShPHt8f0aZ2NDsNK+L+HRzQ6BCvhJbaxM3ZoKPc47c0jY1NXb6Fr7394x8KIOH0ozxuKpkpw06d1ct/CaY0Ow0o47dXHNDoEK+HeWDzke2zs6uXehVMLXds5+ZcTh/zAIWiqBGdmrSDojb5GB1GIE5yZlRJAH60xQMAJzsxK68MlODNLUBB0u4pqZikKoNdVVDNLVau0wflFXzMrJYDeiELbYCRdK2mDpEcqjo2X9CNJj+X/jsuPS9LXJK2S9LCk4wa7vxOcmZXWV3Ar4DpgzxeBLwMWR8SRwOJ8H+AM4Mh8uxi4arCbO8GZWSlB0FtwG/ReEXcBXXscngdcn3++Hjir4vi3I/MzYKykyQPd321wZlZKBHQXb4KbKGlpxf78iJg/yM9Mioi1+ed1wKT88xTg6YrrVufH1rIPTnBmVpLopfBw1o0RMavaJ0VESKq6R8NVVDMrJYC+KLZVaX1/1TP/d0N+fA1QOVh9an5sn5zgzKy03rwUN9hWpVuBC/LPFwC3VBz/07w3dQ7wXEVVdq9cRTWzUrIXfYc049LLJN0AzCVrq1sNXAF8Hlgg6SLgSeDs/PLbgDOBVcB24N2D3d8JzsxKCaA7alP5i4hz93HqlL1cG8D7ytzfCc7MSglEb4u0bjnBmVlpfVGbKmq9OcGZWSm1bIOrNyc4MytJ9NaoDa7enODMrJRsRl8nODNLUITYGe2NDqMQJzgzK63PbXBmlqKsk8FVVDNLkjsZzCxR7mQws6T1+kVfM0tRILqjNVJHa0RpZk3DnQxmlqxArqKaWbrcyWBmSYrAr4mYWZqyTgYP1TKzRLmTwcySFMgTXppZulyCM7MkZeuiOsGZWZKGtObpfuUEZ2alZMsGuhfVzBIUIVdRzSxdftHXzJKUzQfnNjgzS5Jn9DWzRGWvibgEZ2YJ8lhUM0uap0sysyRl0yW5impmiWqVNrjWKGeaWdPIZhNpK7QNRtKHJD0q6RFJN0gaLmmGpHslrZL0PUnDqo3VCc7MSsmGarUV2gYiaQrwAWBWRBwNtAPnAF8AvhIRRwCbgYuqjdVV1Br4+w9N495FYxg7sYf5P1kJwPOb2/nsJdNZv3oYk6bu5JP/9ASjx/by0P+O4lPvnsGrpu0E4MQzt/AnH17fyPCtwqy5z3PJ3z1De1vwXzeMZ8GVkxodUhOq6VCtDuBgSd3ACGAtcDLwrvz89cCngKuquXldS3CSTpe0Mi9qXlbPZzXSW97ZxWe+8/huxxZceRjHvmkr//w/Kzj2TVv53pWHvXzu6ONf4KpFK7lq0UontybS1ha877Nr+OvzZvBnc4/izfO2cPiRLzU6rKbUhwptwERJSyu2i/vvERFrgC8BT5EltueA+4EtEdGTX7YamFJtnHVLcJLaga8DZwAzgXMlzazX8xrp9XO2MXpc727H7ll4CKee3QXAqWd3cc/thzQiNCvhqGO388wTw1j31EH0dLdx5y1jOeG05xodVtPp70UtsgEbI2JWxTa//z6SxgHzgBnAq4GRwOm1jLWeJbjZwKqIeDwidgI3kn2ZA8LmjZ1MmJT9T2j8YT1s3tj58rkV94/kklOP4pPnvZYnVg5vVIi2hwmv6ubZZ3a1Z29c28nEyd0NjKh51aiT4VTgVxHxbER0Az8ATgTGSupvPpsKrKk2znomuCnA0xX7ey1qSrq4v/j67KbePU8nQQIpADji9dv5l/uW881FK5l34bP87YUzGhydWTn9azIU2QbxFDBH0ghJAk4BlgM/Ad6eX3MBcEu1sTa8FzUi5vcXXw+d0BrDP4oYN7GbTeuz/wltWt/B2AlZaW7k6D4OHtkHwOxTttLbLZ7blM73bmWb1nVy6Kt3vrw/cXI3G9d2DvATB6YAeqKt0DbgfSLuBW4CHgB+TpaP5gMfBz4saRUwAbim2ljrmeDWANMq9odU1Gw1c97yPIsWjAdg0YLxL7fldG3oILLCHL94cAR9fTBmfJol11azctkIpszYyaRpO+jo7GPuvC387A63ne5Nrd6Di4grIuJ1EXF0RJwfETvyZq3ZEXFERLwjInZUG2c9XxNZAhwpaQZZYjuHXV2/Sfncn7+Gh+8ZxXNdHZz32zM5/yPreOel6/nMJdO5/cYJHDYle00E4O7/GMt/fHsC7R1w0PA+Lr/qCdQaL4Unr69XfP2TU/jsdx+nrR3uuHE8T/6f20hfoVj1synULcFFRI+kS4GFZC/wXRsRj9breY10+VVP7vX4Fxb88hXH5l24kXkXbqx3SFalJT8ew5Ifj2l0GE3NE17mIuI24LZ6PsPM9r8DvgRnZmnyhJdmlqxA9PQ1/AWMQpzgzKw0t8GZWZrCVVQzS5Tb4MwsaU5wZpakQPS6k8HMUuVOBjNLUriTwcxSFk5wZpYmD7Y3s4S5BGdmSYqA3j4nODNLlHtRzSxJgauoZpYsdzKYWcL61xVpdk5wZlaaq6hmlqSsF9VjUc0sUa6imlmyXEU1syQFcoIzs3S1SA3VCc7MSgoID9Uys1S5impmyWr5XlRJ/8gAVe2I+EBdIjKzppbKWNSl+y0KM2sdAbR6gouI6yv3JY2IiO31D8nMml2rVFEHHW8h6QRJy4Ff5PtvkPSNukdmZk1KRF+xbdA7SWMl3STpF5JW5PlmvKQfSXos/3dctZEWGVD2D8BpwCaAiHgIOKnaB5pZAqLgNrivArdHxOuANwArgMuAxRFxJLA4369KoRGzEfH0Hod6q32gmbW4yDoZimwDkXQIWWHpGoCI2BkRW4B5QH8T2fXAWdWGWiTBPS3pjUBI6pT0UbIsa2YHqtqU4GYAzwL/LOlBSVdLGglMioi1+TXrgEnVhlkkwV0CvA+YAjwDHJPvm9kBSwU3JkpaWrFdXHGTDuA44KqIOBbYxh7V0YgoXtndi0Ff9I2IjcB51T7AzBLUV/jKjRExax/nVgOrI+LefP8msgS3XtLkiFgraTKwodowi/SivlbSDyU9K2mDpFskvbbaB5pZi+t/D67INtBtItaRNYEdlR86BVgO3ApckB+7ALil2lCLDNX6LvB14G35/jnADcDx1T7UzFpbDd+Dez/wHUnDgMeBd5MVvBZIugh4Eji72psXSXAjIuJfKvb/VdLHqn2gmSWgRgkuIpYBe6vCnlKL+w80FnV8/vG/JF0G3Ej2td4J3FaLh5tZi2r1oVrA/WQJrf+bvLfiXACX1ysoM2tuapGhWgONRZ2xPwMxsxYRgpQmvJR0NDATGN5/LCK+Xa+gzKzJtXoJrp+kK4C5ZAnuNuAM4KeAE5zZgapFElyRkQxvJ+vRWBcR7yYbEHtIXaMys+ZWu8H2dVWkivpiRPRJ6pE0huyt4ml1jsvMmlUKE15WWCppLPAtsp7VF4B76hmUmTW3lu9F7RcRf5F//Kak24ExEfFwfcMys6bW6glO0nEDnYuIB+oTkpk1uxRKcH8/wLkATq5xLKx4cRxzlr291re1Oho3en2jQ7AS9EKhOW4H1+ptcBHx5v0ZiJm1iCbpIS3CCz+bWXlOcGaWKhWf8LKhnODMrLwWKcEVmdFXkv5E0t/k+4dLml3/0MysGSmKb41WpEvlG8AJwLn5/layGX7N7EBVgynL94ciVdTjI+I4SQ8CRMTmfHphMztQNUHprIgiCa5bUjv5V5J0KGXW1DGz5DRD9bOIIgnua8C/AYdJ+gzZ7CJ/XdeozKx5RUK9qBHxHUn3k02ZJOCsiPDK9mYHslRKcJIOB7YDP6w8FhFP1TMwM2tiqSQ44D/ZtfjMcGAGsBL4zTrGZWZNLJk2uIh4feV+PsvIX+zjcjOzplF6JENEPCDJq9qbHchSKcFJ+nDFbhtwHPBM3SIys+aWUi8qMLricw9Zm9zN9QnHzFpCCiW4/AXf0RHx0f0Uj5k1OZFAJ4OkjojokXTi/gzIzFpAqyc44D6y9rZlkm4Fvg9s6z8ZET+oc2xm1oyaZKaQIoq0wQ0HNpGtwdD/PlwATnBmB6oEOhkOy3tQH2FXYuvXIvnbzOohhRJcOzCK3RNbvxb5emZWFy2SAQZKcGsj4tP7LRIzaw01XlUrf1tjKbAmIv5A0gzgRmACcD9wfkTsrObeA83o2/jpOM2sKdV4yvIPApUzFH0B+EpEHAFsBi6qNs6BEtwp1d7UzBIXBbdBSJoKvBW4Ot8XWYfmTfkl1wNnVRvmQAs/d1V7UzNLW4mhWhMlLa3Ynx8R8yv2/wH4K3aNmJoAbImInnx/NTCl2ji9bKCZlVOuDW5jRMza2wlJfwBsiIj7Jc2tSWx7cIIzs1JEzRroTwT+UNKZZO/bjgG+CoztH0kFTAXWVPuAIssGmpntrgZtcBFxeURMjYjpwDnAjyPiPOAnZGu/AFwA3FJtmE5wZlZanRd+/jjwYUmryNrkrqn2Rq6imll5NX7RNyLuBO7MPz8OzK7FfZ3gzKycxCa8NDPbXQJDtczM9iqFwfZmZnvnBGdmqXIJzszSFCQx4aWZ2SskseiMmdk+OcGZWaoUrZHhnODMrJwaz+hbT05wZlaa2+DMLFkeqmVm6XIJzsySlNjK9mZmu3OCM7MU+UVfM0ua+lojwznBmVk5fg/uwNS2eicjPr9u1/7abl46fwLdp4zm4M+to21DD32HdbD98lfB6PYGRmoDaWsLvnbzMjauH8anLvnNRofTlFrlNZG6LToj6VpJGyQ9Uq9nNJu+qcN44crDs+2r04jhbXSfMJKDFmym95gRvHD1a+g9ZgTDv7+50aHaAOb96TM89csRjQ6judVoZft6q+eqWtcBp9fx/k2t46EX6XtVJzGpk46fbWPnqdnC3TtPHU3HPdsaHJ3ty8RJO5g9t4uFN01qdChNrc6ratVM3RJcRNwFdNXr/s2u87+30j13FABtW3qJ8VlrQIxrp21LbyNDswG89xOPc80XZ9DXIlWwhgggotjWYA1fF1XSxZKWSlra89z2RodTG91Bx73b6H7TqFeek2q2LLjV1uy5XWzp6mTVo3v5u9lu1Fdsa7SGdzJExHxgPsDIX5/c+JRfAx1Lt9H7awcR47Jfb9/YdtTVQ4zvQF099B3iDoZmNPO455lzche/c9ISOg/qY8SoXj72xZV88WNHNTq0puL34A5wnf/9At2/N/rl/Z45Ixm2aCs7zh7HsEVb6ZkzsoHR2b5c9+XpXPfl6QC8fvYW/vjCNU5ue9Mk1c8iGl5FTc5LfXQ8uJ3uE3clsR3vGEfHg9sZ9Z4n6Vi2nR1nj2tggGZD1yqdDHUrwUm6AZgLTJS0GrgiIq6p1/OaxvA2tn7vtbsdijHtbPvclAYFZNX4+X1j+fl9YxsdRvNqguRVRN0SXEScW697m1ljNUPprAi3wZlZOQH0tkaGc4Izs9JcgjOzdLVIL6oTnJmV1iolOL8mYmblFB1oP0gSlDRN0k8kLZf0qKQP5sfHS/qRpMfyf6t+r8oJzsxKEaDeKLQNogf4SETMBOYA75M0E7gMWBwRRwKL8/2qOMGZWWmKKLQNJCLWRsQD+eetwApgCjAPuD6/7HrgrGrjdBucmZVTbq63iZKWVuzPz8ef70bSdOBY4F5gUkSszU+tA6qeu8oJzsxKKjUWdWNEzBroAkmjgJuBv4yI56Vd0+1EREjVd2m4impmpdVqLKqkTrLk9p2I+EF+eL2kyfn5ycCGauN0gjOz8mow4aWyoto1wIqI+HLFqVuBC/LPFwC3VBumq6hmVk5QpIe0iBOB84GfS1qWH/sE8HlggaSLgCeBs6t9gBOcmZVXg/wWET9l3/NbnzL0JzjBmVkVBnsFpFk4wZlZeU5wZpakAJpgQZkinODMrBQx+CiFZuEEZ2bltcjCsU5wZlaOq6hmljJXUc0sXU5wZpam1ln42QnOzMrxqlpmljK3wZlZupzgzCxJAfQ5wZlZktzJYGYpc4IzsyQF0NsaQxmc4MyspIBwgjOzVLmKamZJci+qmSXNJTgzS5YTnJklKQJ6exsdRSFOcGZWnktwZpYsJzgzS1O4F9XMEhUQftHXzJLloVpmlqQILxtoZglzJ4OZpSpcgjOzNHnCSzNLlQfbm1mqAogWGarV1ugAzKzFRD7hZZFtEJJOl7RS0ipJl9U6VJfgzKy0qEEVVVI78HXg94HVwBJJt0bE8iHfPOcSnJmVV5sS3GxgVUQ8HhE7gRuBebUMU9FEvSGSngWebHQcdTAR2NjoIKyUVP9mr4mIQ4dyA0m3k/1+ihgOvFSxPz8i5uf3eTtwekS8J98/Hzg+Ii4dSnyVmqqKOtRffLOStDQiZjU6DivOf7N9i4jTGx1DUa6imlmjrAGmVexPzY/VjBOcmTXKEuBISTMkDQPOAW6t5QOaqoqasPmNDsBK89+sziKiR9KlwEKgHbg2Ih6t5TOaqpPBzKyWXEU1s2Q5wZlZspzg6qjew1Cs9iRdK2mDpEcaHYsNnRNcnVQMQzkDmAmcK2lmY6OyAq4DWuY9LxuYE1z91H0YitVeRNwFdDU6DqsNJ7j6mQI8XbG/Oj9mZvuJE5yZJcsJrn7qPgzFzAbmBFc/dR+GYmYDc4Krk4joAfqHoawAFtR6GIrVnqQbgHuAoyStlnRRo2Oy6nmolpklyyU4M0uWE5yZJcsJzsyS5QRnZslygjOzZDnBtRBJvZKWSXpE0vcljRjCva7LVzVC0tUDTQQgaa6kN1bxjCckvWL1pX0d3+OaF0o+61OSPlo2RkubE1xreTEijomIo4GdwCWVJyVVNQV9RLxnkMV25wKlE5xZoznBta67gSPy0tXdkm4Flktql/RFSUskPSzpvQDKXJnPT7cIOKz/RpLulDQr/3y6pAckPSRpsaTpZIn0Q3np8XclHSrp5vwZSySdmP/sBEl3SHpU0tWABvsSkv5d0v35z1y8x7mv5McXSzo0P/Zrkm7Pf+ZuSa+ryW/TkuRFZ1pQXlI7A7g9P3QccHRE/CpPEs9FxO9IOgj4H0l3AMcCR5HNTTcJWA5cu8d9DwW+BZyU32t8RHRJ+ibwQkR8Kb/uu8BXIuKnkg4nG63xG8AVwE8j4tOS3goUGQVwYf6Mg4Elkm6OiE3ASGBpRHxI0t/k976UbDGYSyLiMUnHA98ATq7i12gHACe41nKwpGX557uBa8iqjvdFxK/y428Bfqu/fQ04BDgSOAm4ISJ6gWck/Xgv958D3NV/r4jY17xopwIzpZcLaGMkjcqf8Uf5z/6npM0FvtMHJL0t/zwtj3UT0Ad8Lz/+r8AP8me8Efh+xbMPKvAMO0A5wbWWFyPimMoD+X/o2yoPAe+PiIV7XHdmDeNoA+ZExEt7iaUwSXPJkuUJEbFd0p3A8H1cHvlzt+z5OzDbF7fBpWch8OeSOgEk/bqkkcBdwDvzNrrJwJv38rM/A06SNCP/2fH58a3A6Irr7gDe378j6Zj8413Au/JjZwDjBon1EGBzntxeR1aC7NcG9JdC30VW9X0e+JWkd+TPkKQ3DPIMO4A5waXnarL2tQfyhVP+iayk/m/AY/m5b5PNmLGbiHgWuJisOvgQu6qIPwTe1t/JAHwAmJV3YixnV2/u35IlyEfJqqpPDRLr7UCHpBXA58kSbL9twOz8O5wMfDo/fh5wUR7fo3gaeBuAZxMxs2S5BGdmyXKCM7NkOcGZWbKc4MwsWU5wZpYsJzgzS5YTnJkl6/8B++0XmJeemQEAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feed-forward fully connected neural network with ReLu units"
      ],
      "metadata": {
        "id": "O0Bsy-6bLa-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to add more layers to the model. Instead of having just one output from the first (input) layer, the model can have many units in the following *hidden* layers. In general, the number of model outputs (output layer) is equal to the number of labels (one is enough for the Titanic problem, since the prediction is just \"survived\" or not). As mentioned earlier, typically there is either a *sigmoid* unit or a *softmax* layer to complete the model, so the final outputs can be interpreted as probabilities.\n",
        "\n",
        "This model is also known as the *Multilayer Perceptron* (MLP).\n",
        "\n",
        "If all the intermediate layers would just multiply inputs by weights, the model could be reduced to a single matrix multiplication layer. Therefore, there must some non-linearity after each matrix multiplication. That's what is described in the following figure, where $f$ represents some non-linear *activation function* for each layer of the neural network.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Ky82nfC7GUp7YBqp1Spzn9aHDrTzbiCH\" width=\"600\" >\n",
        "\n",
        "The layer is called *fully connected* when each matrix multiplication, which returns the dot product $x_1 \\, w_1 + \\dots + x_n \\, w_n$ envolves all neurons from the previous layer. \n",
        "\n",
        "Typically, all activation functions ($f$ in the figure above) for the *hidden layers* are called rectified linear units (*ReLu*) and they represent the following continuous function, which is the identity function for positive arguments and *zero* for negative arguments.\n",
        "\n",
        "${\\rm ReLu}(z) = \\left\\{\\begin{align}\n",
        "z &, &  z \\ge 0 \\\\\n",
        "0 &, &  z < 0 \\\\\n",
        "\\end{align} \\right.$\n",
        "\n",
        "If there is only one output, the activation layer for the *output layer* is typically the *sigmoid* function. If there is more than one output (as in the figure above), the typical choice of activation function for the output layer is the *softmax* function.\n",
        "\n",
        "For first *neuron* in the first hidden unit, the calculation goes exactely as  we discussed for the perceptron model, where the inputs are multiplied by the  weights $w_1^{(1)},\\dots, w_4^{(1)}$ to return\n",
        "\n",
        "$$w_1^{(1)} \\, x_1 + w_2^{(1)} \\, x_2 + w_3^{(1)} \\, x_3 + w_4^{(1)} \\, x_4 .$$\n",
        "\n",
        "The same product is computed for the second neuron of the first hidden layer, but for a *different set of weights* $w_1^{(2)},\\dots, w_4^{(2)}$, and so on. Hence, in total there are for the example in the figure above, 12 multiplicative weights (4 input variables $\\times$ 3 neuros in the hidden layer). The three multiplications (for the three neurns in the hidden layer) can all be done with a single matrix multiplication:\n",
        "\n",
        "If the weights and input values are  $~~~~~\n",
        "\t{\\rm W}= \\begin{bmatrix} \n",
        "\tw_{1}^{(1)} & w_{2}^{(1)} & w_{3}^{(1)} & w_{4}^{(1)} \\\\\n",
        "\tw_{1}^{(2)} & w_{2}^{(2)} & w_{3}^{(2)} & w_{4}^{(2)} \\\\\n",
        "\tw_{1}^{(3)} & w_{2}^{(3)} & w_{3}^{(3)} & w_{4}^{(3)} \\\\\n",
        "\t\\end{bmatrix}~~~{\\rm and}~~~~\n",
        "$\n",
        "$\n",
        "\t{\\rm x}= \\begin{bmatrix} \n",
        "\tx_1  \\\\\n",
        "\tx_2 \\\\\n",
        "\tx_3  \\\\\n",
        "\tx_4  \\\\\n",
        "\t\\end{bmatrix}~~~\n",
        "$\n",
        "\n",
        "then, the hidden layer three outputs (before applying the activation function) are just the rows of the product ${\\rm W} \\, {\\rm x}$:\n",
        "\n",
        "$$ {\\rm  W} \\, {\\rm x}= \\begin{bmatrix} \n",
        "\tw_1^{(1)} \\, x_1 + w_2^{(1)} \\, x_2 + w_3^{(1)} \\, x_3 + w_4^{(1)} \\, x_4  \\\\\n",
        "\tw_1^{(2)} \\, x_1 + w_2^{(2)} \\, x_2 + w_3^{(2)} \\, x_3 + w_4^{(2)} \\, x_4  \\\\\n",
        "\tw_1^{(3)} \\, x_1 + w_2^{(3)} \\, x_2 + w_3^{(3)} \\, x_3 + w_4^{(3)} \\, x_4  \\\\\n",
        "\t\\end{bmatrix}\n",
        ".$$\n",
        "\n",
        "This is very convenient since matrix multiplication can be computed quickly.\n",
        "\n",
        "Note that it is usual to include also an *additive weight* for each neuron (this is called the *bias*). Without lost of generality, we can think that $x_1$ is an artificial input which value is always 1, and therefore $w_1^{(j)} \\times x_1=w_1^{(j)}$ is the additive weight. In alternative, we can add a weight $w_0^{(j)}$ to each neuron, so the neuron output (before applying the activation function) is \n",
        "\n",
        "$$w_0^{(1)} + w_1^{(1)} \\, x_1 + w_2^{(1)} \\, x_2 + w_3^{(1)} \\, x_3 + w_4^{(1)} \\, x_4 $$\n",
        "\n",
        "in the above example.\n",
        "\n",
        "Putting everything together, the three outputs of the first hidden layer are:\n",
        "\n",
        "$$\n",
        "\t {\\rm ReLu} \\left(w_0^{(1)} + w_1^{(1)} \\, x_1 + w_2^{(1)} \\, x_2 + w_3^{(1)} \\, x_3 + w_4^{(1)} \\, x_4 \\right)  \\\\\n",
        "   {\\rm ReLu} \\left(w_0^{(2)} + w_1^{(2)} \\, x_1 + w_2^{(2)} \\, x_2 + w_3^{(2)} \\, x_3 + w_4^{(2)} \\, x_4 \\right)  \\\\\n",
        " {\\rm ReLu} \\left(w_0^{(3)} + w_1^{(3)} \\, x_1 + w_2^{(3)} \\, x_2 + w_3^{(3)} \\, x_3 + w_4^{(3)} \\, x_4 \\right)  \\\\\n",
        "$$\n",
        "\n",
        "Then, calculations proceed to the following layer, and so on, until they reach  the output layer. This network is called *feed-forward* because computations are done sequentially layer by layer.\n",
        "\n"
      ],
      "metadata": {
        "id": "LVVVxdMRMEyV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image classification"
      ],
      "metadata": {
        "id": "CD6hFZ18NweS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolutional neural networks for image classification"
      ],
      "metadata": {
        "id": "6mQQM1QvFPZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a detailed overview of convolutional neural networks see the notebook that includes `pytorch`code for computing covolutions:  https://github.com/fastai/fastbook/blob/master/13_convolutions.ipynb. Some concepts and examples from that notebook are included in the text below."
      ],
      "metadata": {
        "id": "1yIjopNB75t9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convolutions and kernels"
      ],
      "metadata": {
        "id": "HPga1DGR_h4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A convolution applies a kernel across an image. A kernel is a little matrix, such as the 3Ã—3 matrix below. The 7Ã—7 grid to the left is the image we're going to apply the kernel to. The convolution operation multiplies each element of the kernel by each element of a 3Ã—3 block of the image. The results of these multiplications are then added together. The diagram  shows an example of applying a kernel to a single location in the image, the 3Ã—3 block around cell 18."
      ],
      "metadata": {
        "id": "De9r08q58Jf_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm9ZH_4P7sgM"
      },
      "source": [
        "<img src=\"https://github.com/fastai/fastbook/blob/master/images/chapter9_conv_basic.png?raw=1\" id=\"basic_conv\" caption=\"Applying a kernel to one location\" alt=\"Applying a kernel to one location\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HytpwvII7sga"
      },
      "source": [
        "In the paper [\"A Guide to Convolution Arithmetic for Deep Learning\"](https://arxiv.org/abs/1603.07285) there are many great diagrams showing how image kernels can be applied. Here's an example from the paper showing (at the bottom) a light blue 4Ã—4 image, with a dark blue 3Ã—3 kernel being applied, creating a 2Ã—2 green output activation map at the top. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM0gl8pN7sga"
      },
      "source": [
        "<img alt=\"Result of applying a 3Ã—3 kernel to a 4Ã—4 image\" width=\"782\" caption=\"Result of applying a 3Ã—3 kernel to a 4Ã—4 image (courtesy of Vincent Dumoulin and Francesco Visin)\" id=\"three_ex_four_conv\" src=\"https://github.com/fastai/fastbook/blob/master/images/att_00028.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZTVi15h7sga"
      },
      "source": [
        "What is the shape of the result? If the original image has a height of `h` and a width of `w`, how many 3Ã—3 windows can we find? As you can see from the example, there are `h-2` by `w-2` windows, so the image we get has a result as a height of `h-2` and a width of `w-2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx_3HUel_N6i"
      },
      "source": [
        "#### Padding, pooling, stride and activation map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhvgNqbz_N6j"
      },
      "source": [
        "**Padding** consists in creating new cells on th emargins of the input, with a given value (in general 0). With appropriate padding, we can ensure that the output **activation map** is the same size as the original image, which can make things a lot simpler when we construct our architectures. The figure below shows how adding padding allows us to apply the kernels in the image corners."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwuyrTB3_N6j"
      },
      "source": [
        "<img src=\"https://github.com/fastai/fastbook/blob/master/images/chapter9_padconv.svg?raw=1\" id=\"pad_conv\" caption=\"A convolution with padding\" alt=\"A convolution with padding\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBonLNgi_N6k"
      },
      "source": [
        "With a 5Ã—5 input, 4Ã—4 kernel, and 2 pixels of padding, we end up with a 6Ã—6 activation map:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZs6pyQO_N6k"
      },
      "source": [
        "<img alt=\"A 4Ã—4 kernel with 5Ã—5 input and 2 pixels of padding\" width=\"783\" caption=\"A 4Ã—4 kernel with 5Ã—5 input and 2 pixels of padding (courtesy of Vincent Dumoulin and Francesco Visin)\" id=\"four_by_five_conv\" src=\"https://github.com/fastai/fastbook/blob/master/images/att_00029.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBr61m-P_N6l"
      },
      "source": [
        "If we add a kernel of size `ks` by `ks` (with `ks` an odd number), the necessary padding on each side to keep the same shape is `ks//2`. An even number for `ks` would require a different amount of padding on the top/bottom and left/right, but in practice we almost never use an even filter size.\n",
        "\n",
        "**Stride**. So far, when we have applied the kernel to the grid, we have moved it one pixel over at a time. But we can jump further; for instance, we could move over two pixels after each kernel application, as in the figure below. This is known as a *stride-2* convolution. The most common kernel size in practice is 3Ã—3, and the most common padding is 1. As you'll see, **stride-2** convolutions are useful for decreasing the size of our outputs, and **stride-1** convolutions are useful for adding layers without changing the output size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1cu9Gle_N6m"
      },
      "source": [
        "<img alt=\"A 3Ã—3 kernel with 5Ã—5 input, stride-2 convolution, and 1 pixel of padding\" width=\"774\" caption=\"A 3Ã—3 kernel with 5Ã—5 input, stride-2 convolution, and 1 pixel of padding (courtesy of Vincent Dumoulin and Francesco Visin)\" id=\"three_by_five_conv\" src=\"https://github.com/fastai/fastbook/blob/master/images/att_00030.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFr3YGMP_N6m"
      },
      "source": [
        "In an image of size `h` by `w`, using a padding of 1 and a stride of 2 will give us a result of size `(h+1)//2` by `(w+1)//2`. The general formula for each dimension is `(n + 2*pad - ks)//stride + 1`, where `pad` is the padding, `ks`, the size of our kernel, and `stride` is the stride.\n",
        "\n",
        "**Pooling** is a type of convolution with a fixed operation (not trainable) as illustrated in the example below. This can be used to reduce the size of a layer. However, pooling can be replaced by convolution with stride larger than 1 (see paper \"Striving for Simplicity: The All Convolutional Net\" at https://arxiv.org/abs/1412.6806). \n",
        "\n",
        "<img src=\"https://epynn.net/_images/pool-01.svg\"  width=\"600\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example with MNIST data set (\"3\" and \"7\" digits)"
      ],
      "metadata": {
        "id": "9zSYuXnzG8Wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "matplotlib.rc('image', cmap='Greys')\n",
        "path = untar_data(URLs.MNIST_SAMPLE) # MNIST_SAMPLE only contains digits 3 and 7\n",
        "path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgkMU1q_HCNp",
        "outputId": "3dd816f4-d079-4232-99d9-f9683efbb223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/.fastai/data/mnist_sample')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im3 = Image.open(path/'train'/'3'/'12.png')\n",
        "show_image(im3);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "GLSo4CFxHbto",
        "outputId": "1ffc776a-53f7-4417-fc9f-9a7685e7c6ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataloaders (dls)\n",
        "mnist = DataBlock((ImageBlock(cls=PILImageBW), CategoryBlock), \n",
        "                  get_items=get_image_files, \n",
        "                  splitter=GrandparentSplitter(),\n",
        "                  get_y=parent_label)\n",
        "\n",
        "dls = mnist.dataloaders(path)\n",
        "xb,yb = first(dls.valid)\n",
        "# By default, fastai puts data on the GPU when using data blocks. Let's move it to the CPU for our examples:\n",
        "xb,yb = to_cpu(xb),to_cpu(yb)\n",
        "xb.shape # batch size, number of channels, number of rows, number of columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctAiH9amHySA",
        "outputId": "ddfc9d14-1d10-43c1-a5de-3d36d021a345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a simple CNN from scratch"
      ],
      "metadata": {
        "id": "4cLf5yYEKCei"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgF4HmK97sgo"
      },
      "source": [
        "We will create a CNN from scratch with `nn.Conv2d`. First, we'll define a function with the basic parameters we'll use in each convolution. Each layer receives `ni` channels of input and produces `nf` output features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N6_WTVu7sgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3536a732-1730-4ebb-9f07-7e4c7590feea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# ni and nf are the number of input and output channels (also called output features)\n",
        "def conv(ni, nf, ks=3, act=True):\n",
        "    res = nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)\n",
        "    if act: res = nn.Sequential(res, nn.ReLU())\n",
        "    return res\n",
        "\n",
        "# build CNN:\n",
        "simple_cnn = sequential(\n",
        "    conv(1 ,4),            #14x14\n",
        "    conv(4 ,8),            #7x7\n",
        "    conv(8 ,16),           #4x4\n",
        "    conv(16,32),           #2x2\n",
        "    conv(32,2, act=False), #1x1\n",
        "    Flatten(),\n",
        ")\n",
        "simple_cnn(xb).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, overall, the model's input (`batch`, `channel`, `height`, `width`) is a batch of 64 examples of 1-channel images with 28 rows and columns, and outputs two activations, which map to the two possible levels in our labels. \n",
        "\n",
        "We can now create the `learner`, and look at its structure with `summary`.\n"
      ],
      "metadata": {
        "id": "mPCSTnSbLptM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, simple_cnn, loss_func=F.cross_entropy, metrics=accuracy)\n",
        "learn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "ECGpSRWkM4ng",
        "outputId": "2b1eb4da-dc5b-4df4-dff1-fa829c923032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential (Input shape: 64 x 1 x 28 x 28)\n",
              "============================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "============================================================================\n",
              "                     64 x 4 x 14 x 14    \n",
              "Conv2d                                    40         True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     64 x 8 x 7 x 7      \n",
              "Conv2d                                    296        True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     64 x 16 x 4 x 4     \n",
              "Conv2d                                    1168       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     64 x 32 x 2 x 2     \n",
              "Conv2d                                    4640       True      \n",
              "ReLU                                                           \n",
              "____________________________________________________________________________\n",
              "                     64 x 2 x 1 x 1      \n",
              "Conv2d                                    578        True      \n",
              "____________________________________________________________________________\n",
              "                     64 x 2              \n",
              "Flatten                                                        \n",
              "____________________________________________________________________________\n",
              "\n",
              "Total params: 6,722\n",
              "Total trainable params: 6,722\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: <function Adam at 0x7f2b59a85c10>\n",
              "Loss function: <function cross_entropy at 0x7f2b6cd19c10>\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - CastToTensor\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(2, 0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Nmyv44o5NbeK",
        "outputId": "266b1728-7531-44d7-feed-e65831020d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.072641</td>\n",
              "      <td>0.039753</td>\n",
              "      <td>0.985280</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.030240</td>\n",
              "      <td>0.031761</td>\n",
              "      <td>0.989696</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Weights and bias parameters"
      ],
      "metadata": {
        "id": "1VqJ9dVKS39v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NJiUPV47sgv"
      },
      "source": [
        "The number of parameters depend on the kernel size, the number of input channels and the number of output features. Each convolution applies over the kernel and the input channels. There will be one convolution per output feature. The number of multiplicative weights per convolution is therefore `ni*ks*ks`. If there is an additive weight (bias) that will add one more parameter per convolution. Finally, the number of parameters `ni*ks*ks+1`must be multiplied by the number `nf` of output fatures. \n",
        "\n",
        "The summary shows we have 40 parameters for the first convolution, which is  `nf*(ni*ks*ks+1)=4*(1*3*3+1)`. Four of those parameters are for the bias."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = learn.model[0] # first layer\n",
        "print(m)\n",
        "print(m[0].weight.shape)\n",
        "print(m[0].bias.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZfYnATzS7aL",
        "outputId": "174231c6-6419-4706-8b41-a36c89ad5d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            ")\n",
            "torch.Size([4, 1, 3, 3])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPEjZ_ch7sgx"
      },
      "source": [
        "Similarly, for the second convolution, the depth of the input is `4`, the kernel is `3x3` which means that there are `4*3*3` multiplicative weights and `1` additive weight (bias) per output feature. Since the depth (`nf`=number output features) is 8, then, in total there are `8*(4*3*3+1)=296` parameters.\n",
        "\n",
        "We can now use this information to clarify the statement : \"When we use a stride-2 convolution, we often increase the number of features because we're decreasing the number of activations in the activation map by a factor of 4; we don't want to decrease the capacity of a layer by too much at a time.\"\n",
        "\n",
        "There is one bias for each channel. (Sometimes channels are called *features* or *filters* when they are not input channels.) The output shape is `64x4x14x14`, and this will therefore become the input shape to the next layer. The next layer, according to `summary`, has 296 parameters. Let's ignore the batch axis to keep things simple. So for each of `14*14=196` locations we are multiplying `296-8=288` weights (ignoring the bias for simplicity), so that's `196*288=56448` multiplications at this layer. The next layer will have `7*7*(1168-16)=56448` multiplications.\n",
        "\n",
        "What happened here is that our stride-2 convolution halved the *grid size* from `14x14` to `7x7`, and we doubled the *number of filters* from 8 to 16, resulting in no overall change in the amount of computation. If we left the number of channels the same in each stride-2 layer, the amount of computation being done in the net would get less and less as it gets deeper. But we know that the deeper layers have to compute semantically rich features (such as eyes or fur), so we wouldn't expect that doing *less* computation would make sense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1QsEp5T7sgx"
      },
      "source": [
        "#### Receptive Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5xAPJ5_7sgx"
      },
      "source": [
        "The *receptive field* is the area of an image that is involved in the calculation of a layer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-m_ec6O7sgy"
      },
      "source": [
        "<img alt=\"Secondary precedents of conv2 layer\" width=\"700\" caption=\"Secondary precedents of Conv2 layer\" id=\"preced2\" src=\"https://github.com/fastai/fastbook/blob/master/images/att_00069.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSJE4WSl7sgy"
      },
      "source": [
        "In this example, we have just two convolutional layers, each of stride 2, so this is now tracing right back to the input image. We can see that a 7Ã—7 area of cells in the input layer is used to calculate the single green cell in the Conv2 layer. This 7Ã—7 area is the *receptive field* in the input of the green activation in Conv2. We can also see that a second filter kernel is needed now, since we have two layers.\n",
        "\n",
        "As you see from this example, the deeper we are in the network (specifically, the more stride-2 convs we have before a layer), the larger the receptive field for an activation in that layer. A large receptive field means that a large amount of the input image is used to calculate each activation in that layer is. We now know that in the deeper layers of the network we have semantically rich features, corresponding to larger receptive fields. Therefore, we'd expect that we'd need more weights for each of our features to handle this increasing complexity. This is another way of saying the same thing we mentioned in the previous section: when we introduce a stride-2 conv in our network, we should also increase the number of channels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GwmVyTf7shD"
      },
      "source": [
        "#### Batch Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HarhfRxO7shD"
      },
      "source": [
        "Batch normalization  tries to maintain a good distribution of activations throughout training.\n",
        "\n",
        "Sergey Ioffe and Christian Szegedy presented a solution to this problem in the 2015 paper [\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\"](https://arxiv.org/abs/1502.03167). In the abstract, they describe just the problem that we've seen:\n",
        "\n",
        "> : Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization... We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs.\n",
        "\n",
        "Their solution, they say is:\n",
        "\n",
        "> : Making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrvY5kiK7shD"
      },
      "source": [
        "Batch normalization (often just called *batchnorm*) works by taking an average of the mean and standard deviations of the activations of a layer and using those to normalize the activations. However, this can cause problems because the network might want some activations to be really high in order to make accurate predictions. So they also added two learnable parameters (meaning they will be updated in the SGD step), usually called `gamma` and `beta`. After normalizing the activations to get some new activation vector `y`, a batchnorm layer returns `gamma*y + beta`.\n",
        "\n",
        "That's why  activations can have any mean or variance, independent from the mean and standard deviation of the results of the previous layer. Those statistics are learned separately, making training easier on our model. The behavior is different during training and validation: during training, we use the mean and standard deviation of the batch to normalize the data, while during validation we instead use a running mean of the statistics calculated during training.\n",
        "\n",
        "Let's add a batchnorm layer to `conv` and fit again the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8L7F0un07shD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "65f7da3a-078d-4227-fa05-4b242513c83e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.019299</td>\n",
              "      <td>0.015921</td>\n",
              "      <td>0.993621</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.005612</td>\n",
              "      <td>0.009632</td>\n",
              "      <td>0.997056</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def conv(ni, nf, ks=3, act=True):\n",
        "    layers = [nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)]\n",
        "    if act: layers.append(nn.ReLU())\n",
        "    layers.append(nn.BatchNorm2d(nf))\n",
        "    return nn.Sequential(*layers)\n",
        "    \n",
        "learn.fit_one_cycle(2, 0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CNN as Encoders"
      ],
      "metadata": {
        "id": "uSJ_lA-7OKk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeNet (1998) to VGG-net (2015) are two examples of convolutional neural networks for image classification. Typically, they have an input layer which is a tensor that represents an image with dimension *(number rows, number columns, number channels)*, followed by sets of *convolutional* layers, *ReLu* layers, and *pooling* layers, and at the end they have a couple of   *fully connected layers*  followed by a *sofwmax* or a *sigmoid layer*.\n",
        "\n",
        "LeNet: \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1-Nxj4sRWiWmjWcPgVnqcoSItiuJo38oH\" width=\"700\" >\n",
        "\n",
        "\n",
        "VGG-net: \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1hoR6Qxda7Ls0VsY-xAzSz1ddlL6IEAnT\" width=\"700\" >\n",
        "\n",
        "\n",
        "\n",
        "Those kind of networks exhibit the following structure:\n",
        "1.  reduction of width and height dimensions of input through each layer in this network; \n",
        "2. accompanied by an organized increment in the number of channels in each layer.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aSMVUgTnFVz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resnets"
      ],
      "metadata": {
        "id": "wXks4Spcd0W7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diagram that describes `resnet18`. The arrows represent the application of the identity function. That architecture, proposed in https://arxiv.org/abs/1512.03385, reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. Those residual networks are easier to optimize, and can gain accuracy from considerably increased depth.\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Sajid-Iqbal-13/publication/336642248/figure/fig1/AS:839151377203201@1577080687133/Original-ResNet-18-Architecture_W640.jpg\" width=\"700\" >"
      ],
      "metadata": {
        "id": "ggmRGNdnhZI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolutional neural networks for image segmentation: the encoder/decoder model"
      ],
      "metadata": {
        "id": "oa7bw6mYcSIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "U-nets (https://arxiv.org/abs/1505.04597) are a kind of neural networks used for image segmentation which has an encoder that converts input into a small but with nany channels, followed by a decoder that generates a output with the same number of rows and columns as the input. The output is the predicted segmentation of the input image.\n",
        "\n",
        "\n",
        "<img src=\"https://www.frontiersin.org/files/Articles/841297/fnagi-14-841297-HTML-r2/image_m/fnagi-14-841297-g001.jpg\" width=\"700\" >\n",
        "\n",
        "This approach for image segmentation can be applied to large images by an *overlap-tile strategy* as illustrated by Figure 2 in https://arxiv.org/abs/1505.04597:  \n",
        "\n",
        "<img src=\"https://github.com/isa-ulisboa/greends-pml/blob/main/images/overlap-tile-strategy-U-net-paper-2015.png?raw=1\" width=\"700\" >\n",
        "\n",
        "\n",
        "A commented example of the use of a U-Net to segment self-driving cars street photos is available at [Image_Segmentation_with_Unet.ipynb](Image_Segmentation_with_Unet.ipynb).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UhlpjU4PkXF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision trees"
      ],
      "metadata": {
        "id": "gnji-_ie0Ta4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `DecisionTreeClassifier` class in `scikit-learn` allows you to choose from several criteria to measure the quality of a split. The available criteria for *classification trees* are:\n",
        "\n",
        "1. `gini`: This is the default criterion and it measures the impurity of a set of samples as the probability of misclassifying a randomly chosen element from the set: $G = 1 - \\sum_{i=1}^n p_i^2$, where $p_i$ is the probability of belonging to the $i$th class.\n",
        "2. `entropy`: This criterion measures the impurity of a set of samples as the amount of information gained about the class variable from observing the features: $E=-\\sum_{i=1}^n p_i \\log_2 p_i$.\n",
        "\n",
        "Both measures range from 0 (minimum impurity, maximum certainty) to 1 (maximum impurity, minimum certainty). \n",
        "\n",
        "The reduction in entropy resulting from a split can be considered a measure of the gain in information, and this gain in information can be interpreted as a reduction in the *loss* of the model. In this sense, the reduction in entropy resulting from a split can be viewed as a loss measure, with the goal being to *minimize the loss* by finding the split that results in the greatest reduction in entropy.\n",
        "\n",
        "The loss function is calculated separately for each subset resulting from the split, and the *total loss* is the weighted sum of the losses of the subsets, where the weights are the fractions of samples in each subset. The split with the lowest total loss (i.e., the greatest reduction in entropy) is chosen as the best split. The expression for the loss of a split is the following, where instead of the entropy ($E$) one could use the Gini criterion $G$.\n",
        "\n",
        "$$L = \\frac{n_{\\rm left}}{n} \\times E_{\\rm left} + \\frac{n_{\\rm right}}{n} \\times E_{\\rm right}$$\n",
        "\n",
        "For *regression trees* the criteria are `mse`and `mae`."
      ],
      "metadata": {
        "id": "LoCk_P6M0W6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn import tree\n",
        "from matplotlib import pyplot as plt\n",
        "iris = load_iris()\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "print(iris.target_names)\n",
        "\n",
        "#build decision tree\n",
        "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4,min_samples_leaf=4)\n",
        "#max_depth represents max level allowed in each tree, min_samples_leaf minumum samples storable in leaf node\n",
        "\n",
        "#fit the tree to iris dataset\n",
        "clf.fit(X,y)\n",
        "\n",
        "#plot decision tree\n",
        "fig, ax = plt.subplots(figsize=(10, 10)) #figsize value changes the size of plot\n",
        "tree.plot_tree(clf,ax=ax,feature_names=['sepal length','sepal width','petal length','petal width'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J8nrDgCb0fBw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}