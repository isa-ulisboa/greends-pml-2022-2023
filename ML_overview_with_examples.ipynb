{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMkDVYEOmSrKH3AXhF7Uu/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "287b831a2015472ca1ad96be2344a838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5037df45e75347b999912f5ff8148050",
              "IPY_MODEL_242053e6c5fe49e9b821e592142baa86",
              "IPY_MODEL_0294731999604d828d2f6db099524643",
              "IPY_MODEL_b56866f8cd04425090c8847432d99030"
            ],
            "layout": "IPY_MODEL_0ad66d52b29b4132880bc2c3878bb0cc"
          }
        },
        "5037df45e75347b999912f5ff8148050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": true,
            "description": "a",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7eb98727910e4732a7a0961c9024160c",
            "max": 3.3000000000000003,
            "min": -1.1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".2f",
            "step": 0.1,
            "style": "IPY_MODEL_6fb1bc9c4e4940fea7bd973249e4c294",
            "value": 2.5
          }
        },
        "242053e6c5fe49e9b821e592142baa86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": true,
            "description": "b",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_468087a33c8d482bb2cd7bdbe0ab01c5",
            "max": 3.3000000000000003,
            "min": -1.1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".2f",
            "step": 0.1,
            "style": "IPY_MODEL_af0c9f2494794d8faf9647863eb50e61",
            "value": 1.1
          }
        },
        "0294731999604d828d2f6db099524643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": true,
            "description": "c",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_cdd35afc8efb4be9ae8fd575d1009bc5",
            "max": 3.3000000000000003,
            "min": -1.1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".2f",
            "step": 0.1,
            "style": "IPY_MODEL_454e8a074fa54e4c93a2e75e611c5e13",
            "value": 1.1
          }
        },
        "b56866f8cd04425090c8847432d99030": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_003db380868741ce917469e6dd6b746d",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<Figure size 432x288 with 1 Axes>",
                  "image/png": "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\n"
                },
                "metadata": {
                  "needs_background": "light"
                }
              }
            ]
          }
        },
        "0ad66d52b29b4132880bc2c3878bb0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb98727910e4732a7a0961c9024160c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb1bc9c4e4940fea7bd973249e4c294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "468087a33c8d482bb2cd7bdbe0ab01c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af0c9f2494794d8faf9647863eb50e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "cdd35afc8efb4be9ae8fd575d1009bc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "454e8a074fa54e4c93a2e75e611c5e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "003db380868741ce917469e6dd6b746d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isa-ulisboa/greends-pml/blob/main/ML_overview_with_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical Machine Learning**\n",
        "\n",
        "Masters in Green Data Science, ISA/ULisboa, 2022-2023\n",
        "\n",
        "Instructor: Manuel Campagnolo mlc@isa.ulisboa.pt"
      ],
      "metadata": {
        "id": "f0qoqpJ4-iom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction and some basic concepts in Machine Learning (ML)\n",
        "\n",
        "In this course we are dealing with data sets of *labeled examples*. Examples can be scalar numbers, rows of tabular data, images, etc. For tabular data, we refer the to columns as *explanatory variables* (sometimes also called *independent* or *descriptive* variables).\n",
        "\n",
        "Labels can be categorical, ordinal or continuous. Labels can be refered to as the *response variable* (or *dependent* variable). They are also called *targets*. Typically, we the problems are called:\n",
        "1. *Regression problems*, when the labels are continuous. \n",
        "2. *Classification problems*, when the labels are categorical.\n",
        "\n",
        "The distinction is not always clear. Some problems can be considered either as regression or classification problems. \n",
        "\n",
        "Given a ML problem, i.e. a set of labeled examples, the goal is to build a function $f$ that maps examples to labels or, in other words, that predicts the label from the example.\n",
        "\n",
        "The outputs of $f$ are called *predictions* or *predicted values*, and the actual labels of the examples are called *actual values* or *target values*.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RP73ZCHW-5IP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python packages"
      ],
      "metadata": {
        "id": "OV7OxFdf78XU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this ML course, the main Python packages are:\n",
        "\n",
        "1. **Fastai**, a high-level package build from `pytorch`. A description of `fastai` is available in the paper *Howard, J.; Gugger, S. Fastai: A Layered API for Deep Learning. Information 2020, 11, 108. https://doi.org/10.3390/info11020108* and on the site https://docs.fast.ai/\n",
        "\n",
        "2. **Pytorch**: PyTorch is an optimized tensor library for deep learning using GPUs and CPUs;  https://pytorch.org/docs/stable/index.html\n",
        "\n",
        "3. **Scikit-learn**: Another high-level package build on `NumPy`, `SciPy`, and `matplotlib` which covers most ML techniques except deep learning;  https://scikit-learn.org/stable/index.html."
      ],
      "metadata": {
        "id": "Ly1ySlnR8AMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models and parameters"
      ],
      "metadata": {
        "id": "RW_X7OPCXc3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "More formally, if $E$ is the set of examples and $L$ is a set that includes the labels, then what we call the *model* is a family of functions $f_{\\rm \\bf w}$ that depends on a set of parameters ${\\rm \\bf w}$: $$f_{\\rm \\bf w}: E â†’ L.$$\n",
        "\n",
        "It can be more convenient to express the function as depending on the parameters ${\\rm \\bf w}$ as well as the example ${\\rm \\bf x}$. The model's predicted label $\\hat{y}$ for the example ${\\rm \\bf x}$ is:\n",
        "\n",
        "$$\\hat{y}=f_{\\rm \\bf w}({\\rm \\bf x})= f({\\rm \\bf x}; {\\rm \\bf w}).$$\n",
        "\n",
        "ML practicioners use an enormous variety of models, depending on the problem at hand and on the available computational resources to train the model. Models include convolucional neural networks (CNN) for image classification (resnet and other kind of CNNs), neural networks (NN) for classification of tabular data, linear regression models, decision and regression trees, random forest and other ensemble models, among many other models.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1rjcetay_O8EPd9mUHh4k1XFQIi84FfX2\" width=\"800\" >\n",
        "\n"
      ],
      "metadata": {
        "id": "IKZwTca7XfkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of a simple model (simple linear regression)"
      ],
      "metadata": {
        "id": "xNbDdfhgXHQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose that our examples are scalar numbers $x_1,\\dots, x_n$ and the labels are continuous labels $y_1, \\dots, y_n$. We call $x$ the explanatory variable and $y$ the response variable. \n",
        "\n",
        "Let's consider the simple linear regression model:\n",
        "$f_{\\rm a,b}(x)= a \\, x + b$. The model parameters are ${\\rm \\bf w}=(a,b)$ and the predicted values are given by$\\\\[1em]$ \n",
        "$$\\hat{y}=f(x; {\\rm a,b})=a\\, x + b.$$\n",
        "\n",
        "The target  or actual label values are the $y_1, \\dots, y_n$, and the predicted label values are the $\\hat{y}_1,\\dots,\\hat{y}_n$.\n",
        "\n"
      ],
      "metadata": {
        "id": "ak8k0ZkGXL5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of a simple model (quadratic regression)"
      ],
      "metadata": {
        "id": "KCwiAiilXOkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In notebook [Lesson3_edited_04-how-does-a-neural-net-really-work.ipynb](Lesson3_edited_04-how-does-a-neural-net-really-work.ipynb), a similar simple example was discussed. The only difference was that the model $f_{\\rm a,b,c}$ was quadratic instead of linear: \n",
        "\n",
        "$$f_{\\rm a,b,c}(x)= f(x;a,b,c)= a \\, x^2 + b \\, x + c.$$\n",
        "\n",
        "In the illustration below, the observed (actual) values are plotted in blue, and the values preditted by the model for a fixed set of parameters $a=3, b=2, c=1$ are plotted in red."
      ],
      "metadata": {
        "id": "B06MlDsTXWxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example from Lesson3_edited_04-how-does-a-neural-net-really-work.ipynb\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(42)\n",
        "def noise(x, scale): return np.random.normal(scale=scale, size=x.shape)\n",
        "def add_noise(x, mult, add): return x * (1+noise(x,mult)) + noise(x,add)\n",
        "# create synthetic examples (x) and labels (y), and calculate predictions\n",
        "x = torch.linspace(-2, 2, steps=20)[:,None]\n",
        "def f(x): return 3*x**2 + 2*x + 1\n",
        "y = add_noise(f(x), 0.15, 1.5)\n",
        "ypred=f(x)\n",
        "# plot \n",
        "plt.scatter(x,y);\n",
        "plt.scatter(x,ypred,color='red');\n",
        "plt.title(\"Example of a simple quadratic model with 3 parameters\")\n",
        "plt.xlabel(\"Explanatory variable\")\n",
        "plt.ylabel(\"Response (actual in blue, predicted in red)\")\n",
        "plt.plot(x, f(x), 'red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WcGDmG34Jshd",
        "outputId": "f19cdb50-58a4-4b62-ef9f-ad255aa7e431"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABCWklEQVR4nO3dd7gU5dnH8e/vUA8GRAUL3YqxxIYlrxp7VBJL1EQjFmxo1FiDohhjQ1E0iYpRwYqisfeCBVuwgqLYsCBIUQGVoiD1fv94ZmVZtsw5W8+e+3Nde52d2dmZ+8yWZ58y9yMzwznnnMumptwBOOecq3xeWDjnnMvJCwvnnHM5eWHhnHMuJy8snHPO5eSFhXPOuZy8sCgRSb0l/a8I+5WkWyV9L+nNQu8/6Tg3SPp7kfY9UdLuxdh3oUjaWdKUAu+zaOe0viTdJumSmNvm/bpJekrSkYWIxxVXVRQW0Zt2vqQfkm6Dyx1XiewA7AF0MrNtinUQMzvBzC4u1v6rXbofC35Owcz2NrPbIf8fVJLaSRol6VtJsyS9Jmn7wkVbOcrxA6tpKQ9WZPuY2XPlDqIMugITzezHcgfSWElqamaLyx2H4wfgaOBTwID9gMckrV7s16chvQckCZCZLa3L86qiZpGNpOslPZC0fLmk56Pmm1UkPS5pRtSM87ikTknbvijpEkmvRrWVxyStJmm4pDmS3pLULWl7k3SKpAmSZkoaJCntOZa0oaRnJX0nabykP2X5HzpIejTa9jNJx0XrjwFuAn4dxXdhmueuK2lk9GtrZhR72wzHkaR/SZoe/X/jJG0SPfZzc0CiSUbSWdG2X0naX1JPSZ9EcZ6btN8LJN0v6R5JcyW9LWmzDDHUSOon6fMo5nslrZrl3PSNjj9N0tHRa7Be9NiLko5N2na5X66SrpY0Ofpfx0jaMemx2uh//l7Sh8DWKcedKOlsSe8BP0pqmhT3XEkfSvpDtO0vgRuSXqdZqec0Wt5P0tgons8l7ZXhf54Y/d/vSfpR0s2S1lBo0pkr6TlJqyRtv6+kDxR+bb8YxZN4bIvo9Zgr6R6gZcqxfh/FNCv6HPwq02uR9Jy1o+1rouWhkqYnPX6HpNOSX6NM5yiyiqQnohjfkLRuuuOa2U9mNj76EhSwBFgFSPv+ic7/DQqfw7mSXpLUNenxbO+PxHv6TklzgN6StlGozcyK3pODJTVPeo5JOlHSp9HxLlb4fL4aHePelO3TnntJdwBdCAXhD5LOitZvF203S9K7knZO2teLkgZIGgXMA9aJPg8Toli+kNQr86saTnCDvwETgd0zPNYK+AToDewIzCQ02QCsBhwYbdMauA94OOm5LwKfAesCKwMfRvvanVArGwbcmrS9AS9Eb84u0bbHRo/1Bv4X3V8JmAwcFe1niyiujTL8Dy8D/yF8kDcHZgC7pu43w3PXIzRTtQDaR/v6d4Zt9wTGAG0JH7ZfAmtFj90GXBLd3xlYDJwPNAOOi2K6KzqPGwPzgbWj7S8AFgEHRdv/DfgCaJb6+gGnAq8DnaKYbwTuzhDvXsA3wCbROb0reg3WS3r9jk3afrlzBRwWvQeaAmcCXwMto8cGAq9Er2Vn4H1gSsp7bmz0WG207o9AB8KPsIOBH5PO3wqvU8o53QaYHb1WNUBHYMMs7/fXgTWi7aYDbxPeRy2BkcA/om03iOLYIzr3ZxHe082j2yTg9Oixg6LXKRHTFtG+twWaAEdGx24R43P3JbBVdH88MAH4ZdJjW6S+RlnO0bfR+WkKDAf+m+P74D1gYfReGJplu9uAucBvCO+1q+vw/rggOlf7R69XLbAVsF20fTfgI+C0lO+HR4A2hM/IAuB5YB2Wfb8cWZ9zH70PvgV6RvHsES23TzrPX0bHbRodbw7QPXp8LWDjrOe1GF/epb5FJ+4HYFbS7bikx7cFviN8MP6cZT+bA98nLb8I9E9avgp4Kml5H2Bsypthr6TlE4HnUz8IhC+SV1KOfSPRBzxlfWfCL6TWSesuA27L9AHLca72B97J8NiuhAJuO6AmzQcrubCYDzSJlltH//u2SduPAfZP+mC9nvRYDfAVsGPqG5/wAdstadu1CB/KpmnivQUYmLS8AXUoLNLs73tgs+j+hJTXsg8rFhZH5zjXY4H9Mh075ZzeCPyrDu/3XknLDwDXJy3/lehHD/B34N6Ucz81eg1/A0wjNEkkHn81KabrgYtTjj0e2Cn1dUsT4x3AGcCa0XOuAE4A1iZ8PmtSX6Ms5+impOWewMcxzlFL4M9EX74ZtrmNpIIH+AXhs9Y5xvvjAuDlHDGcBjyUtGzA9imfkbOTlq8i+iFX13MPnA3ckbL9CJYVPi8CFyU9tlL0OhxI9GMn162amqH2N7O2SbehiQfM7A3Ch1/AvYn1klpJulHSpKgq+TLQVlKTpP1+k3R/fprlX6TEMTnp/iTCL81UXYFto+rirKjK3YvwwUrVAfjOzOam7Ldjmm1XEDVP/FfS1Oh/vBNol25bMxsJDAauA6ZLGiKpTYZdf2tmS6L786O/2c7Nz+fFQjPBFDKfm4eSzstHhA/wGmm27cCK5zs2SX+T9JGk2dGxVmbZuYmz7+THkXREUrPBLEKNJ+25TqMz8Hkdwo/7vuxAUuzRuZ9MeP90AKZa9O0RSf4/uwJnprxPO5P+dUv1EssKpJcJX1Y7RbdXrG7t5V8n3Z/Hip+5FVhokrob6KcMTZ6R5PflD4QflR0g5/tjuedG22+g0JT9dfRZu5QVX/+4r1tdz31X4I8p2+9A+LGV7n/9kfCj9QTgq6iZb8MM+wYaQZ8FgKSTCNXMaYRqeMKZQHfCL+I2hDc2hEKlvjon3e8SHTPVZOCllMLtF2b2lzTbTgNWldQ6Zb9TY8ZzKeEXzabR/3gYWf4/M7vGzLYCNiL8Uu8b8zi5/HxeorbsTmQ+N3unnJuWZpbu//2KFc93sh8JTYwJPxfGUfvzWcCfgFXMrC2hGShxbnLtG8J5TeyvKzAUOBlYLdrf+0n7sxWevbzJhObOQptG+CIBfu7c7Ex4/3wFdIzWJST/n5OBASmvRavoSziXlwjNvjtH9/8HbE8oLF7K8Jxc56g+mhGaeTJJfl/+gtDsOC3G+wNWjPd64GNg/eizdi71/y7Jde5Tjz2ZULNI3n4lMxuYKV4zG2FmexAKlI8J79+Mqr6wkLQBcAnhS/Jw4CxJm0cPtyaU5rMUOlH/UYBD9lXoOO9MaH+/J802jwMbSDpcUrPotrWSOh4TzGwyoWngMkkto06uYwg1hDhaE5roZkvqSJYv/yiGbSU1I3zR/gTUacREFltJOkBSU0L1fAGh3T3VDcCAREejpPaS9suwz3sJHYsbSWrFiq/fWOCAqAa5HuG8JbQm9LvMAJpKOp/Qlpy873Oi17IToWknm5UIH8YZUdxHEWoWCd8AnZI7MFPcDBwlaTeFTv6OuX7pxXQv8Ltov80IP5AWEN5TrxHOwSnRe/AAQt9AwlDghOg9IUkrSfpdyg+XtMzsU8Jn6zDCD6M5hHNwIJkLi1znKKuog3cHSc0VBiicTaiRvpHlaT0TzwEuJjSXTib3+yOd1oR+gB+i1y7dj7+4cp37b1i+ELwT2EfSnpKaRN8VOytpwE6yqMVhP0krEd4PP5Djs15NhUViZEDi9lD0xXQncLmZvRu9gc8F7pDUAvg3oWNqJuGL6+kCxPEIoS1yLPAE4UtgOVGT0m+BQwi//L4GLifUftL5M6HDbBrwEKFvI+4w4QuBLQm/ip4AHsyybRvCm/R7QnPEt8CgmMfJ5RFCtfd7QqF9gJktSrPd1cCjwDOS5hJel23T7dDMniK8hiMJnbYjUzb5F6Gj8xvgdkLnaMIIwuv9CeF//YnlmxUujNZ/ATxDaIPPyMw+JLQ5vxYdb1NgVNImI4EPgK8lzUzz/DcJAx7+RXitXiKpRlBfZjae8IV9LeF9vg9hmPlCM1sIHEDoK/iO8Po8mPTc0YTBC4MJr9tn0bZxvURorpyctCxCZ3w6Wc9RDC0ITajfEmpOPYHfmVm6GmzCXYQfGd8ROqgPi9bnen+k8zfgUEKn+VDS/1CMJca5vww4L2py+lt0jvcjfL/NiGLtS+bv+BpCn9I0wv++EzkKNy3fXOnyIckIVdDPyh1LJZF0AaHT+bBc2xbgWP4auFgk3UYYtHBeuWNpCKqpZuGcc65IvLBwzjmXkzdDOeecy8lrFs4553KqpkSCtGvXzrp161buMJxzrsEYM2bMTDNrn2u7ohUWkm4Bfg9MN7NEMrp7CBfBQcg/NMvMNk/z3ImE4WdLgMVm1iPOMbt168bo0aPzjt055xoLSbEyHxSzZnEbYYzwsMQKMzs4cV/SVYTx5JnsYmb1GWvtnHOuwIpWWJjZy0pK350sSi/wJ0LiOueccxWuXB3cOwLfRFdUp2OEK3jHSOpTwricc86lkbNmESV924yQ7XA+8L6ZTc/+rJz+DGRLRraDmU2VtDrwrKSPzezlDPH1IaSPpkuXdLnenHPO5StjYaEwG9XZhIl+PiXkG2lJSIA3j5B///Y6phomytd0ACEPS1qJDKNmNl3SQ4TkZmkLCzMbAgwB6NGjh1804pxzRZCtGeoSQhK+dc1sTzM7zMwOMrNfAfsScrsfXo9j7k6YvGRKugej7IqtE/cJCffer8dxnHOuug0fDt26QU1N+Dt8eK5n1FvGmoWZ/TnLY9MJ2T4zknQ3IZd9O0lTCJlSbyZkWr07ZdsOhNmwehJSCj8UpdhvCtxlZoXIBuucc9Vj+HDo0wfmzQvLkyaFZYBe2afTro+M6T6i3PYZmVm2VNdl0aNHD/PrLJxzjUK3bqGASNW1K0ycGHs3ksbEuZYtWwf3PtHf1YH/Y9lcAbsQJk6puMLCOecajS+/rNv6PGVrhjoKQNIzwEZm9lW0vBbhgjvnnHPl0qVL+ppFkUaFxrnOonOioIh8Q/r5iJ1zzpXKJZeAUqb4btUKBgwoyuHiXMH9vKQRLOuUPhiIO6Wnc865YmjTBsxgtdXgu+9CjWLAgKJ0bkOMwsLMTpb0B+A30aohZvZQUaJxzjmXmxlccAGsuy58/DE0LX4C8bhHeBuYa2bPSWolqbWZzS1mYM455zJ4/HF45x249daSFBQQo89C0nHA/YQrtgE6Ag8XMSbnnHOZJGoV66wDhx1WssPGKZJOIqTbeAPAzD6NcjY555wrtSeegLffhltuKVmtAuKNhlpgZgsTC1FuJ8/B5JxzpZaoVay9dklrFRCvZvGSpHOBWkl7ACcCjxU3LOeccyt48kkYMwZuvhmaNSvpoePULM4mZJwdBxwPPAmcV8ygnHPOpUiuVRxenxyu+clas5DUBPjAzDYEhpYmJOeccyt46ikYPRpuuqnktQrIUbMwsyXAeEl+xbZzzpVLolbRrRsccURZQojTZ7EK8IGkN4EfEyvNbN+iReWcc26Zp5+Gt96CoUPLUquAeIXF34sehXPOufQStYquXctWq4B46T5eKkUgzjnn0hgxAt58E4YMgebNyxZGnNFQzjnnyiFRq+jSBY48sqyhlO7yP+ecc3XzzDPwxhtw441lrVWA1yycc64yJdcqevcudzS5axaStgcuALpG2wswM1unuKE551wj9uyz8PrrcMMNZa9VQLyaxc3AP4EdgK2BHtHfrCTdImm6pPeT1l0gaaqksdGtZ4bn7iVpvKTPJPWL968451yVSNQqOneGo44qdzRAvD6L2Wb2VD32fRswGBiWsv5fZnZlpidFV41fB+wBTAHekvSomX1Yjxicc67hee45eO01uP76iqhVQLzC4gVJg4AHgQWJlWb2drYnmdnLkrrVI6ZtgM/MbAKApP8C+wFeWDjnql8F1iogXmGxbfS3R9I6A3at5zFPlnQEMBo408y+T3m8IzA5aXlKUgwrkNQH6APQpYtnJXHONXDPPw+vvgr/+Q+0aFHuaH4W56K8XQp4vOuBiwmFzcXAVcDR+ezQzIYAQwB69Ojh82w45xquRK2iUyc4Oq+vxoLLWFhIOszM7pR0RrrHzeyfdT2YmX2TtP+hwONpNpsKdE5a7hStc8656jZyJIwaBdddV1G1Cshes1gp+tu6UAeTtJaZfRUt/gF4P81mbwHrS1qbUEgcAhxaqBicc64iJWoVHTvCMceUO5oVZCwszOzG6O+F9dmxpLuBnYF2kqYA/wB2lrQ5oRlqImEyJSR1AG4ys55mtljSycAIoAlwi5l9UJ8YnHOuwXjhBfjf/2Dw4IqrVQDIrHqa+Xv06GGjR48udxjOOVc3ZrDTTjBhAnz2GbRsWbJDSxpjZj1ybefpPpxzrlyGDw8TGtXUwCuvwG67lbSgqAsvLJxzrhyGD4c+fWDSpGXr7rsvrK9AGZuhMo2CSqjPaKhi82Yo51yD0a3b8gVFQteuMHFiycKI2wyVbTRUYhRUd0IuqEej5X2AN/MLzznnGrkvv6zb+jLLNhrqQgBJLwNbmtncaPkC4ImSROecc9WqS5f0NYsKzUQRp89iDWBh0vLCaJ1zzrn6uvBCkJZf16oVDBhQnnhyiJMbahjwpqSHouX9gduLFpFzzjUGc+aEIbOrrw4zZoQaxYAB0KtX7F08/M5UBo0Yz7RZ8+nQtpa+e3Zn/y06FiXcWNdZSNoS2DFafNnM3ilKNHnyDm7nXIMwezastx786lchHXlqDSOGh9+ZyjkPjmP+oiU/r6tt1oTLDti0TgVGoa+zaAXMMbOrgSlRKg7nnHP1cfnlMHMmXHFFvQoKgEEjxi9XUADMX7SEQSPGFyLCFeQsLCT9AzgbOCda1Qy4syjROOdctZs8Gf71r9DctNVW9d7NtFnz67Q+X3FqFn8A9gV+BDCzaRQwuaBzzjUqf/976KvIsyO7Q9vaOq3PV5zCYqGFjg0DkLRSju2dc86l8+67MGwYnHJKuPguD3337E5tsybLratt1oS+e3bPa7+ZxBkNda+kG4G2ko4jTFZ0U1Gicc65anbWWbDKKnDuuXnvKtGJXarRUHFmyrtS0h7AHMLV3Oeb2bNFicY556rVM8+E2z//CW3bFmSX+2/RsWiFQ6qchYWky83sbODZNOucc87lsmQJ9O0La68NJ55Y7mjqJU6fxR5p1u1d6ECcc65q3XEHvPceXHZZRU5sFEe2Obj/ApwIrCvpvaSHWgOvFjsw55yrCvPmwXnnwTbbwJ/+VO5o6i1bM9RdwFPAZUC/pPVzzey7okblnHPV4t//hqlT4e67630BXiXI2AxlZrPNbCJwNfCdmU0ys0nAYknblipA55xrsGbMgIEDYb/9YMcdc29fweL0WVwP/JC0/EO0zjnnXDYXXRSaoQYOLHckeYtTWMiSsg2a2VLijaK6RdJ0Se8nrRsk6WNJ70l6SFLbDM+dKGmcpLGSPDOgc67h+eQTuOEGOO442HDDckeTtziFxQRJp0hqFt1OBSbEeN5twF4p654FNjGzXwGfsCzfVDq7mNnmcbIhOudcxTnnHGjZEi64oNyRFEScwuIE4P+AqcAUYFugT64nmdnLwHcp654xs8XR4utApzpF65xzDcGoUfDgg+GK7TWqY664OFdwTwcOKcKxjwbuyXRY4BlJBtxoZkMy7URSH6LCq0uFTkfonGtEzMIFeGutBWecUe5oCibbdRZnmdkVkq4lSiKYzMxOqe9BJfUHFgPDM2yyg5lNlbQ68Kykj6OaygqigmQIhMmP6huTc84VxIMPwmuvwdChsFL15F3NVrP4KPpb0A5mSb2B3wO7JXecJzOzqdHf6dF0rtsAaQsL55yrGAsXQr9+sPHGcNRR5Y6moDIWFmb2WPS3YPNtS9oLOAvYyczmZdhmJaDGzOZG938LXFSoGJxzrmhuvBE++wyeeAKaNMm9fQOSrRnqMdI0PyWY2b7ZdizpbmBnoJ2kKcA/CKOfWhCalgBeN7MTJHUAbjKznsAawEPR402Bu8zs6br8U3VRygnPnXNVbPZsuPBC2HVX2Lv60udla4a6Mvp7ALAmy6ZS/TPwTa4dm9mf06y+OcO204Ce0f0JwGa59l8IqROeT501n3MeHAfgBYZzrm4GDoRvv4VBgxp0Wo9MsjVDvQQg6aqUax0eq5YL5bJNeO6FhXMutsmTQw6oXr1gyy3LHU1RxLnOYiVJ6yQWJK0NVEUXf6knPHfOVZnhw6FbN+jSBX76CbbeutwRFU2caVVPB16UNAEQ0BU4vqhRlUiHtrVMTVMwFGvCc+dcFRk+HPr0CbmfEs49F9q1CzWMKpOzZhF1Lq8PnAqcAnQ3sxHFDqwUSj3huXOuivTvv3xBAWG5f//yxFNkcRICtgLOALqa2XGS1pfU3cweL354xVXqCc+dc1Xkyy/rtr6Bi9MMdSswBvh1tDwVuA9o8IUFlHbCc+dcFenYEaZMWXF9laYditPBva6ZXQEsAogupqu+cWHOOVcX3dM0V7dqBQMGlD6WEohTWCyUVEt0gZ6kdYEFRY3KOecq2RtvwMiRsNde0LVruK6ia1cYMqQqO7chXjPUP4Cngc6ShgPbA72LGZRzzlWsxYvhhBNCVtl774XWrcsdUUlkLSwk1QCrEK7i3o7Q/HSqmc0sQWzOOVd5rrsOxo6F++5rNAUF5CgszGxplKr8XuCJEsXknHOVado0+PvfQ/PTgQeWO5qSitNn8Zykv0nqLGnVxK3okTnnXKU5/XRYtAgGD67K/E/ZxOmzODj6e1LSOgPWSbOtc85Vp2eeCX0UF10E665b7mhKLs60qmuXIhDnnKtY8+fDiSfCBhuEebUboThXcLcETgR2INQoXgFuMLOfihybc85VhoED4fPP4bnnoEWLckdTFnGaoYYBc4Fro+VDgTuAPxYrKOecqxiffBIKi0MPhd12K3c0ZROnsNjEzDZKWn5B0ofFCsg55yqGGZx0EtTWwlVXFXz3DWmmzjiFxduStjOz1wEkbQtUxeRHzjmX1T33hKanwYNhzTULuuuGNlNnnKGzWwGvSpooaSLwGrC1pHGS3itqdM45Vy6zZ4ehsj16hCu2CyzbTJ2VKE7NYq/67lzSLcDvgelmtkm0blXgHqAbMBH4k5l9n+a5RwLnRYuXmNnt9Y3DOefq7LzzYPp0ePxxaNIk9/Z11NBm6owz+dGkbLccT7+NFQubfsDzZrY+8Hy0vJyoQPkHsC2wDfAPSavE+H+ccy5/Y8bAf/4ThstutVVRDpFpRs5KnakzTjNUvZnZy8B3Kav3AxK1hNuB/dM8dU/gWTP7Lqp1PEseNRznnIttyZLQ7LT66nDJJUU7TEObqTNOM1ShrWFmX0X3vwbWSLNNR2By0vKUaN0KJPUB+gB0qdJJR5xzJXTjjTB6NNx1F6y8ctEO09Bm6ixHYfEzMzNJluc+hgBDAHr06JHXvpxzjdzXX8O558Luu8MhhxT9cA1pps46N0NJek7SU5J+X89jfiNprWhfawHT02wzFeictNwpWuecc8Vz5pkhtcd11zW6RIG51KfP4gjCKKWu9Tzmo8CR0f0jgUfSbDMC+K2kVaKO7d9G65xzrjiefz40PfXrF3JAueXEKiwk1UrqDmBm08xsjJldF+N5dxOuy+guaYqkY4CBwB6SPgV2j5aR1EPSTdExvgMuBt6KbhdF65xzrvAWLAgjn9ZdF845p9zRVKQ4iQT3Aa4EmgNrS9qc8OW9b67nmtmfMzy0QoIVMxsNHJu0fAtwS65jOOdcvQ0fDv37w6ToKoCzzoKWLcsbU4WK08F9AeFahxcBzGysJE9b7pxr2IYPhz59YN68ZesGD4Zf/Qp69Yq1i4aU2ylfcZqhFpnZ7JR1PurIOdew9e+/fEEBYbl//1hPT+R2mjprPsay3E4Pv1OdY3HiFBYfSDoUaCJpfUnXAq8WOS7nnCuuL7+s2/oUDS23U77iFBZ/BTYGFgB3A3OA04oYU2kNHw7dukFNTfg7fHi5I3LOlUKmLLIxL+5taLmd8hVnWtV5QP/oVl1S2ywnTQrLELvN0jnXAC1cmH7Gu1atYMCAWLvo0LaWqWkKhkrN7ZSvnDULSS9IGpl6K0VwRZdnm6VzroG66CKYOBFOOw26dg0X4HXtCkOGxP6h2NByO+VLZtn7qiUlp1xsCRwILDazipu1vEePHjZ6dB3mZaqpCTNhpZJg6dLCBeacqxyvvgo77gi9e8PNN+e1q2oYDSVpjJn1yLldrsIiw87fNLNt6hVZEdW5sOjWbdn46mRdu4ZfHc656vLDD7DZZuFH4rvvQuvW5Y6o7OIWFnGaoVZNurWTtCdQvFSMpTRgQGijTFZTAxdfXJ54nHPFdcYZ8MUXMGyYFxR1FOeivDGE6yoELAa+AI4pZlAlk2ib7N8/DJdbZRX47jv49tvyxuWcK7zHHoOhQ0Pupx12KHc0DU69mqEqVZ2boVKZwX77wYgR8NZb4UpO51zDN306bLoprLUWvPkmNG9e7ogqRtxmqIw1C0kHZHuimT1Yn8AqmhQ6vDbdFA49NBQYtdU5DM65RsMsDImfPTtklk0qKKqhg7pUsjVD7ZPlMQOqr7AAaN8ebrsN9t4bzj4brrmm3BE55/Jx663wyCPwz3/CJpv8vDqRriNxFXYiXQfgBUYa3gyVyWmnwdVXwxNPQM+ehdmnc660JkwIo5+23hqeey4MYIlsP3Bk2ovqOratZVS/XUsZZVkVcjTUapKukfS2pDGSrpa0WmHCrGADB4ZfIUcdFdo7nXMNy5IlcMQR0KRJaC2oWf7rrrGl68hXnNxQ/wVmEC7GOyi6f08xg6oILVuGWbNmz4ajj05/8Z5zrnINGgSjRoUpUtPke8qUlqNa03XkK05hsZaZXWxmX0S3S4A1ih1YRdh0U7jiitAUdf315Y7GORfX2LFw/vnwpz+FwSppNLZ0HfmKU1g8I+kQSTXR7U80pvmw//pX2GuvMJH7hx+WOxrnXC4//QSHHQbt2oUfeVLazfbfoiOXHbApHdvWIkJfxWUHbOqd2xlk7OCWNJdlF+OtBCQStzcBfjCzNiWJsA4K2sGd7OuvQy2jY0d444302Sqdc5XhzDPDyKenn4Y99yx3NBUv7w5uM2ttZm2ivzVm1iy61VRiQVFUa64Jt9wScsl4RlrnKtfIkaGgOPlkLygKLE4zVEFJ6i5pbNJtjqTTUrbZWdLspG3OL3WcK9hnH/jLX+Cqq8IQPOdcZZk1K2SS7d4dLr+83NFUnTi5oQrKzMYDmwNIagJMBR5Ks+krZvb7EoaW25VXwgsvhOF448bBatU/gti5BuOvf4WvvoLXXlsxQajLW8lrFil2Az43szR5witQq1ZhOO3MmXDccT6c1rlyS0yLLMGdd4bcbj1yNr+7eohVWEhqIqmDpC6JW4GOfwhhXu90fi3pXUlPSdo4S2x9JI2WNHrGjBkFCiuLLbaASy+Fhx7Ke+IU51weEtMiJ89J8+STYb0ruDgz5f0V+AfwDZCYPs7MLK+UrJKaA9OAjc3sm5TH2gBLzewHST2Bq81s/Vz7LNpoqFRLl8Iee8Drr8M778AGGxT/mM655fnkZQVRsHQfwKlAdzPb2Mw2jW6FyN29N/B2akEBYGZzzOyH6P6TQDNJ7QpwzMKoqYHbbw9DaPfaK7w5a2rCm9d/1ThXGl9+Wbf1Li9xCovJwOwiHPvPZGiCkrSmFK6kkbQNIc7KmpGoUyc4/PAw69aXX4b+i0mTQrXYCwznim/VVdOvT5Paw+UvzmioCcCLkp4AFiRWmtk/63tQSSsBewDHJ607IdrvDYQcVH+RtBiYDxxilZge95FHVlw3b164FiMxC59zrvDefhvmzAk1+qVLl61v1SpMl+wKLk5h8WV0ax7d8mZmPwKrpay7Ien+YGBwIY5VVF4Ndq70ZsyAP/whzHrXr1+4puLLL0ONYsAA/6FWJDkLCzO7sBSBNEhduqTvYPNqsHPFsXgxHHxwmDZg1CjYcstwsawrumzTqv7bzE6T9BghR9RyzGzfokbWEAwYEPoo5s1btq5JE7j44vLF5Fw169s3XBg7bFgoKFzJZKtZ3BH9vbIUgTRIvXrx1sTv6Xzlxaw+awY/tFyJNj/9EDq9nXOFdccd8O9/w6mnhsElrqR8WtU8pM7hixlXP/Vv9hv3PDzwABxwQMlica6qvf02bL89bLcdPPMMNGtW7oiqRiGvs3AZDBoxfllBASBx1m9P4oPOvwy/fN59t3zBOVctEh3aq68O997rBUWZeGGRh3Rz9S5o2pyj9j0H2rYNeWp8/m7n6m/RojDb3fTpIcVO+/bljqjR8sIiD5nm6m3WqSM8/DB88w0cdBAsXFjawJyrFn37wosvwtCh3qFdZtlGQ6UdBZXgo6HCHL7L9VmQNIfvFh1DosFevcJELDfemHF6R+dcGnfcAVdfDaedFqZJdWWVbTSUj4LKITFX76AR45k2az4d2tbSd8/uy+bwPfRQeP99uOwy2GwzOOmkMkbrXAMyZkwYlr7LLjBoULmjcfhoqOJbuhT23z+kTh4xAnbbbbmHH35naubCxrnGaPr0MCeFBKNHez9FkRVsNJSk9SXdL+lDSRMSt8KE2QjU1IRJWTbcEP74R/j8858fSgy9nTprPgZMnTWfcx4cx8PvTC1fvM6VU6JDe8YM79CuMHE6uG8FrgcWA7sAw4A7ixlU1WnTJiQdlGDffUMCNNIMvQXmL1rCoBHjyxGlc+X3t7/BSy/BTTd5h3aFiVNY1JrZ84Qmq0lmdgHwu+KGVYXWXRfuuw/Gjw+d3kuWpB16C+mH5DpX9YYNg2uugdNP92SAFShOYbFAUg3wqaSTJf0B+EWR46pOu+4aPgyPPw7nnZdx6G2m9c5VneQ5tI88EjbaCK64otxRuTTizpTXCjgF2Ao4HDiymEFVtb/8BY4/HgYO5OqlH1LbrMlyD/889Na5apduDu0vvoB77ilfTC4jHw1VDgsXhjm833yTF4feT/8ptT4ayjU+Pod2RYg7GirnfBaSXiB9ivJd6xmba94c7r8fttmGnU85nFGtWsG0aWEejM4DYAtvr3XVzyZNIt1lqvbll2nXu/KKM1Pe35LutwQOJIyMcvlo3z5Uwc89F77/PqxLzOEN3sHnqtuiRSxo2pyWi1dMhfPNyu1Zswwhuexy9lmY2Zik2ygzOwPYufihNQI33rjiusQc3s5Vq6VLoXdvWi5eyMKa5X+vzmvagst28LkqKlGcZqhVkxZrCJ3cK+d7YEkTgbnAEmBxapuZJAFXAz2BeUBvM3s73+NWFJ/D2zU2ZiHtzV13cf2ex/JRs5U56+VhdJgzk2lt2nHFb45gzPY9yx2lSyNOM9QYQp+FCM1PXwDHFOj4u5jZzAyP7Q2sH922JVwYuG2BjlsZMs3h3blz6WNxrtjM4Oyz4YYboF8/1vrTyVzz4Dge3XiXnzepbdaEy3w0YEWKU1j80sx+Sl4hqUWR4km2HzDMwnCt1yW1lbSWmX1VgmOXRro5vCFcwGfmWWpddbn00pAU8MQT4dJL2T96f+eTG81zq5VOnMLiVSD1uvvX0qyrKwOekWTAjWY2JOXxjsDkpOUp0brlCgtJfYA+AF26dMkzpBJLdGL37x+anjp3DtlpH3sMTjklXMDnBYarBtdcA+edF2aQvPban9/X+2/Rsd5f7qnTGidyqyX26wor23wWaxK+nGslbQE/j2ZrQ7hIL187mNlUSasDz0r62MxerutOokJmCITrLAoQV2n16rX8yCezkB/nn/+EFi3CLzEvMFxDduutcOqpYWrUW24JyTULIFtuNS8sCi9bzWJPoDfQCbiKZYXFHODcfA9sZlOjv9MlPQRsAyQXFlOB5Mb7TtG66ibBlVeGC/euuioUGJdc4gWGS6vim2Huvx+OPTZchHr33dA0TmNGPJ5brbQyvnJmdjtwu6QDzeyBQh5U0kpAjZnNje7/FrgoZbNHgZMl/ZfQsT27qvorspHCDGELFoR23hYt4Pzzyx2VqzAV3wzz1FNhArBf/zqkG29R2K7ODm1rmZqmYPDcasURpz64laS2iQVJq0i6JM/jrgH8T9K7wJvAE2b2tKQTJJ0QbfMkMAH4DBgKnJjnMRuWmpowaqR3b/jHP+Dyy8sdkaswFZ3i/uWX4YADYJNN4IknYKWVCn6Ivnt299xqJRSnTri3mf3c7GRm30vqCZxX34Oa2QRgszTrb0i6b0Djnoe0pibk9V+4EPr1C2lCTj+93FG5ClGxzTCjR8Pvfx9yP40YASvnfVlWWjmnNXYFFaewaCKphZktAJBUC5Ri6KwDaNIEbr89FBhnnBEKDJ/L21GhzTDvvw977gnt2sFzzxV9prt8RlO5uonTDDUceF7SMZKOAZ4Fbi9uWG45TZvCXXeFWfZOPhmGDi13RK4CVFwzzOefh47sFi1CQdHRv8SrSc6ahZldLuk9YLdo1cVmNqK4YbkVNGsG994bhh8ef3yoYRzp04o0ZhXRDDN8eLhOaNKkUAuurYU33oB11ildDK4kYo1jM7OngKeKHIvLpUULeOCBUMM4+uiwfMgh5Y7KlVFZm2ESkxclMhAsWQKLF8M774QZ71xVydkMJWk7SW9J+kHSQklLJM0pRXAujdpaeOQR2GEHOOywcLFTt26hM7xbt/ABdq4U+vdfMVXNTz951uQqFadmMRg4BLgP6AEcAWxQzKBcDq1ahXm8t9oqpFFI8PkwXCmlS4IJnjW5SsW67t7MPgOamNkSM7sV2Ku4YbmcWrcOv+JS+XwYrhQeeyxzVoGGlqPNxRKnsJgnqTkwVtIVkk6P+TxXbFOmpF/vv+xcMV13Hey/f2j2rE0ZptuqVcim7KpOnC/9w6PtTgZ+JORrOrCYQbmYMv2C8/kwXDEsXRqSXJ58MvzudzBuXBjG3bVrqGV07QpDhngTaJVSuFC6OvTo0cNGjx5d7jBKJ3U0SsJGG8Err8Cqq6Z/nnN1NX9+SC/+wAOhsPj3v8NQWdfgSRqTOlNpOhlrFpIek7SPpGZpHltH0kWSjs43UJeHXr3CL7nkX3bHHw+ffQbbbQfjKyBHkGv4ZsyA3XaDBx8MqfOvucYLikYoY80ims/iDEKT03fADKAlsDYhud9gM3ukRHHG0uhqFpmMGhUu3lu0CO67D3bfvdwRuYbqk0+gZ0+YOhXuvBMO9BboahO3ZhGrGUpSN2AtYD7wiZnNy/6M8vDCIsnEiSGZ28cfw+DBcMIJOZ/i3HJGjQoXgNbUhNFP221X7ohcEeTdDJXMzCaa2WtmNrZSCwqXols3ePXVkNTtL38J07QuXlzuqFxDcc89oelptdXg9de9oHA+BLaqtWkDjz4a0ppfe22oacyeXe6oXCUzC3OnHHIIbL01vPYarLtuuaNyFaBwcxy6ytSkSeiU/OUv4cQTw6xljz3mXwAOWH5a1s6tm3P72DtY+/474OCD4bbboGXLcofoKkSswiKaw6KLmfnwmobquONgvfVCB+W224aRLb/5TbmjcmX08DtT+d9FV3PPyNvoMGcGC5o2p3bxQj456iQ2uOma0FfhXCROIsF9gLHA09Hy5pIeLXJcrhh22SWkj27XLoyQuvXWckfkymjswOu46PFr6DRnBjVA7eKFLKhpyl0/tvGCwq0gzjviAmAbYBaAmY0lDJ91FeDhd6ay/cCRrN3vCbYfOJKH35ma/Qnrrx/aoXfaKaQ5/93vwvUZnrW20Tn26ZtotXjBcutaLF3MsU/fVKaIXCWL0wy1yMxma/mkYdVz2XcD9vA7UznnwXHMX7QEgKmz5nPOg+MAss9xsMoq8OSTYfz8k08uW+9ZaxuP77+n45wZaR/qMGdmiYNxDUGcmsUHkg4lzMW9vqRrgVfre0BJnSW9IOlDSR9IOjXNNjtLmi1pbHQ7v77Hq2aDRoz/uaBImL9oCYNGxOhaatYMPv10xfWetbb6Pf00bLJJxod/WqtDCYNxDUWcwuKvwMbAAuBuYA5wWh7HXAycaWYbAdsBJ0lKN63WK2a2eXS7KI/jVa1ps+bXaf0KMmWnzTRPgWvY5s4N6WD23hvatkUXX8zilstnjV3cspZWgy4vU4CukuUsLMxsnpn1N7OtgW2By80szUQK8ZjZV2b2dnR/LvAR4DO710OHtrV1Wr+CTFlrmzQJs/G56vHSS/CrX4UssX37wpgxcN55NL1p+ayxTW8a6k2QLq04o6HuktRG0krAOOBDSX0LcfAojcgWwBtpHv61pHclPSVp4yz76CNptKTRM2akb4OtVn337E5ts+UTutU2a0LfPbvH28GAAWH+gWQtWkDHjmG+goMPhm++KUywrjzmzw8XZe6yS/gR8MorcMUVy66f6NUrpIZZujT89YLCZRCnGWojM5sD7A88RRgJdXi+B5b0C+AB4LRo/8neBrqa2WbAtcDDmfZjZkPMrIeZ9Wjfvn2+YTUo+2/RkcsO2JSObWsR0LFtLZcdsGn2zu1k6bLW3nxzyFp7ySXw8MMh3fkdd4Qre13D8uabsMUWIZ34iSfCu+/C9tuXOyrXQOVMJCjpA2Bz4C5CptmXJL0bfZHX76Ah7fnjwAgz+2eM7ScCPcws6zANTyRYYB99BMceG3JM7bUX3HBDKFBcZVu4EC66CC67LNQSb7nFMw+7jAqZSPBGYCKwEvCypK6ETu76BibgZuCjTAWFpDWj7ZC0TRTnt/U9pqunX/4yNFtce234u8kmYUrNpUvLHZlLGD48XB+TuE7m0ktDTqcBA+DII8Nsdl5QuAKo10x5kpqaWb1SmEraAXiF0P+R+NY5F+gCYGY3SDoZ+Ath5NR84Awzyzlc12sWRTRxYhhJ88wzoSnjpptgww2Xyy3UoW0tfffsHr8ZzOUn00yJK68cmg732ac8cbkGpWDzWUhqQZgAqRtJF/FV4nBWLyzqrk5f9mYwbFjoMP3xRz487nRum7yIU168gw5zZjKtTTv+vWtvdjj/VC8wSqFbt/TDnDt1gsmTSx6Oa5gKWVg8DcwGxgA/XwFmZlflG2SheWFRN6lXgEMYTZWzk/zrr+Gvf4X772cpoibpgv55TVtwxQFncME9lxYzdAdhUEKm9d5U6GKKW1jESffRycz2KkBMrsJkuwI8a2Gx5ppw333MbLUy7eYv333VavGCKLeQFxZFM3ZsGK2WSabrZ5zLQ5wO7lclbVr0SFzJ5XsF+Krz56Zd3yFDziGXp9GjYb/9wnDYZ58N92tTLsBs1Sp0bjtXYHEKix2AMZLGS3pP0jhJ7xU7MFd8+V4BnimHUA2Ei8Ceeqro12fUOetuQ/TaayHp49Zbh1FpF14Y+ioefjhckZ18ncyQIX5hnSuKOH0WaQfWm1nFJRDyPou6qXefRcLw4Sw+9jia/rSsJrK4RUuaHnhASC8xdWoYbtu3b5ims3nzyoq/0r38Mlx8MTz3XJiD5Mwzw8V1bdqUO7Kf+Wi4hq9g11lEhUJbYJ/o1rYSCwpXd4W4AnyF3EI33xSGdE6YALffHrY78khYZx248kqYU+9LdFaQV9bdSpF6ncSdd8LIkbDzzmHOkXHjwnmbOBH69au4guKcB8cxddZ8jGUp8quydudi1SxOBY4DHoxW/QEYYmbXFjm2OvOaRQUyCymxBw2CF14IX3YnnACnngodOoQvy/79QwbcLl1Ce3vMZpS1+z2RdmIVAV8M/F1B/42iSHedRE1NGMnUoQOcfXaYDje1X6JCbD9wJFPT9G91bFvLqH67liEiVx+FHA11DLCtmf0Y7fhy4DVCzibnspNCSuy99w4dtIMGhV/K//oX/PrXIX/RT1ES4zpOvtShbW3aL6vYWXfLrX//FS+oW7oUVl0VPv98WbK/CpV3inzXoMTp4BZJ11dE9zMM8HYuix494J57wqRLffqEztqfUrLd12Hypbyz7pbL55+H5H6Z5g35/vuKLyigACnyXYMSp7C4FXhD0gWSLgReJ+R2cq5+1lkHBg/OPFJq0iQYNQoWLcq6m7z7XEpl8eJQMJ51Vsi3td564Sr4Zs3Sb99ArpNosIW1q5dYuaEkbUkYQmvA/8zsnWIHVh/eZ9HAZEpXkdC6dejo3WOPcOvePfNVy+WSqc9l9mwYMQIeeyzMc/7dd6Fw2GmnkLPp978PQ2JT+yxatWpQw199NFTDF7fPAjPLeQO2BE4lTLG6ZZznlOO21VZbmWtA7rzTrFUrs1DHCLdWrcxuuMHs/vvNjj/ebJ11lj3WqZNZ795mw4ebffPNsn107Womhb933lne+Js1M9t4Y7OmTcPyaquZHX642b33ms2enX4f5YrfOTMDRlucciDnBnA+IUPsBcCFwLvAeXF2XuqbFxYNUJwvy88/N7vxRrODDjJbZZVlX8xduiz7Uk4ubOryhVvXL+sffzQbP97suedCQZB87OQC46yzzF55xWzx4vixOFcGcQuLOENnxwObWTTvtqRaYKyZVVzDpDdDNQJLlsDbb4d0FxddBAsWrLhN06bhaud27Zbd2rdf8f7IkXDaaWHq0YSWLcO67t1hypSQvXXKlGX3v/8+d4yeyM81IIXMOvsC8AczmxUttwUeNLOKG0jthUUjU1OTuZN8991hxgyYOTP8Xbiwfsdo3x46dw5pvzt1Wv5+r14wbdqKz+naNVxE51wDUMjrLGYDH0h6ltDBvQfwpqRrAMzslLwida6+unRJ30HetWuoeSSYwY8/Lis4Zs4MtyOOyLzvzz8PF8ZlGcL61onnsMmFf6N20bLazfxmLXj/uL+xdX3+H+cqWJzC4qHolvBicUJxro4GDEg/mig166oEv/hFuHXrtmz93/+eubBZZ52chz+tyUZstefJnPXysJ8nf7riN0cwpslGjKrff+RcxcpZWJjZ7Yn7klYBOpuZZ5115ZcYXlrPdCGxC5sMps2az9SNd+HRjXdZbr3qcAWzDz11DUXOwkLSi8C+0bZjgOmSRpnZGUWOzbncevWq/zUJeRY2+aYbSc2am0jEB3iB4SpOnCu4VzazOcABwDAz2xbYPZ+DStormh/jM0n90jzeQtI90eNvSOqWz/Gcy6hXr9AZvXRp+FuHgiffK5irImuuazTiFBZNJa0F/Al4PN8DSmoCXAfsDWwE/FnSRimbHQN8b2brAf8CLs/3uM4VWr7pRjwRn2tI4nRwXwSMAEaZ2VuS1gE+zeOY2wCfmdkEAEn/BfYDPkzaZj/CRYAA9wODJclyjfN1rsT236JjvZuMGnzWXNeoxJn86D4z+5WZ/SVanmBmB+ZxzI7A5KTlKdG6tNuY2WLC8N3V8jimcxXHE/G5hiROB/cGwPXAGma2iaRfAfua2SVFjy4GSX2APgBdGki2TrdMuUcDlfP4ieP4aCjXEMRphhoK9AVuBDCz9yTdBdS3sJgKdE5a7hStS7fNFElNgZWBb9PtzMyGAEMgXMFdz5hcGZR7NFC5j584jhcOriGI08HdyszeTFm3OI9jvgWsL2ltSc2BQ4BHU7Z5FDgyun8QMNL7K6pPuUcDlfv4zjUkcWoWMyWtS0j1gaSDgK/qe0AzWyzpZEKneRPgFjP7QNJFhOyHjxImV7pD0mfAd4QCxVWZco8GKvfxnWtI4hQWJxGaeTaUNBX4AshrZhYzexJ4MmXd+Un3fwL+mM8xXOUr92igch/fuYYkzmioCWa2O9Ae2BDYiTBrnnN5KfdooHIf37mGJGNhIamNpHMkDZa0BzCP0I/wGeECPefyUu45tMt9fOcakozzWUh6BPgeeA3YDVgdEHCqmY0tVYB14fNZOOdc3RRiPot1zGzTaGc3ETq1uyRmzHPOOdd4ZOuzWJS4Y2ZLgCleUDjnXOOUrWaxmaQ50X0BtdGyADOzNkWPzjnnXEXIWFiYWZNMjznnnGtc4lzB7ZxzrpHLOBqqIZI0A0gzqXIs7YCZBQynUDyuuvG46sbjqptqjKurmbXPtVFVFRb5kDQ6zvCxUvO46sbjqhuPq24ac1zeDOWccy4nLyycc87l5IXFMkPKHUAGHlfdeFx143HVTaONy/ssnHPO5eQ1C+ecczl5YeGccy6nRltYSBok6WNJ70l6SFLbDNvtJWm8pM8k9StBXH+U9IGkpZIyDoWTNFHSOEljJRU91W4d4ir1+VpV0rOSPo3+rpJhuyXRuRorKXUa30LGk/X/l9RC0j3R429I6lasWOoYV29JM5LO0bEliOkWSdMlvZ/hcUm6Jor5PUlbFjummHHtLGl20rk6P912RYirs6QXJH0YfRZPTbNN8c6ZmTXKG/BboGl0/3Lg8jTbNAE+B9YBmgPvAhsVOa5fAt2BF4EeWbabCLQr4fnKGVeZztcVQL/ofr90r2P02A8lOEc5/3/gROCG6P4hwD0VEldvYHCp3k/RMX8DbAm8n+HxnsBThHx02wFvVEhcOwOPl/JcRcddC9gyut8a+CTN61i0c9ZoaxZm9oyZLY4WXwc6pdlsG+AzC7MFLgT+C+xX5Lg+MrPxxTxGfcSMq+TnK9r/7dH924H9i3y8bOL8/8nx3g/sJkkVEFfJmdnLwHdZNtkPGGbB60BbSWtVQFxlYWZfmdnb0f25wEdA6kxdRTtnjbawSHE0oTRO1RGYnLQ8hRVfnHIx4BlJYyT1KXcwkXKcrzXM7Kvo/tfAGhm2aylptKTXJe1fpFji/P8/bxP9WJkNrFakeOoSF8CBUdPF/ZI6FzmmOCr58/drSe9KekrSxqU+eNR8uQXwRspDRTtn2VKUN3iSngPWTPNQfzN7JNqmP7AYGF5JccWwg5lNlbQ68Kykj6NfROWOq+CyxZW8YGYmKdNY8K7R+VoHGClpnJl9XuhYG7DHgLvNbIGk4wm1n13LHFOlepvwfvpBUk/gYWD9Uh1c0i+AB4DTzGxOru0LpaoLCzPbPdvjknoDvwd2s6jBL8VUIPkXVqdoXVHjirmPqdHf6ZIeIjQ15FVYFCCukp8vSd9IWsvMvoqq29Mz7CNxviZIepHwq6zQhUWc/z+xzRRJTYGVgW8LHEed4zKz5BhuIvQFlVtR3k/5Sv6CNrMnJf1HUjszK3qCQUnNCAXFcDN7MM0mRTtnjbYZStJewFnAvmY2L8NmbwHrS1pbUnNCh2TRRtLEJWklSa0T9wmd9WlHbpRYOc7Xo8CR0f0jgRVqQJJWkdQiut8O2B74sAixxPn/k+M9CBiZ4YdKSeNKadfel9AeXm6PAkdEI3y2A2YnNTmWjaQ1E/1MkrYhfI8Wu8AnOubNwEdm9s8MmxXvnJW6R79SbsBnhLa9sdEtMUKlA/Bk0nY9CaMOPic0xxQ7rj8Q2hkXAN8AI1LjIoxqeTe6fVApcZXpfK0GPA98CjwHrBqt7wHcFN3/P2BcdL7GAccUMZ4V/n/gIsKPEoCWwH3R++9Nwlz3pXi/54rrsui99C7wArBhCWK6G/iKMIXzFOAY4ATghOhxAddFMY8jy+jAEsd1ctK5eh34vxLFtQOhr/K9pO+tnqU6Z57uwznnXE6NthnKOedcfF5YOOecy8kLC+ecczl5YeGccy4nLyycc87l5IWFq1haPlPs2HTZUmPu5zZJBxU4tm6SDi3kPgtJ0qs5Hu+WJavqi8qSWdg1TlV9Bbdr8Oab2eblDiKDbsChwF1xnyCpqS1LXlkUiWOY2f8V8ziu8fGahWtQJK2sMC9D92j5bknHRfd/kPSvKNf/85Lap3n++ZLekvS+pCFJV+K+KOlySW9K+kTSjtH6bpJekfR2dEt8CQ8EdoxqPKdLainpVoU5Rt6RtEv0/N6SHpU0Enhe0rDkRIaShkvaLyXG/0r6XdLybZIOyhSLwvwKryjM0/Fh4lxEf38RnYu3o9iSj9U0Ov5HCskDW6U5X7+V9Fr0/PsU8hK5xqgUVx76zW/1uQFLWHal6ljg4Gj9HsBrhLQVTydtb0Cv6P75RPMzALcBB0X3V03a/g5gn+j+i8BV0f2ewHPR/VZAy+j++sDo6P7OJM1pAJwJ3BLd3xD4knC1dm/CVcCJK8t3Ah6O7q8MfEE0r0rSvv4A3B7db07INFCbI5YfgbWT9vFD9Lcp0Ca6345w5bgINSMDto8euwX4W9K56BFt/zKwUrT+bOD8cr8v/FaemzdDuUqWthnKzJ6V9EdCWoPNkh5aCtwT3b8TSJdobRdJZxG+eFclpG14LHossf0YwpcpQDNgsKTNCYXXBhli3QG4NorvY0mTkrZ91sy+ix57SSHxXHvgQOABW7Fp6ing6iif1V7Ay2Y2X9LKWWJ508y+SBOXgEsl/YZwfjqyLI37ZDMbFd2/EzgFuDLpudsBGwGjogpYc0Ih7RohLyxcgyOphjBz3zxgFcIv93SWy2UjqSXwH0K+nMmSLiD8+k9YEP1dwrLPxumEXFibEZptf6pHyD+mLA8DDiPUjI5aIWiznxQy4+4JHEyYrChXLKnHSOgFtAe2MrNFkiay7H9OzfWTuixCQffnDPt2jYj3WbiG6HRCVtRDgVsV0jZDeD8nRj0dCvwv5XmJL8mZUdt7nBFSKwNfmdlS4HDCFKUAcwlTWya8QvhiRtIGQBcg08yCtwGnAZhZpuy39xAKkh2Bp3PEkiv+6VFBsQvQNemxLpJ+Hd1Pd75eB7aXtF70f60U/W+uEfLCwlWy2pShswOjju1jgTPN7BVCm/p50fY/AttEQ0J3JWRV/ZmZzQKGEtK5jyCk7s7lP8CRkt4l9EUkfsG/ByxRmC3t9Gi7GknjCF/0vc1sQbodmtk3hMLu1izHfYbQv/GchalQs8WSzXCgRxTXEcDHSY+NB06S9BGhhnZ9SpwzCH0ud0t6j9AEtWGMY7oq5FlnXdWQ9IOZVfxonWjU0ThgSzObXe54nIvDaxbOlZCk3Qm1imu9oHANidcsnHPO5eQ1C+ecczl5YeGccy4nLyycc87l5IWFc865nLywcM45l9P/Ax5VGgR5b3YBAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss function"
      ],
      "metadata": {
        "id": "TsCcLtocYK6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In ML, it is usual to call *loss* to the **dissimilarity** between actual and predicted label values for a *set* of labeled examples.\n",
        "\n",
        "Let ${\\rm \\bf x}_1, \\dots , {\\rm \\bf x}_n$ be a set of examples with labels $y_1, \\dots , y_n$. Let $f_{\\rm \\bf w}$ be our model. Therefore, the predicted labels are \n",
        "\n",
        "$$\\hat{y}_1=f_{\\rm \\bf w}({\\rm \\bf x}_1), \\dots, \\hat{y}_n=f_{\\rm \\bf w}({\\rm \\bf x}_n).$$\n",
        "\n",
        "The loss over that set of examples is some dissimilarity measure between the actual labels $y_1, \\dots , y_n$ and the predicted labels $\\hat{y}_1, \\dots , \\hat{y}_n$.\n",
        "\n"
      ],
      "metadata": {
        "id": "Bp8K-cntPVfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example (simple linear regression)\n"
      ],
      "metadata": {
        "id": "cM7AZbYpYeRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "For the linear regression example, the response variable is continuous. We wish to measure the dissimilarity between the set of actual label values $y_1, \\dots , y_n$  and the set of values predicted by the model \n",
        "$f_{\\rm a,b}(x)= a \\, x + b$: \n",
        "\n",
        "$$\\hat{y}_1=a\\, x_1+ b, \\dots, \\hat{y}_n=a\\, x_n+ b.$$\n",
        "\n",
        "Since the response is continuous, it makes sense to use a function like:\n",
        "\n",
        "1. Mean absolute error (MAE), given by $\\sum_{i=1}^n |y_i-\\hat{y}_i|$; or\n",
        "\n",
        "2. Mean square error (MSE), given by $\\frac{1}{n}\\sum_{i=1}^n \\left(y_i-\\hat{y}_i\\right)^2$."
      ],
      "metadata": {
        "id": "L2buuqntYha_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example (quadratic regression)"
      ],
      "metadata": {
        "id": "2WgfmI8oavMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In notebook [Lesson3_edited_04-how-does-a-neural-net-really-work.ipynb](Lesson3_edited_04-how-does-a-neural-net-really-work.ipynb), loss was given by MAE, i.e. $\\sum_{i=1}^n |y_i-\\hat{y}_i|$."
      ],
      "metadata": {
        "id": "FE79yyV8a1hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(preds, acts): return (torch.abs(preds-acts)).mean()"
      ],
      "metadata": {
        "id": "P2hSIz50ckp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The notebook includes code to interactively change the parameter values and compute the MAE loss function for the data set for an arbitrary choice of weights $(a,b,c)$.\n",
        "\n",
        "Function `partial` in the code below converts the 4-argument function $f(x,a,b,c)$ into a one argument function $f(x;a,b,c)=f_{\\rm a,b,c}(x)$. Therefore, `mk_quad` corresponds to the one argument function $f_{\\rm a,b,c}(x)$. Hence it can be passed to `plot_function` which expects a one argument function.\n",
        "\n"
      ],
      "metadata": {
        "id": "Mz8gGbFccln_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.basics import * # necessary for partial\n",
        "def quad(a, b, c, x): return a*x**2 + b*x + c\n",
        "def mk_quad(a,b,c): return partial(quad, a,b,c)\n",
        "def plot_function(f, title=None, min=-2.1, max=2.1, color='r', ylim=None):\n",
        "    x = torch.linspace(min,max, 100)[:,None]\n",
        "    if ylim: plt.ylim(ylim)\n",
        "    plt.plot(x, f(x), color)\n",
        "    if title is not None: plt.title(title)\n",
        "# interactive plot\n",
        "from ipywidgets import interact\n",
        "@interact(a=1.1, b=1.1, c=1.1) # this is called a decorator\n",
        "def plot_quad(a, b, c):\n",
        "    f = mk_quad(a,b,c)\n",
        "    plt.scatter(x,y)\n",
        "    loss = mae(f(x), y)\n",
        "    plot_function(f, ylim=(-3,12), title=f\"MAE: {loss:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377,
          "referenced_widgets": [
            "287b831a2015472ca1ad96be2344a838",
            "5037df45e75347b999912f5ff8148050",
            "242053e6c5fe49e9b821e592142baa86",
            "0294731999604d828d2f6db099524643",
            "b56866f8cd04425090c8847432d99030",
            "0ad66d52b29b4132880bc2c3878bb0cc",
            "7eb98727910e4732a7a0961c9024160c",
            "6fb1bc9c4e4940fea7bd973249e4c294",
            "468087a33c8d482bb2cd7bdbe0ab01c5",
            "af0c9f2494794d8faf9647863eb50e61",
            "cdd35afc8efb4be9ae8fd575d1009bc5",
            "454e8a074fa54e4c93a2e75e611c5e13",
            "003db380868741ce917469e6dd6b746d"
          ]
        },
        "id": "PoOuvmF9bHM4",
        "outputId": "8a86cddb-3408-4ace-a71e-56c81e087cc5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(FloatSlider(value=1.1, description='a', max=3.3000000000000003, min=-1.1), FloatSlider(vâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "287b831a2015472ca1ad96be2344a838"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dissimilarity measures to define *loss*"
      ],
      "metadata": {
        "id": "9dLMWMHcYlvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To define loss, we then need to choose an appropriate dissimilarity metric between a set of actual $y_1, \\dots , y_n$ and predicted labels $\\hat{y}_1, \\dots , \\hat{y}_n$. The choice depends on the type of problem, and while MAE or RMSE are adequate for *regression* problems, other dissimilarities are used for *classification* problems.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JaP8Ef2zYo24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples of loss functions for regression problems (MAE, MSE, Huber)\n",
        "\n"
      ],
      "metadata": {
        "id": "TazkXj5DYsdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, two common loss functions for regression problems were listed\n",
        "\n",
        "1. Mean absolute error (MAE), given by $\\sum_{i=1}^n |y_i-\\hat{y}_i|$; or\n",
        "\n",
        "2. Mean square error (MSE), given by $\\frac{1}{n}\\sum_{i=1}^n \\left(y_i-\\hat{y}_i\\right)^2$\n",
        "\n",
        "In the one hand, MAE is not differentiable everywhere, which is an undesirable property for ML. On the other hand, MSE penalizes too much large differences between actual and predicted values, which means that a single example can constraint strongly the solution. \n",
        "\n",
        "An alternative is called the Huber loss function, which is differentiable everywhere, and behaves like MSE near the origin and like MAE for large $|y_i-\\hat{y}_i|$.\n"
      ],
      "metadata": {
        "id": "WlJNpKjwWRLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of loss functions for classification problems (cross-entropy)"
      ],
      "metadata": {
        "id": "Fsp3Fh9KYwCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification problems have categorical labels. Therefore, the model predictions should return the most likely label for each example. \n",
        "\n",
        "While in regression, the model's output is typically an unbounded response variable (for instance, it is $f(x;a,b) = a\\, x + b$ in simple linear regression), for classification problems, it is more convenient to have:\n",
        "1. one output per label;\n",
        "2. each output being a value between 0 and 1 that can be interpreted as the probability of the label.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1iD519g8QbBmOGp9SiOQsIneJnWg53SMQ\" width=\"600\" >\n",
        "\n",
        "Therefore, it is usual to have a model that outputs $f_1({\\rm \\bf x};{\\rm \\bf w_1}), \\dots , f_k({\\rm \\bf x};{\\rm \\bf w_k})$ for each of the $k$ possible labels, and an additional model component that converts those *raw* outputs into probability-like values for the labels.\n",
        "\n",
        "You saw that kind of probabilistic output when you trained and deployed an image classifier in notebook [Lesson2_edited_book_02_production.ipynb](Lesson2_edited_book_02_production.ipynb). When you did predict the label for a new example with\n",
        "\n",
        "    learn_inf.predict('images/grizzly.jpg'),\n",
        "\n",
        "you got a vector of estimated probabilities like the following:\n",
        "\n",
        "    ('grizzly', tensor(1), tensor([9.0767e-06, 9.9999e-01, 1.5748e-07])).\n",
        "\n",
        "where the values `9.0767e-06, 9.9999e-01, 1.5748e-07` correspond, respectively, to labels *black*, *grizzly* and *teddy*.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NHRyajD_N6hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Softmax \n",
        "\n"
      ],
      "metadata": {
        "id": "iPE1rlP3fzTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The unormalized model outputs $f_1, \\dots, f_k$ are called *logits* or *raw* outputs. Each $z_i=f_i({\\rm \\bf x};{\\rm \\bf w_i})$ is converted into a [0,1] value by the *softmax* function:\n",
        "\n",
        "$$p_j=\\frac{\\exp(z_j)}{\\sum_{i=1}^k \\exp(z_i)} âˆˆ [0,1].$$\n",
        "\n",
        "After that transformation, the classification model's output is a vector of values $(p_1,\\dots,p_k)$, with $p_i \\ge 0$ and $\\sum p_i=1$ as required for  probability distributions. The predicted label is the one with highest $p$.\n"
      ],
      "metadata": {
        "id": "9g9P9qwTf18P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing target and predicted probability distributions\n",
        "\n"
      ],
      "metadata": {
        "id": "B-r4_0PVfthi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While in the regression problem the loss is a dissimilarity between the actual labels $y_1,\\dots,y_n$ and the predicted labels $\\hat{y}_1,\\dots,\\hat{y}_n$ for the set with $n$ examples, in classification with *softmax* the loss is then a dissimilarity between the actual labels $y_1,\\dots,y_n$ and the $n$ probability vectors $(p_1,\\dots,p_k)_1, \\dots, (p_1,\\dots,p_k)_n$.\n",
        "\n",
        "To compare vectors of the same dimension, one can express each target label $y_i$ as a probabilitity distribution with 0 uncertainty. Suppose that there are 3 different possible labels and the actual label of the example is the first label: then, the *target distribution* would be $(1,0,0)$ which can be  compared with the model's output probability distribution $(p_1,p_2,p_3)$. This will be illustrated with an example below.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "86MG2Jplf8LX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loss functions in fastai\n",
        "\n"
      ],
      "metadata": {
        "id": "JeIWFIf1gCoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A list of `fastai` loss functions is available in https://docs.fast.ai/losses.html. In general, they are simple adaptations of `pytorch` loss functions listed in https://pytorch.org/docs/stable/nn.html#loss-functions.  The most common *loss* function for classification is called *cross-entropy*. Notebook [Lesson1_00_is_it_a_bird_creating_a_model_from_your_own_data.ipynb](Lesson1_00_is_it_a_bird_creating_a_model_from_your_own_data.ipynb) creates the learner with:\n",
        "\n",
        "    learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
        "\n",
        "`vision_learner` allows to explicitely define the loss function  with the argument `loss_func`. Since it is not explicitely defined in the code above, we can check the default which is stored in property `loss_func`:\n",
        "\n",
        "    learn.loss_func\n",
        "\n",
        "which returns `FlattenedLoss of CrossEntropyLoss()`. This `fastai` loss is described in the Pytorch documentation as the `nn.CrossEntropyLoss` class  [https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). Hence, the loss function that is applied in the example in the notebook is  `torch.nn.CrossEntropyLoss` that computes the cross entropy loss between input logits and target. \n",
        "\n"
      ],
      "metadata": {
        "id": "iPfaq5EUgOR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-entropy\n",
        "\n"
      ],
      "metadata": {
        "id": "qq_PFJW3gGcn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, what is the *loss* you see in the output when you train an image classifier in notebook [Lesson2_edited_book_02_production.ipynb](Lesson2_edited_book_02_production.ipynb)?\n",
        "\n",
        "    epoch \ttrain_loss \tvalid_loss \terror_rate \ttime\n",
        "    0          1.174910        0.043982      0.009091     00:34\n",
        "\n",
        "\n",
        "Suppose that your model (`resnet`) was trained to classify photos of bears into *black*, *grizzly* and *teddy* as in [Lesson2_edited_book_02_production.ipynb](Lesson2_edited_book_02_production.ipynb). The last layer of the model outputs the values of three functions $f_1, f_2, f_3$, where $f_1$ is associated to *black*, $f_2$ is associated to *grizzly* and $f_3$ is associated to *teddy*. The values $(z_1,z_2,z_3)$ of the function for some input and for your trained model are the so-called *logits* or *raw* outputs. \n",
        "\n",
        "The code below creates an example of the outputs for a *batch* of 4 examples. In the matrix below each row is an example and each column is a label. Consider that column 1 is for *black*, column 2 is for *grizzly* and column 3 is for *teddy*."
      ],
      "metadata": {
        "id": "lqWLiFHzgJjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "raws=torch.tensor([[4.5,2.1,0.2],\n",
        "                   [1.3,8.3,0.8],\n",
        "                   [1.2,1.5,4.2],\n",
        "                   [5.1,0.4,2.3]])"
      ],
      "metadata": {
        "id": "pYMCDHdArmrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ikv6xMwCYSAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the tensor above, it looks like the first and fourth examples have a higher likelihood of being photos of *black* bears, while the second example is more likely a *grizzly* bear and the third one seems to be a *teddy* bear photo. Let's apply *softmax* to convert the raw outputs into probability-like values."
      ],
      "metadata": {
        "id": "9N7exOe4L6Y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " softs = raws.softmax(dim=1)\n",
        " torch.set_printoptions(sci_mode=False)\n",
        " softs"
      ],
      "metadata": {
        "id": "_JktsXREIxvg",
        "outputId": "40f4c65a-fadc-4b6a-c9fe-84dca1ab5454",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    0.9056,     0.0822,     0.0123],\n",
              "        [    0.0009,     0.9985,     0.0006],\n",
              "        [    0.0446,     0.0602,     0.8953],\n",
              "        [    0.9347,     0.0085,     0.0568]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clear that the softmax rule did amplify the difference in values for each example. In each row there is one value close to 1 and the remainder values are close to 0. For each example, *cross-entropy* compares the target distribution with the probability distribution returned by *softmax*. \n",
        "\n",
        "Let's suppose that in fact, the first and last examples have actually label *black*, the second is actually *grizzly* and the third is actually *teddy*. Then the target distribution will be 1 for the correct label and 0 for the remaining labels. This is known as  *one-hot encoding* and it's illustrated by the rows of the following tensor (each row is one example):"
      ],
      "metadata": {
        "id": "q-ok5s3pMwFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target=torch.tensor([[1.,0.,0.],\n",
        "                     [0.,1.,0.],\n",
        "                     [0.,0.,1.],\n",
        "                     [1.,0.,0.]])"
      ],
      "metadata": {
        "id": "5MLo9NugNaLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-entropy loss measures the dissimilarity between the probability distribution returned by *softmax* $(p_1,p_2,p_3)$ and the target distribution $(t_1,t_2,t_3)$ for the $i$-th example with the expression, and takes values between 0 (optimal value associated to minimum uncertainty) and 1 (maximum value associated to maximum uncertainty, i.e. all probabilities are equal):\n",
        "\n",
        "$$L_i=-\\left( t_1 \\, \\log(p_1) + t_2 \\, \\log(p_2) + t_3 \\, \\log(p_3) \\right) \\in [0,1].$$\n",
        "\n",
        "In the expression above, we suppose that the probabilities are non zero. \n",
        "For the whole batch of $n$ examples, the cross-entropy loss is given by the average of the $n$ individual loss values:\n",
        "\n",
        "$$L=\\frac{1}{n} \\left( L_1+L_2+ \\dots,L_n\\right).$$\n",
        "\n",
        "This can be computed with `nn.CrossEntropyLoss()` directly from the *raw* and *target* values as shown below:"
      ],
      "metadata": {
        "id": "2ziX1cVzOkaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "# compute loss\n",
        "loss = nn.CrossEntropyLoss()\n",
        "output = loss(raws, target)\n",
        "print('Cross Entropy Loss: ', output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIbwzbeJp7Vg",
        "outputId": "33f64b4d-0208-46bc-973c-12c428bc61c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Entropy Loss:  tensor(0.0697)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ML as an optimization problem\n"
      ],
      "metadata": {
        "id": "BZmxXfDFYx3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now, we can define a ML problem as a optimization problem. Given\n",
        "\n",
        "1.  a set of examples  ${\\rm \\bf x}_1, \\dots , {\\rm \\bf x}_n$  with labels $y_1, \\dots , y_n$\n",
        "2. a model $f_{\\rm \\bf w}$\n",
        "3. a *loss* function $L$\n",
        "\n",
        "the goal is to determine the optimal set of parameters ${\\rm \\bf w}$ that minimize the loss $L$ over that set of examples.\n",
        "\n",
        "## Training and validation sets\n",
        "\n",
        "To prevent *overfitting* the parameters to the set of examples, an independent set of examples for *validation* are set apart. In general, the example data set with $N$ examples is partitioned into a subset with, say $0.2 \\times N$ examples for validation and $0.8 \\times N$ examples for training like we saw in [Lesson2_edited_book_02_production.ipynb](Lesson2_edited_book_02_production.ipynb):\n",
        "\n",
        "    bears = DataBlock(\n",
        "        blocks=(ImageBlock, CategoryBlock), \n",
        "        get_items=get_image_files, \n",
        "        splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "        get_y=parent_label,\n",
        "        item_tfms=Resize(128))\n",
        "\n",
        "where `RandomSplitter(valid_pct=0.2, seed=42)` indicates that 20% of the examples are used for validation.\n",
        "\n",
        "The *training* data set is used to search for the optimal set of weights for the model, typically by iteratively updating the weights from a initial set of weights using *gradient descent* over the loss. The *validation* data set is used to compute the same loss metric over an independent set of examples.\n",
        "\n",
        "By comparing the training and validation losses it is possible to assess issues in model behaviour like *high bias/underfitting*,  *high variance/overfitting*,  and *unrepresentativeness* of either training or validation set.\n",
        "\n",
        "## Gradient descent and learning rate\n",
        "\n",
        "Informally, a gradient measures how much the output of a function changes if you change the inputs a little bit.\n",
        "\n",
        "Given a model $f_{\\rm \\bf w}({\\rm \\bf x})= f({\\rm \\bf x}; {\\rm \\bf w})$ and a batch of examples ${\\rm \\bf x_1}, \\dots, {\\rm \\bf x_n}$, we have seen how we can define a *loss* function \n",
        "\n",
        "$$L({\\rm \\bf x_1, \\dots, x_n; w})= L_{\\rm \\bf x_1, \\dots, \\rm \\bf x_n}(\\rm \\bf w).$$ \n",
        "\n",
        "We can write $L$ just a function of the weights since the ${\\rm \\bf x_i}$ are fixed for given batch of examples. Our goal is to find the set of weights ${\\rm \\bf w}$ that minimize $L({\\rm \\bf w})$. In order to do this iteratively, starting with an arbitrary set of initial weights, we would like to know how $L$ changes with a small change in the weights $\\rm \\bf w$ from the current set weights ${\\rm \\bf w}^{*}$.\n",
        "\n",
        "This  is given by the gradient of $L$ with respect to ${\\rm \\bf w}$ at ${\\rm \\bf w}^{*}$, which is a vector with length equal to $m$=number of model parameters.\n",
        "\n",
        "$$ \\nabla L({\\rm \\bf w}^{*}) = \\frac{\\partial L}{\\partial \\rm \\bf w}({\\rm \\bf w}^{*})= \\left(\\frac{\\partial L}{\\partial \\rm w_1}({\\rm \\bf w}^{*}), \\dots,  \\frac{\\partial L}{\\partial \\rm w_m}({\\rm \\bf w}^{*}) \\right).$$\n",
        "\n",
        "\n",
        "The vector $\\nabla L({\\rm \\bf w}^{*})$ points to the direction from ${\\rm \\bf w}^{*}$ along which $L$ grows faster, so gradient descent follows the opposite direction $ - \\nabla L({\\rm \\bf w}^{*})$. \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1-KGjbUaR1l3z879V_eJu7JutnSutqbdC\" width=\"500\" >\n",
        "\n",
        "\n",
        "\n",
        "The steps of gradient descent algorithm are the following, when all examples are visited before updating the set of weights. In ML, one *epoch* corresponds to the processing of the totally of examples in the data set. So, for instance, if the algorithm runs for 20 epochs, tem the model is applied to all examples 20 times.\n",
        "\n",
        "---\n",
        "\n",
        "1. Choose an initial set of weights ${\\rm \\bf w}^{*}$\n",
        "\n",
        "2. For $i = 1, \\dots, E$, where $E$ is the number of epochs, do:\n",
        "\n",
        "   i) Cumpute $\\nabla L({\\rm \\bf w}^{*})$\n",
        "\n",
        "   ii) Update ${\\rm \\bf w}^{*}:={\\rm \\bf w}^{*} - \\eta \\, \\nabla L({\\rm \\bf w}^{*}) $, where $\\eta >0 $ is the learning rate.\n",
        "\n",
        "---\n",
        "\n",
        "The choice of the *learning rate* is critical for a good performance of the algorithm. A very small learning rate will permit a good approximation of the gradient flow by the algorithm (see next figure). But if the step is too small, many epochs will be needed to get a good solution. \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=12c4X3po4-xVGUJKzyKC56lwl4ZEmXqWa\" width=\"400\" >\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ML practicioners use many different techniques to determine the *learning rate*. In particular, the learning rate can be adaptive and change along epochs, which is a standard approach in ML. An adaptive learning rate is provided by the `fine_tune` method used in   [Lesson1_02_saving_a_basic_fastai_model.ipynb](Lesson1_02_saving_a_basic_fastai_model.ipynb):\n",
        "\n",
        "    learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
        "    learn.fine_tune(3)\n",
        "\n",
        "## Mini-Batch Gradient Descent applied to simple linear regression\n",
        "\n",
        "The description above of the gradient descent algorithm is for the simplest case, where weights are updated once per epoch. This is called *batch gradient descent*. Things get a bit more envolved if one wants to group examples in smaller batches and update the weights after each batch, which is the most common approach in ML. There is another alternative, called *stochastic gradient descent*, where weights are updated after each single example (this is the particular case of a mini-batch of size 1).\n",
        "\n",
        "Next, we create from scratch a gradient descent for the very simple linear regression problem, and we compare the result with the optimal least squares regression. The code shows how *training loss* and *validation loss* are computed. It also illustrates how weights update are done after each mini-batch of data, which is known as *Mini-Batch Gradient Descent*.\n",
        "\n",
        "The most specific part of the algorithm is the gradient computation. Note that the *gradient machinery* of `pytorch` is turned-on for each weight with `requires_grad = True` as in the following case:\n",
        "\n",
        "    coeffs=torch.tensor([-20.,-10.]).requires_grad_()\n",
        "\n",
        "Then, the *loss* $L$ is defined as a function (that can be arbitrarily complicated) of the weights, and the *gradient* $\\nabla L({\\rm \\bf w}^{*})$ for the current set of weights ${\\rm \\bf w}^{*}$ is computed with \n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "Finally, the weights are updated with \n",
        "\n",
        "    coeffs.sub_(coeffs.grad * step_size)\n",
        "\n",
        "where method `sub_` computes the substraction in weight updating ${\\rm \\bf w}^{*}:={\\rm \\bf w}^{*} - \\eta \\, \\nabla L({\\rm \\bf w}^{*})$, and  the learning rate $\\eta$ is called `step_size` in the code.\n"
      ],
      "metadata": {
        "id": "1fG2E4DuYzu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "torch.manual_seed(42)\n",
        "\n",
        "B=20 # batch size\n",
        "step_size = 0.1 # learning rate\n",
        "iter=20 # number epochs\n",
        "\n",
        "############################################ Creating synthetic data\n",
        "# Creating a function f(X) with a slope of -5\n",
        "X = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
        "func = -5 * X + 2\n",
        "# Adding Gaussian noise to the function f(X) and saving it in Y\n",
        "y = func + 0.4 * torch.randn(X.size())\n",
        "\n",
        "##################################### Create train and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "########################################## Linear regression LS solution\n",
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression().fit(X, y)\n",
        "print('coefficients:',reg.coef_,reg.intercept_)\n",
        "\n",
        "####################################################### Gradient Descent\n",
        "# initial weights\n",
        "coeffs=torch.tensor([-20.,-10.]).requires_grad_() \n",
        "\n",
        "# defining the function for prediction (linear regression)\n",
        "def calc_preds(x): return coeffs[0] + coeffs[1] * x \n",
        "\n",
        "# evaluating data points with Mean Square Error (MSE)\n",
        "def calc_loss_from_labels(y_pred, y): return torch.mean((y_pred - y) ** 2)\n",
        "\n",
        "# lists to store losses for each epoch\n",
        "training_losses=[]; validation_losses=[]\n",
        "\n",
        "# epochs\n",
        "for i in range(iter):\n",
        "  # calculating loss as in the beginning of an epoch and storing it\n",
        "    y_pred = calc_preds(X_train)\n",
        "    training_losses.append(calc_loss_from_labels(y_pred, y_train).tolist())\n",
        "    y_pred = calc_preds(X_valid)\n",
        "    validation_losses.append(calc_loss_from_labels(y_pred, y_valid).tolist())\n",
        "    # mini-batch gradient descent: weight are updated after each batch\n",
        "    for idx_start in np.arange(0,X_train.shape[0],B):\n",
        "        # create batch\n",
        "        batch_X=X_train[idx_start:(idx_start+B),:]\n",
        "        batch_y=y_train[idx_start:(idx_start+B),:]\n",
        "        # making a prediction in forward pass\n",
        "        y_pred = calc_preds(batch_X)\n",
        "        # calculating the loss between predicted and actual values\n",
        "        loss = calc_loss_from_labels(y_pred, batch_y)\n",
        "        # compute gradient\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            # update coeffs\n",
        "            coeffs.sub_(coeffs.grad * step_size)\n",
        "            # zerofy gradients (because they add up)\n",
        "            coeffs.grad.zero_()\n",
        "\n",
        "print('batch size:', B)\n",
        "print('coeffs found bt gradient descent:',coeffs.requires_grad_(False))\n",
        "plt.plot(training_losses, '-g',  validation_losses, '-r')\n",
        "plt.gca().legend(('train','validation'))\n",
        "plt.ylim(0, 5)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss (MSE)')\n",
        "#plt.title(\"Train (green) and validation (red) losses\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "sS0Uki84xoHN",
        "outputId": "ccd186da-319b-4162-de2d-ac72c14ffdd3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coefficients: [[-5.0023813]] [2.0237875]\n",
            "batch size: 20\n",
            "coeffs found bt gradient descent: tensor([ 2.0390, -5.0677])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEKCAYAAAAYd05sAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAg40lEQVR4nO3de3xcdZ3/8denyaRJ00LTNr2ztMVum6aUNp0ga7kX2YKKgkBRQcFLH4so9LHrz63oetnVB7r6Q2RFEBQXtYDYWnFdkIsWgZ8CTaHU3qQtFGkLTVLa9N7m8vn9cU5CGiaXJnPmzEzez8djHpmZc86cTyaTd775nu/5HnN3REQk/wyIuwAREYmGAl5EJE8p4EVE8pQCXkQkTyngRUTylAJeRCRPFUb54ma2BdgLNANN7p6Mcn8iIvKWSAM+dI6712dgPyIi0o66aERE8pRFeSarmb0C7AIc+KG735linQXAAoDS0tLZU6dOjayerNLQAJs2saEcpv7d7LirEZEctXLlynp3L0+1LOqAH+fu28xsJPAY8Fl3f7Kz9ZPJpNfU1ERWT1Z5+GG48ELe9UnjT3e1xF2NiOQoM1vZ2fHNSLto3H1b+LUWWAacGuX+ckoiAUBBs9PiCngRSb/IAt7MSs1sSOt94HxgTVT7yzlhwCeaobmlOeZiRCQfRTmKZhSwzMxa93Ovu/8uwv3lltaAb4GmliYSBYmYCxKRfBNZwLv7y8ApUb1+zmvXgm9qaYq5GJH0a2xsZOvWrRw6dCjuUvJCcXEx48ePJ5HoeWMwE+PgJZUOLXiRfLN161aGDBnChAkTCP+Tl15yd3bu3MnWrVuZOHFij7fTOPi4qAUvee7QoUMMHz5c4Z4GZsbw4cOP+b8hBXxc1IKXfkDhnj69eS8V8HFRC15EIqaAj4ta8CKR2r17Nz/4wQ+OebsLL7yQ3bt3p7+gGCjg4xIGfKECXiQSnQV8U1PXv28PPfQQQ4cOjaiqzNIomrgUBm+9umhEorFo0SI2b97MzJkzSSQSFBcXU1ZWxoYNG3jppZf4wAc+wGuvvcahQ4e44YYbWLBgAQATJkygpqaGffv2ccEFF3D66afzpz/9iXHjxvHggw9SUlIS83fWcwr4uKiLRvqRhb9byKo3VqX1NWeOnskt827pdPk3v/lN1qxZw6pVq3jiiSd4z3vew5o1a9qGGd59990MGzaMgwcPUl1dzQc/+EGGDx9+1Gts3LiR++67j7vuuovLL7+cpUuXcuWVV6b1+4iSAj4uOsgqklGnnnrqUWPIb731VpYtWwbAa6+9xsaNG98W8BMnTmTmzJkAzJ49my1btmSq3LRQwMdFLXjpR7pqaWdKaWlp2/0nnniCxx9/nD//+c8MGjSIs88+O+UY84EDB7bdLygo4ODBgxmpNV10kDUuBQWAWvAiURkyZAh79+5NuayhoYGysjIGDRrEhg0beOaZZzJcXWaoBR8XM1oShSRamhTwIhEYPnw4c+bMYfr06ZSUlDBq1Ki2ZfPmzeOOO+6goqKCKVOmcNppp8VYaXQU8DHywkISzQp4kajce++9KZ8fOHAgDz/8cMplrf3sI0aMYM2at2Y4/9znPpf2+qKmLpoYeaJQffAiEhkFfIyCFrwCXkSioYCPkVrwIhIlBXycChOaqkBEIqOAj5En1EUjItFRwMepMOiiaWxpjLsSEclDCvg4JRJqwYtkicGDBwOwfft2Lr300pTrnH322dTU1HT5OrfccgsHDhxoexzn9MMK+DglEjrIKpJlxo4dy5IlS3q9fceAj3P6YQV8jCxRpBa8SEQWLVrEbbfd1vb4q1/9Kl//+teZO3cuVVVVnHzyyTz44INv227Lli1Mnz4dgIMHD3LFFVdQUVHBxRdffNRcNNdeey3JZJLKykq+8pWvAMEEZtu3b+ecc87hnHPOAYLph+vr6wG4+eabmT59OtOnT+eWW25p219FRQWf+tSnqKys5Pzzz0/bnDc6kzVORWrBSz+xcCGsWpXe15w5E8KQTGX+/PksXLiQ6667DoAHHniARx55hOuvv57jjjuO+vp6TjvtNC666KJOr3d6++23M2jQINavX8/q1aupqqpqW/aNb3yDYcOG0dzczNy5c1m9ejXXX389N998M8uXL2fEiBFHvdbKlSv5yU9+wrPPPou78853vpOzzjqLsrKyyKYlVgs+RmrBi0Rn1qxZ1NbWsn37dl588UXKysoYPXo0N954IzNmzOC8885j27Zt7Nixo9PXePLJJ9uCdsaMGcyYMaNt2QMPPEBVVRWzZs1i7dq1rFu3rst6nn76aS6++GJKS0sZPHgwl1xyCU899RQQ3bTEasHHyNQHL/1FFy3tKF122WUsWbKEN954g/nz57N48WLq6upYuXIliUSCCRMmpJwmuDuvvPIK3/nOd1ixYgVlZWVcffXVvXqdVlFNS6wWfIysSC14kSjNnz+f+++/nyVLlnDZZZfR0NDAyJEjSSQSLF++nFdffbXL7c8888y2CcvWrFnD6tWrAdizZw+lpaUcf/zx7Nix46iJyzqbpviMM87g17/+NQcOHGD//v0sW7aMM844I43f7dupBR8jSxSpBS8SocrKSvbu3cu4ceMYM2YMH/nIR3jf+97HySefTDKZZOrUqV1uf+2113LNNddQUVFBRUUFs2fPBuCUU05h1qxZTJ06lRNOOIE5c+a0bbNgwQLmzZvH2LFjWb58edvzVVVVXH311Zx66qkAfPKTn2TWrFmRXiXK3D2yFz9WyWTSuxtjmk/8sktZ/8RSliz5Gl8+68txlyOSVuvXr6eioiLuMvJKqvfUzFa6ezLV+uqiiZElijQXjYhERgEfJx1kFZEIKeDjVFhIkQJe8lg2dQHnut68lwr4OCUSJJpNAS95qbi4mJ07dyrk08Dd2blzJ8XFxce0nUbRxEldNJLHxo8fz9atW6mrq4u7lLxQXFzM+PHjj2kbBXycNJuk5LFEIsHEiRPjLqNfUxdNnBIJCltcAS8ikYg84M2swMxeMLPfRr2vnKMWvIhEKBMt+BuA9RnYT+5JJChwaG7SFZ1EJP0iDXgzGw+8B/hRlPvJWYkEAN54JOZCRCQfRd2CvwX4PNDS2QpmtsDMasyspt8dbW8LeLXgRST9Igt4M3svUOvuK7taz93vdPekuyfLy8ujKic7qQUvIhGKsgU/B7jIzLYA9wPnmtnPI9xf7gkDHrXgRSQCkQW8u3/B3ce7+wTgCuAP7t73a1DlEwW8iERI4+DjVBicZ6YuGhGJQkbOZHX3J4AnMrGvnKIWvIhESC34OIUBb4060UlE0k8BHye14EUkQgr4OLW24JvUgheR9FPAx0ldNCISIQV8nNSCF5EIKeDjpBa8iERIAR8nteBFJEIK+Di1BXxzzIWISD5SwMcpDPgBCngRiYACPk5qwYtIhBTwcQrnohmgPngRiYACPk5tXTSdXg9FRKTXFPBxCgO+QF00IhIBBXycdJBVRCKkgI9Tawu+WV00IpJ+Cvg4teuDd/eYixGRfKOAj1MY8IlmaHG14kUkvRTwcWoN+BZoatFQSRFJLwV8nAoKAChUwItIBBTwcTKjubCARLMCXkTSTwEfs5bCAnXRiEgkFPAxa1ELXkQiooCPmRcMINECjS268LaIpJcCPmYtiUK14EUkEgr4mLn64EUkIgr4mLUUqgUvItFQwMfME4VqwYtIJBTwMXO14EUkIgr4uKkFLyIRUcDHzAsTmqpARCKhgI+bhkmKSEQU8DHzREJdNCISCQV83BIJteBFJBIK+LipBS8iEYks4M2s2MyeM7MXzWytmX0tqn3lNA2TFJGIFEb42oeBc919n5klgKfN7GF3fybCfeYcUwteRCLSo4A3syRwBjAWOAisAR5z912dbePBVaT3hQ8T4U1Xlu4oUaQWvIhEossuGjO7xsyeB74AlAB/BWqB04HHzeweM/u7LrYvMLNV4TaPufuzKdZZYGY1ZlZTV1fXh28lN1mRWvAiEo3uWvCDgDnufjDVQjObCUwG/pZqubs3AzPNbCiwzMymu/uaDuvcCdwJkEwm+10L39SCF5GIdBnw7n5bN8tX9WQn7r7bzJYD8wi6dyRkiSK14EUkEt110TzQ7v63Oix7tJtty8OWO2ZWArwb2NDrSvOUFakFLyLR6G6Y5OR299/dYVl5N9uOAZab2WpgBUEf/G+Psb68Z4kizUUjIpHorg++qz7xLvvL3X01MOuYK+pnrGigumhEJBLdHmQ1s1kELf2S8L6Ft5Koi+sPBhQVUaguGhGJQHcB/wZwc4r7rY+lj6xoIIUOTc2NcZciInmmu1E0Z2eojn5rQNFAAFqOHI65EhHJN92Noqk2s9HtHn/UzB40s1vNbFj05eW/AYkiAFoOK+BFJL26G0XzQ+AIgJmdCXwT+CnQQHhykvRNa8B745GYKxGRfNNdH3yBu78Z3p8P3OnuS4Gl4RQE0kdWFLbg1UUjImnWXQu+wMxa/wjMBf7QblmUM1H2H4kEoBa8iKRfdyF9H/BHM6snmEXyKQAzewdBN430VRjwHNEoGhFJr+5G0XzDzH5PcFbqo+EUwBC0/D8bdXH9glrwIhKRLgM+HCnzUngbaGYDw0X14U36qi3g1YIXkfTqroumHtgKtJ5mae2WOTApiqL6lTDgm48cirkQEck33QX8rcA5wP8j6I9/ul03jaRDGPA7dm+NuRARyTddjqJx94XATOCXwFXAC2b2n2Y2MfrS+okw4F+t3xxzISKSb7obJokHlgOfB+4ArgHOi7qwfiMM+L373mTngZ0xFyMi+aS7qQpKzezDZvYg8BAwGJjt7ndlpLr+IAz4RAusrVsbczEikk+664OvBTYC94dfHUiaWRLA3X8VbXn9QGHwI0g0w9ratZx54pkxFyQi+aK7gP8lQahPCW/tOaCA76uwBX/8gBK14EUkrbo70enqDNXRf4UBP3HweFYo4EUkjbrrg7/SzDpdx8xOMrPT019WPxIG/ITScayrWxdzMSKST7rrohlOMDRyJbASqAOKgXcAZxGcCLUo0grzXRjwJw4aS+3+J6g/UM+IQSNiLkpE8kF34+C/B1QRnORUTjCjZBWwDbjK3T/o7hsjrzKfhQF/wqDguipra9VNIyLp0e2Uv+7eDDwW3iTdwoAfXzIaDgZDJc+acFbMRYlIPuj2RCeJWBjwZYWDOW7gcWrBi0jaKODjFga8NTUxrXyahkqKSNoo4OPWesGPxkYqyysV8CKSNj0KeDO7wcyOs8CPzex5Mzs/6uL6hQ4BX3+gntr9tfHWJCJ5oact+I+7+x7gfKCMYGbJb0ZWVX/SLuCnlU8DNJJGRNKjpwHfeqGPC4Gfuftajr74h/RWQUHwtbGRypGVADrhSUTSoqcBv9LMHiUI+EfMbAjQEl1Z/YhZMOFYYyPjhowLRtKoH15E0qDbcfChTxBc+ONldz8QXqv1msiq6m8SCWhsxMx0oFVE0qanLfh/AP7q7rvN7ErgS0BDdGX1M2HAA0HA165FV0YUkb7qacDfDhwws1OAfwE2Az+NrKr+pn3Aj6xk58GdGkkjIn3W04BvCi+2/X7g++5+GzAkurL6mUGDYO9eIGjBg67uJCJ919OA32tmXyAYHvm/4RTCiejK6mdOPhleeAGgbSSNhkqKSF/1NODnA4cJxsO/AYwHvh1ZVf1NMgnr1sH+/YwZPIahxUPVgheRPutRwIehvhg43szeCxxy9y774M3sBDNbbmbrzGytmd2QhnrzU3U1tLTACy9gZpqTRkTSoqdTFVwOPAdcBlwOPGtml3azWRPwL+4+DTgNuM7MpvWl2LyVTAZfa2oAjaQRkfToaRfNF4Fqd/+Yu38UOBX4t642cPfX3f358P5eYD0wri/F5q3Ro2H8+KMCftehXezYvyPmwkQkl/U04Ae4e/txezuPYVvMbAIwC3g2xbIFZlZjZjV1dXU9fcn8k0zCihWADrSKSHr0NKR/Z2aPmNnVZnY18L/AQz3Z0MwGA0uBheGEZUdx9zvdPenuyfLy8p7WnX+qq+Gll6ChQUMlRSQtenqQ9f8AdwIzwtud7v6v3W1nZgmCcF/s7r/qS6F5r7UffuVKRg8eTVlxmVrwItInPZ2LBndfShDWPWJmBvwYWO/uN/eitv6l3YFWO/dcKkdqThoR6ZsuW/BmttfM9qS47TWzt3W3dDCH4MSoc81sVXi7MG2V55thw2DSpLf64cNJxzSSRkR6q8sWvLv3ejoCd38azRl/bJJJeO45IAj43Yd28/q+1xk7ZGzMhYlILtI1WbNJdTVs2QJ1dbq6k4j0mQI+m7Q70KqrO4lIXyngs0lVVXCFp5oaRpWOYljJMB1oFZFeU8Bnk+OOgylTYMUKXd1JRPpMAZ9tqqs1J42IpIUCPtskk7B9O2zfTuXIShoON7B97/a4qxKRHKSAzzbtTnjSlAUi0hcK+GwzcyYUFMCKFZp0TET6RAGfbQYNgspKqKlhZOlIRgwaoRa8iPSKAj4bVVcHUxa4M618msbCi0ivKOCzUTIJO3fCq69qThoR6TUFfDaqrg6+hgda9xzew7a92+KtSURyjgI+G518MhQV6UCriPSJAj4bFRXBKadoqKSI9IkCPlslk1BTQ3nJcMoHlasFLyLHTAGfrZJJ2LMHNm3S1Z1EpFcU8Nmq9UDrihVUlleyrm6dRtKIyDFRwGerigooKWnrh997ZC+v7Xkt7qpEJIco4LNVYWEwP/yKFW1Xd9IJTyJyLBTw2SyZhBdeoHLYFEBDJUXk2Cjgs1l1NRw4wIhX6xhZOlIHWkXkmCjgs1mHqYMV8CJyLBTw2Wzy5OAyfmHAaySNiBwLBXw2GzAAZs9um7Jg35F9/K3hb3FXJSI5QgGf7ZJJePFFph//94CmLBCRnlPAZ7vqajhyhOm1QdeMRtKISE8p4LNdeKB16JpNjCodpRa8iPSYAj7bTZgAw4e39cPrZCcR6SkFfLYza5tZsnUkTYu3xF2ViOQABXwuqK6GNWs4Zchk9jfu10gaEekRBXwuSCahuZlkXQLQgVYR6RkFfC4Ipw6e/EoDoKGSItIzCvhcMHYsjBnDoFVrGTN4jAJeRHpEAZ8rWg+0jqxUF42I9EhkAW9md5tZrZmtiWof/Up1NWzYQFXpZNbXr9dIGhHpVpQt+P8G5kX4+v1LMgnunF4/iAONB9iye0vcFYlIloss4N39SeDNqF6/3wnPaJ3+6kFAV3cSke7F3gdvZgvMrMbMaurq6uIuJ3uVl8OJJzLupdcBDZUUke7FHvDufqe7J909WV5eHnc52a26mqLnX2TskLEaSSMi3Yo94OUYJJPw8sucVvL3CngR6ZYCPpeEJzydt6uM9XUaSSMiXYtymOR9wJ+BKWa21cw+EdW++o2qKgCS252DTQd5ZdcrMRckItmsMKoXdvcPRfXa/dbQoTB5MpM274LyYMqCk4adFHdVIpKl1EWTa6qrKfvLJkAjaUSkawr4XJNMMmDbNmb6aNbVayy8iHROAZ9rwgOt79s7Ri14EemSAj7XzJoFAwYwZ8dA1tevp7mlOe6KRCRLKeBzTWkpTJvGtC37OdR0iFd2aySNiKSmgM9FySSj/roVXAdaRaRzCvhcVF1NUf0uxu/R1Z1EpHMK+FwUzix5wa7hCngR6ZQCPhfNmAGFhZy783h10YhIpxTwuai4GGbMoGprExvqN2gkjYikpIDPVckkJ26q53DTYV7e9XLc1YhIFlLA56rqagbuPcBJb+pAq4ikpoDPVeGB1uR2DZUUkdQU8LmqshKKi5m7c4ha8CKSkgI+VyUSMHMmp71RqIAXkZQU8LmsuprJr+7jpdr1NLU0xV2NiGQZBXwuSyYpPtjIxB2NbH5zc9zViEiWUcDnsvYHWtVNIyIdKOBz2ZQp+ODBVG+H1TtWx12NiGQZBXwuKyjAqqo4q24Q//Hkf/Cp33yKbXu2xV2ViGQJBXyuq67m5NdbuH7Wtdzz4j1M/q/J3Pj7G9l9aHfclYlIzBTwuS6ZxA4d4rsnfJINn9nAxRUXc9PTN3HSrSfx3T9/l8NNh+OuUERiooDPdeE1Wlmxgkllk1h8yWJWLlhJ1Zgq/vnRf2bK96fw89U/p8Vb4q1TRDJOAZ/rJk2C4cPha1+Dm26C2lqqxlTx2FWP8eiVjzKsZBhXLbuKqh9W8cimR3D3uCsWkQxRwOc6M1i6FCZPhhtvhPHj4UMfgief5N2TzqNmQQ2LL1lMw+EG5i2ex3k/O4+a7TVxVy0iGaCAzwdnnQXLl8O6dfDpT8PDDwfPTZ/OgO/fxof/7j1suG4D35v3PVbvWE31XdVcseQKnRwlkucU8PmkogJuuQW2b4cf/xhKS+H662HsWAZe+xmuL5zD5us386UzvsT/vPQ/TL1tKp996LPU7q+Nu3IRiYBlU59sMpn0mhp1H6TVypVw++1w771w8GBwUPbaa3n9wjP52opv86Pnf0RJooS5E+dSVlJGWXEZQ4uHUlZcRlnJW/eHFg9te1xSWIKZxf2diQhgZivdPZlymQK+n9i9G372syDs16+HoUPhYx/jlfn/yJde/zl/2fEXdh/aza5Du9h3ZF+XL1VUUPS2PwIlhSUMsAG9vhm9/4PhpP4Mp/psp1o3G34HOvsepH8YUjSEm867qVfbKuDlLe7w1FNB0C9dCo2NcM45cOaZQZfO4ME0lQzkQJGxN+HsKWxmd0EjuwqOsHPAYertIHV2gJ1HGth9eDe7Du5i16FdHG46TIu39OrW7H2/pmxnfyBS/aeRat1s+I+kL3/kJLeNLB3JuuvW9WpbBbyktmMH/OQncNdd8PIxXtd14MDgD0LrragoGNEzYEDwtf39VM+lWh6VLPqMi6RUVga//GWvNu0q4Av7VJTktlGjYNGi4NbSAgcOwL59sH9/cGt/v+PjjvcbG4MgdQ9eq/3Xzu63tLx16wv37v9AZEELXaRTh6M541wBL4EBA2Dw4OAmInlBwyRFRPKUAl5EJE9FGvBmNs/M/mpmm8xsUZT7EhGRo0UW8GZWANwGXABMAz5kZtOi2p+IiBwtyhb8qcAmd3/Z3Y8A9wPvj3B/IiLSTpSjaMYBr7V7vBV4Z8eVzGwBsCB8uM/M/trL/Y0A6nu5bSaovr5RfX2j+vomm+s7sbMFsQ+TdPc7gTv7+jpmVtPZYP9soPr6RvX1jerrm2yvrzNRdtFsA05o93h8+JyIiGRAlAG/AphsZhPNrAi4AvhNhPsTEZF2IuuicfcmM/sM8AhQANzt7muj2h9p6OaJmOrrG9XXN6qvb7K9vpSyarIxERFJH53JKiKSpxTwIiJ5KucCvrvpD8xsoJn9Ilz+rJlNyGBtJ5jZcjNbZ2ZrzeyGFOucbWYNZrYqvH05U/WF+99iZn8J9/22yfctcGv4/q02s6oM1jal3fuyysz2mNnCDutk9P0zs7vNrNbM1rR7bpiZPWZmG8OvZZ1s+7FwnY1m9rEM1vdtM9sQ/vyWmdnQTrbt8rMQYX1fNbNt7X6GF3aybeRTnXRS3y/a1bbFzFZ1sm3k71+fuXvO3AgO1m4GJgFFwIvAtA7rfBq4I7x/BfCLDNY3BqgK7w8BXkpR39nAb2N8D7cAI7pYfiHwMGDAacCzMf6s3wBOjPP9A84EqoA17Z77T2BReH8R8K0U2w0DXg6/loX3yzJU3/lAYXj/W6nq68lnIcL6vgp8rgc//y5/16Oqr8Py/wt8Oa73r6+3XGvB92T6g/cD94T3lwBzLUPXY3P31939+fD+XmA9wRm9ueT9wE898Aww1MzGxFDHXGCzu78aw77buPuTwJsdnm7/GbsH+ECKTf8ReMzd33T3XcBjwLxM1Ofuj7p7U/jwGYJzUGLRyfvXExmZ6qSr+sLcuBy4L937zZRcC/hU0x90DNC2dcIPeQMwPCPVtRN2Dc0Cnk2x+B/M7EUze9jMKjNbGQ48amYrw2kiOurJe5wJV9D5L1ac7x/AKHd/Pbz/BjAqxTrZ8j5+nOA/slS6+yxE6TNhF9LdnXRxZcP7dwaww903drI8zvevR3It4HOCmQ0GlgIL3X1Ph8XPE3Q7nAL8F/DrDJd3urtXEczyeZ2ZnZnh/XcrPDHuIiDVRSrjfv+O4sH/6lk51tjMvgg0AYs7WSWuz8LtwEnATOB1gm6QbPQhum69Z/3vUq4FfE+mP2hbx8wKgeOBnRmpLthngiDcF7v7rzoud/c97r4vvP8QkDCzEZmqz923hV9rgWUE/wq3lw1TTFwAPO/uOzouiPv9C+1o7bYKv9amWCfW99HMrgbeC3wk/CP0Nj34LETC3Xe4e7O7twB3dbLfuN+/QuAS4BedrRPX+3csci3gezL9wW+A1hELlwJ/6OwDnm5hn92PgfXufnMn64xuPSZgZqcS/Awy8gfIzErNbEjrfYKDcWs6rPYb4KPhaJrTgIZ23RGZ0mnLKc73r532n7GPAQ+mWOcR4HwzKwu7IM4Pn4ucmc0DPg9c5O4HOlmnJ5+FqOprf0zn4k72G/dUJ+cBG9x9a6qFcb5/xyTuo7zHeiMY5fESwRH2L4bP/TvBhxmgmOBf+03Ac8CkDNZ2OsG/66uBVeHtQuCfgH8K1/kMsJZgVMAzwLsyWN+kcL8vhjW0vn/t6zOCC7VsBv4CJDP88y0lCOzj2z0X2/tH8IfmdaCRoB/4EwTHdH4PbAQeB4aF6yaBH7Xb9uPh53ATcE0G69tE0H/d+hlsHVU2Fnioq89Chur7WfjZWk0Q2mM61hc+ftvveibqC5//79bPXLt1M/7+9fWmqQpERPJUrnXRiIhIDyngRUTylAJeRCRPKeBFRPKUAl5EJE8p4EXSIJzl8rdx1yHSngJeRCRPKeClXzGzK83suXAO7x+aWYGZ7TOz71owh//vzaw8XHemmT3Tbl71svD5d5jZ4+GEZ8+b2Unhyw82syXhXOyLMzWLqUhnFPDSb5hZBTAfmOPuM4Fm4CMEZ8/WuHsl8EfgK+EmPwX+1d1nEJx52fr8YuA2DyY8exfBmZAQzB66EJhGcKbjnIi/JZEuFcZdgEgGzQVmAyvCxnUJwURhLbw1qdTPgV+Z2fHAUHf/Y/j8PcAvw/lHxrn7MgB3PwQQvt5zHs5dEl4FaALwdOTflUgnFPDSnxhwj7t/4agnzf6tw3q9nb/jcLv7zej3S2KmLhrpT34PXGpmI6Ht2qonEvweXBqu82HgaXdvAHaZ2Rnh81cBf/TgSl1bzewD4WsMNLNBmfwmRHpKLQzpN9x9nZl9ieAqPAMIZhC8DtgPnBouqyXop4dgKuA7wgB/GbgmfP4q4Idm9u/ha1yWwW9DpMc0m6T0e2a2z90Hx12HSLqpi0ZEJE+pBS8ikqfUghcRyVMKeBGRPKWAFxHJUwp4EZE8pYAXEclT/x/rIF+ArAeCcQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_losses\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dqz-uMTjdT_",
        "outputId": "e122ad69-bfec-460d-c8ee-20b112253693"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[710.3104248046875, 195.94064331054688]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assessing ML performance"
      ],
      "metadata": {
        "id": "kP-e5P8tGRD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook [Lesson1_00_is_it_a_bird_creating_a_model_from_your_own_data.ipynb](Lesson1_00_is_it_a_bird_creating_a_model_from_your_own_data.ipynb) uses  `error_rate` when creating the `learner`:\n",
        "\n",
        "    learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
        "\n",
        "    learn.fine_tune(3)\n",
        "\n",
        "where `dls` is a `DataLoaders` object with the input data, `resnet18` is a deep CNN model. The argument `metrics=error_rate` indicates that the overall performance of the algorithm is measured proportion of mismatches between the set of actual labels $y_1, \\dots , y_n$ and the set of predicted labels $\\hat{y}_1, \\dots , \\hat{y}_n$. The output for the training epochs looks like\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1PJ36nJ-Isu-LThJTFwRj7XwVY5qWeRfJ\" width=\"300\" >\n",
        "\n",
        "One could wonder how the  `error_rate` is computed when the data set is divided into *training* and *validation* sets. In `fastai`, because the training set and validation set are integrated into a single class,  by default the metrics display during training (see above) use the validation set.\n",
        "\n",
        "At this pont it should be clear what *epoch*, *train_loss*, *valid_loss* and *error_rate* in the above training output along epochs is.\n",
        "\n",
        "There are many metrics other than `error_rate` for measuring the performance of *regression* and *classification* problems. For instance, `scikit-learn` provides the metrics listed in \n",
        "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics. The package `fastai`  includes  all metrics from `scikit-learn` and some additional ones. The documentation is available at https://docs.fast.ai/metrics.html. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "At32ItDHGVkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion matrix"
      ],
      "metadata": {
        "id": "RyKdSl5bQA_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In [Lesson2_edited_book_02_production.ipynb](Lesson2_edited_book_02_production.ipynb), to understand in detail which  mistakes the model is making,  a confusion matrix (also called an *error matrix*) was created with \n",
        "\n",
        "    interp = ClassificationInterpretation.from_learner(learn)\n",
        "\n",
        "    interp.plot_confusion_matrix()\n",
        "\n",
        "which output was: \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1zsTJ7wh6KneWG7_QuXijy5LDlJiu3K-F\" width=\"300\" >\n",
        "\n",
        "\n",
        "The comment in the notebook for this figure is the following: The rows represent all the black, grizzly, and teddy bears in our dataset, respectively. The columns represent the images which the model predicted as black, grizzly, and teddy bears, respectively. Therefore, the diagonal of the matrix shows the images which were classified correctly, and the off-diagonal cells represent those which were classified incorrectly. This is one of the many ways that fastai allows you to view the results of your model. *It is (of course!) calculated using the validation set*. \n"
      ],
      "metadata": {
        "id": "AaA2DfU8P_9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some specific models for ML"
      ],
      "metadata": {
        "id": "emfh_GZQagkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tabular data"
      ],
      "metadata": {
        "id": "buB1nxDccH5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far the examples from scratch above (simple linear regression, quadratic regression) dealt with *scalar* inputs, i.e. each example was described by a single number. \n",
        "\n",
        "Examples can also be tabular data, where each example is described by a numeric vector. Formally, the $i$-th example is described by a vector  $(x_{i1}, \\dots, x_{ik})$ of length $k$, for examples $i = 1, \\dots, n$ and labels are $y_1, \\dots,  y_n$  as before.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZxwIpE1oavEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Perceptron"
      ],
      "metadata": {
        "id": "AnfcN6V9am9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On of the simplest models for numerical tabular data is the *perceptron* \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1HqHfJn7ejJMGeAa5fTTQzW_myubIDsDh\" width=\"600\" >"
      ],
      "metadata": {
        "id": "9k6m_gN4aqDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "torch.manual_seed(42)\n",
        "\n",
        "B=20 # batch size\n",
        "step_size = 0.1 # learning rate\n",
        "iter=20 # number epochs\n",
        "\n",
        "############################################ Creating synthetic data\n",
        "# Creating a function f(X) with a slope of -5\n",
        "X = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
        "func = -5 * X + 2\n",
        "# Adding Gaussian noise to the function f(X) and saving it in Y\n",
        "y = func + 0.4 * torch.randn(X.size())\n",
        "\n",
        "##################################### Create train and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "########################################## Linear regression LS solution\n",
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression().fit(X, y)\n",
        "print('coefficients:',reg.coef_,reg.intercept_)\n",
        "\n",
        "####################################################### Gradient Descent\n",
        "# initial weights\n",
        "coeffs=torch.tensor([-20.,-10.]).requires_grad_() \n",
        "\n",
        "# defining the function for prediction (linear regression)\n",
        "def calc_preds(x): return coeffs[0] + coeffs[1] * x \n",
        "\n",
        "# evaluating data points with Mean Square Error (MSE)\n",
        "def calc_loss_from_labels(y_pred, y): return torch.mean((y_pred - y) ** 2)\n",
        "\n",
        "# lists to store losses for each epoch\n",
        "training_losses=[]; validation_losses=[]\n",
        "\n",
        "# epochs\n",
        "for i in range(iter):\n",
        "  # calculating loss as in the beginning of an epoch and storing it\n",
        "    y_pred = calc_preds(X_train)\n",
        "    training_losses.append(calc_loss_from_labels(y_pred, y_train).tolist())\n",
        "    y_pred = calc_preds(X_valid)\n",
        "    validation_losses.append(calc_loss_from_labels(y_pred, y_valid).tolist())\n",
        "    # mini-batch gradient descent: weight are updated after each batch\n",
        "    for idx_start in np.arange(0,X_train.shape[0],B):\n",
        "        # create batch\n",
        "        batch_X=X_train[idx_start:(idx_start+B),:]\n",
        "        batch_y=y_train[idx_start:(idx_start+B),:]\n",
        "        # making a prediction in forward pass\n",
        "        y_pred = calc_preds(batch_X)\n",
        "        # calculating the loss between predicted and actual values\n",
        "        loss = calc_loss_from_labels(y_pred, batch_y)\n",
        "        # compute gradient\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            # update coeffs\n",
        "            coeffs.sub_(coeffs.grad * step_size)\n",
        "            # zerofy gradients (because they add up)\n",
        "            coeffs.grad.zero_()\n",
        "\n",
        "print('batch size:', B)\n",
        "print('coeffs found bt gradient descent:',coeffs.requires_grad_(False))\n",
        "plt.plot(training_losses, '-g',  validation_losses, '-r')\n",
        "plt.gca().legend(('train','validation'))\n",
        "plt.ylim(0, 5)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss (MSE)')\n",
        "#plt.title(\"Train (green) and validation (red) losses\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v1ufDH1Wareo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Examples\n",
        "1. Quadratic function\n",
        "Xs are just scalars\n",
        "Y are continuous (regression problem)\n",
        "F_w is f(x;a,b,c)\n",
        "Loss is mÃ£e or rmse\n",
        "In this case the best set of weights can be determined analytacally\n",
        "In alternative one can use gradient descent\n",
        "\n",
        "2. Perceptron (no sigmoid) = mlr\n",
        "X are vectors , after preprocessing\n",
        "Y are 0 or 1 (regression or classification)\n",
        "Fw is S(X1 w1+....)\n",
        "Loss is ...\n",
        "In this case the problem 8s equivalent to least square mlr, and has an analital solution\n",
        "\n",
        "3. Perceptron with sigmoid output\n",
        "\n",
        "\n",
        "4 FC nn with hidden layers\n"
      ],
      "metadata": {
        "id": "1iMtNBUt7zxi"
      }
    }
  ]
}